{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from scipy import stats\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, auc, roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_curve, average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./data2100205.csv\")\n",
    "\n",
    "columns = data.iloc[:,2:-19].columns\n",
    "columns =columns.drop(['pleura_tb', 'pleura_bac','blood_positive', 'blood_obscure', 'cancer'])\n",
    "float_column=data[columns].select_dtypes(include=['float']).columns\n",
    "object_column = data[columns].select_dtypes(include=['object']).columns\n",
    "not_object = ['D-dimer', 'BNP', 'procalcitonin', 'ANA titer','ANA 1:40','ionized calcium','E-ANC_blood']\n",
    "\n",
    "data[not_object[0]] = data[not_object[0]].replace(\"\\<\",\"\",regex=True).replace(\"\\>\",\"\", regex=True).astype(float)\n",
    "data[not_object[1]] = data[not_object[1]].replace(\"\\<\",\"\",regex=True).replace(\"\\>\",\"\", regex=True).astype(float)\n",
    "data[not_object[2]] = data[not_object[2]].replace(\"\\<\",\"\",regex=True).replace(\"\\>\",\"\", regex=True).astype(float)\n",
    "data[not_object[5]] = data[not_object[5]].replace(\"\\<\",\"\",regex=True).replace(\"\\>\",\"\", regex=True).astype(float)\n",
    "\n",
    "def floating(x):\n",
    "    try:\n",
    "        value = float(x)\n",
    "    except ValueError :\n",
    "        value = np.nan\n",
    "    return value\n",
    "\n",
    "data[not_object[6]] = data[not_object[6]].replace(\"\\-\",\"\",regex=True).apply(floating).astype(float)\n",
    "data[not_object[4]] = data[not_object[4]].replace({np.nan:0, \n",
    "  'Neg(<1:40)':0,\n",
    "  'Non(<1:40)':0,\n",
    "  'Pos. Speckled':1,\n",
    "  'Reactive Speckled':2,\n",
    "  'Cytoplasmic':3,\n",
    "  'Reactive Nuclear membrane':4,\n",
    "  'Positive Speckled':5})\n",
    "\n",
    "data[not_object[3]] =  data[not_object[3]].replace({np.nan:0,\n",
    " '<1:40':0,\n",
    " 'Speckled 1:1280':1,\n",
    " 'Speckled 1:40':2,\n",
    " 'Nucleolar 1:80':3,\n",
    " 'Homogene.1:640':4,\n",
    " 'Mixed type(Remark)':5,\n",
    " 'Nucle.Membrane 1:80':6,\n",
    " 'Speckled 1:160':7,\n",
    " 'Homogene.1:40':8,\n",
    " 'Nucleolar 1:640':9,\n",
    " 'Homogene.1:160':10,\n",
    " 'Discr.speckled 1:1280':11,\n",
    " 'Nucleolar 1:40':12,\n",
    " 'Homogene.1:80':13,\n",
    " 'Homogene.1:1280':14,\n",
    " 'Speckled 1:320':15})\n",
    "\n",
    "data[['ANA1','ANA2','ANA3','ANA4','ANA5','ANA6','ANA7','ANA8','ANA9','ANA10','ANA11','ANA12','ANA13','ANA14',\n",
    "    'ANA15','ANA16']]=pd.DataFrame(np.eye(len(data[not_object[3]].unique()))[data[not_object[3]]])\n",
    "\n",
    "data[['ANA_1','ANA_2','ANA_3','ANA_4','ANA_5','ANA_6']]=pd.DataFrame(np.eye(len(data[not_object[4]].unique()))[data[not_object[4]]])\n",
    "\n",
    "reallist = float_column.tolist()+['D-dimer', 'BNP', 'procalcitonin','ionized calcium','E-ANC_blood']\n",
    "analist = ['ANA1','ANA2','ANA3','ANA4','ANA5','ANA6','ANA7','ANA8','ANA9','ANA10','ANA11','ANA12','ANA13','ANA14',\n",
    "    'ANA15','ANA16','ANA_1','ANA_2','ANA_3','ANA_4','ANA_5','ANA_6']\n",
    "\n",
    "count_label = pd.DataFrame(data.count()/len(data))\n",
    "\n",
    "data.loc[data['ph_pleural fluid'].isna(), 'ph_pleural fluid'] = data.loc[data['ph_pleural fluid'].isna(), 'pH_pleural fluid(Qn) ']\n",
    "\n",
    "list_04 = ['ADA_pleural fluid', 'LD_pleural fluid', 'albumin_pleural fluid', 'ph_pleural fluid', 'Total protein_pleural fluid', 'Glucose_pleural fluid',\n",
    "'Total amylase_pleural fluid', 'Creatinine', 'AST(SGOT)', 'Alkaline phosphatase', 'total bilirubin', 'glucose', 'Albumin', 'BUN',\n",
    "'Total protein', 'LD', 'ALT(SGPT)', 'r-GT', 'CRP', 'D-dimer', 'BNP', 'procalcitonin', 'total calcium', 'sodium', 'chloride', 'potassium', 'phosphorus', 'Hb_blood',\n",
    "'RDW_blood', 'WBC_blood', 'MCHC_blood', 'MCV_blood', 'PDW_blood', 'Hct_blood', 'E-ANC_blood', 'MCH_blood', 'RBC_blood', 'MPV_blood', 'Platelet_blood', \"Histiocyte (Qn)[Cytospin,Wright's stain],Pleural fluid\",\n",
    "\"Neutrophil (Qn)[Cytospin,Wright's stain],Pleural fluid\", \"RBC (Qn)[Cytospin,Wright's stain],Pleural fluid\", \"Eosinophil (Qn)[Cytospin,Wright's stain],Pleural fluid\",\n",
    "\"Nucleated cells (Qn)[Cytospin,Wright's stain],Pleural fluid\", \"Lymphocyte (Qn)[Cytospin,Wright's stain],Pleural fluid\", \"Mesothelial cell (Qn)[Cytospin,Wright's stain],Pleural fluid\"\n",
    "          ]\n",
    "\n",
    "xlist =dict()\n",
    "\n",
    "for i in range(len(list_04)):\n",
    "    xlist.update({data[list_04[i]].name: stats.mode(data[list_04[i]]).mode.item()})\n",
    "\n",
    "for i in range(len(list_04)):\n",
    "    data[list_04[i]] = data[list_04[i]].replace(np.nan, xlist[list_04[i]])\n",
    "\n",
    "data.loc[data['pleura_bac']>0,'Labeling']=3\n",
    "\n",
    "data.loc[((data['Labeling'].isin([3,17,\"3\",\"17\"]))& (data['제외']!=1)),'new_label']=\"bacterial\"\n",
    "data.loc[((data['Labeling'].isin([1,\"1\"]))& (data['제외']!=1)),'new_label']=\"tuberculosis\"\n",
    "data.loc[((data['Labeling'].isin([2,\"2\"]))& (data['제외']!=1)),'new_label']=\"malignancy\"\n",
    "data.loc[((data['Labeling'].isin([4,5,6,18,22,26,\"4\",\"5\",\"6\",\"18\",\"22\",\"26\"]))\n",
    "          & (data['제외']!=1)),'new_label']=\"volume\"\n",
    "data.loc[((data['Labeling'].isin([7,10,14,19,25,29,30,\"7\",\"10\",\"14\",\"19\",\"25\",\"29\",\"30\"]))\n",
    "          & (data['제외']!=1)),'new_label']=\"other\"\n",
    "data.loc[((data['Labeling'].isin([8,16,24,23,20,21,27,28,\"8\",\"16\",\"24\",\"23\",\"20\",\"21\",\"27\",\"28\"]))\n",
    "          & (data['제외']!=1)),'new_label']=\"other\"\n",
    "data.loc[((data['Labeling'].isin([9,15,\"9\",\"15\"]))& (data['제외']!=1))\n",
    "         ,'new_label']=\"other\"\n",
    "\n",
    "data.loc[((data['Labeling'].isin([3,17,\"3\",\"17\"]))& (data['제외']!=1)),'new_int']=0\n",
    "data.loc[((data['Labeling'].isin([1,\"1\"]))& (data['제외']!=1)),'new_int']=1\n",
    "data.loc[((data['Labeling'].isin([2,\"2\"]))& (data['제외']!=1)),'new_int']=2\n",
    "data.loc[((data['Labeling'].isin([4,5,6,18,22,26,\"4\",\"5\",\"6\",\"18\",\"22\",\"26\"]))\n",
    "          & (data['제외']!=1)),'new_int']=3\n",
    "data.loc[((data['Labeling'].isin([7,10,14,19,25,29,30,\"7\",\"10\",\"14\",\"19\",\"25\",\"29\",\"30\"]))\n",
    "          & (data['제외']!=1)),'new_int']=4\n",
    "data.loc[((data['Labeling'].isin([8,16,24,23,20,21,27,28,\"8\",\"16\",\"24\",\"23\",\"20\",\"21\",\"27\",\"28\"]))\n",
    "          & (data['제외']!=1)),'new_int']=4\n",
    "data.loc[((data['Labeling'].isin([9,15,\"9\",\"15\"]))& (data['제외']!=1))\n",
    "         ,'new_int']=4\n",
    "data.loc[((data['new_int'].isna())& (data['제외']!=1))\n",
    "         ,'new_int']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### test set process\n",
    "\n",
    "data.loc[((data['final'].isin([3,17,\"3\",\"17\"]))& (data['제외']!=1)),'final_label']=\"bacterial\"\n",
    "data.loc[((data['final'].isin([1,\"1\"]))& (data['제외']!=1)),'final_label']=\"tuberculosis\"\n",
    "data.loc[((data['final'].isin([2,\"2\"]))& (data['제외']!=1)),'final_label']=\"malignancy\"\n",
    "data.loc[((data['final'].isin([4,5,6,18,22,26,\"4\",\"5\",\"6\",\"18\",\"22\",\"26\"]))\n",
    "          & (data['제외']!=1)),'final_label']=\"volume\"\n",
    "data.loc[((data['final'].isin([7,10,14,19,25,29,30,35,36,\"7\",\"10\",\"14\",\"19\",\"25\",\"29\",\"30\",\"35\",\"36\"]))\n",
    "          & (data['제외']!=1)),'final_label']=\"other\"\n",
    "data.loc[((data['final'].isin([8,16,24,23,20,21,27,28,31,32,\"8\",\"16\",\"24\",\"23\",\"20\",\"21\",\"27\",\"28\",\"31\",\"32\"]))\n",
    "          & (data['제외']!=1)),'final_label']=\"other\"\n",
    "data.loc[((data['final'].isin([9,15,33,34,\"9\",\"15\",\"33\",\"34\"]))& (data['제외']!=1))\n",
    "         ,'final_label']=\"other\"\n",
    "\n",
    "data.loc[((data['final'].isin([3,17,\"3\",\"17\"]))& (data['제외']!=1)),'final_int']=0\n",
    "data.loc[((data['final'].isin([1,\"1\"]))& (data['제외']!=1)),'final_int']=1\n",
    "data.loc[((data['final'].isin([2,\"2\"]))& (data['제외']!=1)),'final_int']=2\n",
    "data.loc[((data['final'].isin([4,5,6,18,22,26,\"4\",\"5\",\"6\",\"18\",\"22\",\"26\"]))\n",
    "          & (data['제외']!=1)),'final_int']=3\n",
    "data.loc[((data['final'].isin([7,10,14,19,25,29,30,35,36,\"7\",\"10\",\"14\",\"19\",\"25\",\"29\",\"30\",\"35\",\"36\"]))\n",
    "          & (data['제외']!=1)),'final_int']=4\n",
    "data.loc[((data['final'].isin([8,16,24,23,20,21,27,28,31,32,\"8\",\"16\",\"24\",\"23\",\"20\",\"21\",\"27\",\"28\",\"31\",\"32\"]))\n",
    "          & (data['제외']!=1)),'final_int']=4\n",
    "data.loc[((data['final'].isin([9,15,33,34,\"9\",\"15\",\"33\",\"34\"]))& (data['제외']!=1))\n",
    "         ,'final_int']=4\n",
    "\n",
    "data['LD_ratio'] = data['LD_pleural fluid']/data['LD']>=0.6\n",
    "data['LD_raw'] = data['LD_pleural fluid']>= 250*2/3\n",
    "data['PF_ratio'] = data['Total protein_pleural fluid']/data['Total protein']>=0.6\n",
    "\n",
    "\n",
    "data['sum_pleural'] = data['LD_ratio'].replace(True, 1).replace(False,0) +data['LD_raw'].replace(True, 1).replace(False,0)+data['PF_ratio'].replace(True, 1).replace(False,0)\n",
    "\n",
    "data['exudate']= data['sum_pleural']>=1\n",
    "\n",
    "\n",
    "data['low_pH']=data['ph_pleural fluid']<7.2\n",
    "data['low_glu']=data['Glucose_pleural fluid']<61\n",
    "data['high_LDH']=data['LD_pleural fluid']>1000\n",
    "\n",
    "data['score']=data['low_pH'].replace(True, 1).replace(False,0)+data['low_glu'].replace(True, 1).replace(False,0)+data['high_LDH'].replace(True, 1).replace(False,0)\n",
    "\n",
    "data['complicated_pleural_effusion']=data['score']>2\n",
    "\n",
    "data['might_Tb']= data['ADA_pleural fluid']>50\n",
    "data['lymph_dominant'] = data[\"Lymphocyte (Qn)[Cytospin,Wright's stain],Pleural fluid\"]/data[\"Neutrophil (Qn)[Cytospin,Wright's stain],Pleural fluid\"]>0.75\n",
    "data.loc[(data['lymph_dominant']==True) & (data['might_Tb']==True),'Tuberculosis']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing\n",
    "scaling, transformation, rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['trans_label']=data['final_label']\n",
    "data.loc[data['Tuberculosis']==True,'trans_label']='rule_tuberculosis'\n",
    "data.loc[(data['Tuberculosis']==True)&\n",
    "         (data['final_label']!='tuberculosis'),'trans_label']='not_tuberculosis'\n",
    "data['trans_int']=data['final_int']\n",
    "data.loc[data['Tuberculosis']==True,'trans_int']=5\n",
    "data.loc[(data['Tuberculosis']==True)&\n",
    "         (data['final_label']!='tuberculosis'),'trans_int']=7\n",
    "\n",
    "data['trans_label2']=data['final_label']\n",
    "data.loc[data['complicated_pleural_effusion']==True,'trans_label2']='rule_complicated_effusion'\n",
    "data.loc[(data['complicated_pleural_effusion']==True)&\n",
    "         (data['final_label']!='bacterial'),'trans_label2']='not_bacteria'\n",
    "data['trans_int2']=data['final_int']\n",
    "data.loc[data['complicated_pleural_effusion']==True,'trans_int2']=6\n",
    "data.loc[(data['complicated_pleural_effusion']==True)&\n",
    "         (data['final_label']!='bacterial'),'trans_int2']=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['제외']!=1]\n",
    "\n",
    "training = data[list_04+['new_label']+['new_int']]\n",
    "training_only = training.loc[training['new_label'].isna()==False]\n",
    "col_name  = training.columns.difference([\"new_label\",'new_int'])\n",
    "\n",
    "range_lower = 0.05\n",
    "range_upper = 0.95\n",
    "outcome_quantile = training[col_name].quantile([range_lower, range_upper])\n",
    "\n",
    "for i in col_name:\n",
    "    training.loc[(training[i]<=outcome_quantile[i][range_lower]),i]=\\\n",
    "        outcome_quantile[i][range_lower]\n",
    "\n",
    "    training.loc[(training[i]>=outcome_quantile[i][range_upper]),i]=\\\n",
    "        outcome_quantile[i][range_upper]\n",
    "\n",
    "scaler01 = MinMaxScaler(feature_range=(0.01,1))\n",
    "scaler01 = scaler01.fit(training[col_name])\n",
    "training[col_name] = scaler01.transform(training[col_name])\n",
    "\n",
    "training = training.loc[training['new_label'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrast import small_encoder, added_on_model, parse_option\n",
    "from contrast import train, validate\n",
    "from losses import SupConLoss\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import sys\n",
    "sys.argv=['']\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "from util import AverageMeter\n",
    "from util import save_model, accuracy\n",
    "\n",
    "try:\n",
    "    import apex\n",
    "    from apex import amp, optimizers\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "batch_size, val_batch_size = 450,223\n",
    "\n",
    "#weighted sampler \n",
    "# test-set의 proportion\n",
    "weight = 1/np.array([201, 123, 600, 100, 200])\n",
    "\n",
    "samples_weight = np.array([weight[t] for t in y_train.numpy().astype(int)])\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weight = samples_weight.double()\n",
    "train_sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "val_samples_weight = np.array([weight[t] for t in y_nottrain.numpy().astype(int)])\n",
    "val_samples_weight = torch.from_numpy(val_samples_weight)\n",
    "val_samples_weight = val_samples_weight.double()\n",
    "val_sampler = WeightedRandomSampler(val_samples_weight, len(val_samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split():\n",
    "    train_, test_ = train_test_split(training, test_size = 0.3,\n",
    "                                 stratify=training['new_int']\n",
    "                                                   )\n",
    "    X_train, X_notrain, y_train, y_nottrain = train_test_split(train_[col_name],\n",
    "                                                     train_['new_int'], test_size = 0.3\n",
    "                                                   , stratify=train_['new_int'])\n",
    "    X_train = torch.tensor(np.array(X_train), dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.values.astype(int), dtype=torch.long)\n",
    "    X_notrain = torch.tensor(np.array(X_notrain), dtype=torch.float32)\n",
    "    y_nottrain = torch.tensor(y_nottrain.values.astype(int), dtype=torch.long)\n",
    "    X_test_ = torch.tensor(np.array(test_[col_name]), dtype=torch.float32)\n",
    "    y_test_ = torch.tensor(test_['new_int'].values.astype(int), dtype=torch.long)\n",
    "    train_data = TensorDataset(X_train, y_train)\n",
    "    total_val_data = TensorDataset(X_notrain, y_nottrain)\n",
    "\n",
    "    return X_test_, y_test_, train_data, total_val_data, X_notrain, y_nottrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate로 early stopping적용 학습모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parse_option()\n",
    "input_len = 46\n",
    "dimension = 20\n",
    "\n",
    "layer_list = [128,256,128,32]\n",
    "\n",
    "opt.model_path = './revise/{}_{}_models'.format(\"effu220120_weighted\", dimension)\n",
    "if not os.path.isdir(opt.model_path):\n",
    "    os.makedirs(opt.model_path)\n",
    "\n",
    "opt.tb_path = './revise/{}_{}_tensorboard'.format(\"effu220120_weighted\", dimension)\n",
    "if not os.path.isdir(opt.tb_path):\n",
    "    os.makedirs(opt.tb_path)\n",
    "\n",
    "opt.print_freq = 100\n",
    "\n",
    "min_epoch = 600\n",
    "n_epochs_stop =100\n",
    "epoch =5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1():\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           sampler = train_sampler)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=total_val_data, \n",
    "                                               batch_size=val_batch_size, \n",
    "                                               sampler = val_sampler)\n",
    "    model = small_encoder(input_len, layer_list, dimension)\n",
    "    criterion = SupConLoss()\n",
    "    model = model.cuda()\n",
    "    cudnn.benchmark = True\n",
    "    criterion = criterion.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                         lr=0.002, weight_decay=1e-5)\n",
    "    \n",
    "    opt.epochs = 5000\n",
    "    best_val_loss = np.inf\n",
    "        # training routine\n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        # adjust_learning_rate(opt, optimizer, epoch)\n",
    "        # train for one epoch\n",
    "        loss  = train(train_loader, model, criterion, optimizer, epoch, opt)\n",
    "\n",
    "        \n",
    "        # evaluation\n",
    "        val_loss = validate(val_loader, model, criterion, epoch, opt)\n",
    "\n",
    "        if val_loss <= best_val_loss:\n",
    "            filename = [f for f in os.listdir(opt.model_path) if f.startswith(\"model_{layer}\".format(layer=layer_list))]\n",
    "            if filename:\n",
    "                if os.path.isfile(opt.model_path+\"/\"+filename[0]):\n",
    "                    os.remove(opt.model_path+\"/\"+filename[0])\n",
    "                    \n",
    "            save_file = os.path.join(\n",
    "                opt.model_path, 'model_{layer}_loss_{loss:.3f}.pth'.format(layer=layer_list,\n",
    "                                                                             loss=val_loss))\n",
    "\n",
    "            save_model(model, optimizer, opt, epoch, save_file)\n",
    "            epochs_no_improve = 0\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            \n",
    "        if epoch > min_epoch and epochs_no_improve > n_epochs_stop:\n",
    "            break\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layer_list = [128,5]\n",
    "\n",
    "\n",
    "# writer = SummaryWriter('runs/model_classifier')\n",
    "PATH = './model_classifier221024/'\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_on():\n",
    "    classifier_ = added_on_model(model_=model, parameter=add_layer_list, dimension = 20 )\n",
    "    classifier_ = classifier_.cuda()        \n",
    "    optimizer = optim.Adam(classifier_.parameters(), weight_decay = 1e-4, lr=0.0005)\n",
    "    min_val_loss = np.Inf\n",
    "    epochs_no_improve = 20\n",
    "    \n",
    "    for num_epoch in range(epoch):\n",
    "\n",
    "        average_loss = 0\n",
    "        device = 'cuda'\n",
    "        classifier_ = classifier_.train()\n",
    "        for batch_idx, (train_X,train_Y) in enumerate(train_loader):\n",
    "            train_X = train_X.to(device)\n",
    "            train_Y = torch.tensor(train_Y, dtype=torch.long).to(device)\n",
    "            output = classifier_(train_X)\n",
    "            loss = loss_function(output, train_Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            average_loss += loss.item()\n",
    "\n",
    "        average_loss /=len(train_loader)\n",
    "        aver_val_loss = 0\n",
    "\n",
    "        classifier_= classifier_.eval()\n",
    "        for val_X,val_Y in val_loader:\n",
    "            val_X = val_X.to(device)\n",
    "            val_Y = torch.tensor(val_Y, dtype=torch.long).to(device)\n",
    "            val_output = classifier_(val_X)\n",
    "            loss_val = loss_function(val_output, val_Y)\n",
    "            aver_val_loss += loss_val.item()\n",
    "\n",
    "        aver_val_loss /=len(val_loader)\n",
    "\n",
    "        if aver_val_loss <= min_val_loss:\n",
    "            directory = PATH\n",
    "            #directory 이름은 layer 첫번째 및 두번째 그리고 마지막 layer수 \n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            filename = [f for f in os.listdir(directory) if f.startswith(\"model_{}\".format(add_layer_list))]\n",
    "            if filename:\n",
    "                if os.path.isfile(directory+filename[0]):\n",
    "                    os.remove(directory+filename[0])\n",
    "            torch.save(classifier_, directory+'model_{}_{:.0f}.pt'.format(add_layer_list,aver_val_loss*1000))\n",
    "            epochs_no_improve = 0\n",
    "            min_val_loss = aver_val_loss\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # If the validation loss is at a minimum\n",
    "        if num_epoch > min_epoch and epochs_no_improve == n_epochs_stop:\n",
    "            early_stop = True\n",
    "            break\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model():\n",
    "    vp_label = classifier_model(X_notrain.cuda())\n",
    "    v_predict = torch.argmax(vp_label, axis=1)\n",
    "    val_acc1, val_acc2 = accuracy(vp_label.cpu(), y_nottrain, topk=(1, 2))\n",
    "    val_acc1 = val_acc1.item()\n",
    "    val_acc2 = val_acc2.item()\n",
    "    one_hot_y = nn.functional.one_hot(y_nottrain)\n",
    "    roc_weight_val = roc_auc_score(one_hot_y, soft(vp_label).cpu().detach().numpy(),  multi_class= 'ovr', average = 'weighted')\n",
    "    roc_mirco_val = roc_auc_score(one_hot_y, soft(vp_label).cpu().detach().numpy(),  multi_class= 'ovr', average = 'micro')\n",
    "    \n",
    "    testp_label = classifier_model(X_test_.cuda())\n",
    "    testpredict = torch.argmax(testp_label, axis=1)\n",
    "    test_acc1, test_acc2 = accuracy(testp_label.cpu(), y_test_, topk=(1, 2))\n",
    "    test_acc1 = test_acc1.item()\n",
    "    test_acc2 = test_acc2.item()    \n",
    "    \n",
    "    one_hot_y_test = nn.functional.one_hot(y_test_)\n",
    "    roc_weight_test = roc_auc_score(one_hot_y_test, soft(testp_label).cpu().detach().numpy(),  multi_class= 'ovr', average = 'weighted')\n",
    "    roc_micro_test = roc_auc_score(one_hot_y_test, soft(testp_label).cpu().detach().numpy(),  multi_class= 'ovr', average = 'micro')\n",
    "    return val_acc1, val_acc2, roc_weight_val, roc_mirco_val, test_acc1, test_acc2, roc_weight_test, roc_micro_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [99][1/3]\ttraining loss 6.755 (average: 6.755)\n",
      "Train: [99][2/3]\ttraining loss 6.746 (average: 6.750)\n",
      "Train: [99][3/3]\ttraining loss 4.890 (average: 6.618)\n",
      "Test: [0/2]\tval Loss: 5.9979 (val loss average: 5.9979)\n",
      "Test: [1/2]\tval Loss: 5.8384 (val loss average: 5.9239)\n",
      "Train: [199][1/3]\ttraining loss 6.593 (average: 6.593)\n",
      "Train: [199][2/3]\ttraining loss 6.649 (average: 6.621)\n",
      "Train: [199][3/3]\ttraining loss 4.699 (average: 6.484)\n",
      "Test: [0/2]\tval Loss: 5.8920 (val loss average: 5.8920)\n",
      "Test: [1/2]\tval Loss: 5.7627 (val loss average: 5.8320)\n",
      "Train: [299][1/3]\ttraining loss 6.524 (average: 6.524)\n",
      "Train: [299][2/3]\ttraining loss 6.583 (average: 6.553)\n",
      "Train: [299][3/3]\ttraining loss 4.693 (average: 6.421)\n",
      "Test: [0/2]\tval Loss: 5.7615 (val loss average: 5.7615)\n",
      "Test: [1/2]\tval Loss: 5.7315 (val loss average: 5.7476)\n",
      "Train: [399][1/3]\ttraining loss 6.581 (average: 6.581)\n",
      "Train: [399][2/3]\ttraining loss 6.457 (average: 6.519)\n",
      "Train: [399][3/3]\ttraining loss 4.651 (average: 6.386)\n",
      "Test: [0/2]\tval Loss: 5.7860 (val loss average: 5.7860)\n",
      "Test: [1/2]\tval Loss: 5.6493 (val loss average: 5.7226)\n",
      "Train: [499][1/3]\ttraining loss 6.427 (average: 6.427)\n",
      "Train: [499][2/3]\ttraining loss 6.488 (average: 6.457)\n",
      "Train: [499][3/3]\ttraining loss 4.652 (average: 6.329)\n",
      "Test: [0/2]\tval Loss: 5.8450 (val loss average: 5.8450)\n",
      "Test: [1/2]\tval Loss: 5.6978 (val loss average: 5.7767)\n",
      "Train: [599][1/3]\ttraining loss 6.348 (average: 6.348)\n",
      "Train: [599][2/3]\ttraining loss 6.494 (average: 6.421)\n",
      "Train: [599][3/3]\ttraining loss 4.709 (average: 6.299)\n",
      "Test: [0/2]\tval Loss: 5.9386 (val loss average: 5.9386)\n",
      "Test: [1/2]\tval Loss: 5.7055 (val loss average: 5.8304)\n",
      "Train: [99][1/3]\ttraining loss 6.720 (average: 6.720)\n",
      "Train: [99][2/3]\ttraining loss 6.744 (average: 6.732)\n",
      "Train: [99][3/3]\ttraining loss 4.788 (average: 6.594)\n",
      "Test: [0/2]\tval Loss: 5.9804 (val loss average: 5.9804)\n",
      "Test: [1/2]\tval Loss: 5.8201 (val loss average: 5.9060)\n",
      "Train: [199][1/3]\ttraining loss 6.668 (average: 6.668)\n",
      "Train: [199][2/3]\ttraining loss 6.666 (average: 6.667)\n",
      "Train: [199][3/3]\ttraining loss 4.710 (average: 6.527)\n",
      "Test: [0/2]\tval Loss: 5.9741 (val loss average: 5.9741)\n",
      "Test: [1/2]\tval Loss: 5.7652 (val loss average: 5.8772)\n",
      "Train: [299][1/3]\ttraining loss 6.634 (average: 6.634)\n",
      "Train: [299][2/3]\ttraining loss 6.617 (average: 6.625)\n",
      "Train: [299][3/3]\ttraining loss 4.614 (average: 6.482)\n",
      "Test: [0/2]\tval Loss: 5.9094 (val loss average: 5.9094)\n",
      "Test: [1/2]\tval Loss: 5.7654 (val loss average: 5.8426)\n",
      "Train: [399][1/3]\ttraining loss 6.590 (average: 6.590)\n",
      "Train: [399][2/3]\ttraining loss 6.596 (average: 6.593)\n",
      "Train: [399][3/3]\ttraining loss 4.650 (average: 6.455)\n",
      "Test: [0/2]\tval Loss: 5.8526 (val loss average: 5.8526)\n",
      "Test: [1/2]\tval Loss: 5.7905 (val loss average: 5.8238)\n",
      "Train: [499][1/3]\ttraining loss 6.502 (average: 6.502)\n",
      "Train: [499][2/3]\ttraining loss 6.566 (average: 6.534)\n",
      "Train: [499][3/3]\ttraining loss 4.741 (average: 6.406)\n",
      "Test: [0/2]\tval Loss: 5.8875 (val loss average: 5.8875)\n",
      "Test: [1/2]\tval Loss: 5.7672 (val loss average: 5.8317)\n",
      "Train: [599][1/3]\ttraining loss 6.492 (average: 6.492)\n",
      "Train: [599][2/3]\ttraining loss 6.613 (average: 6.552)\n",
      "Train: [599][3/3]\ttraining loss 4.659 (average: 6.417)\n",
      "Test: [0/2]\tval Loss: 5.8581 (val loss average: 5.8581)\n",
      "Test: [1/2]\tval Loss: 5.7411 (val loss average: 5.8038)\n",
      "Train: [699][1/3]\ttraining loss 6.439 (average: 6.439)\n",
      "Train: [699][2/3]\ttraining loss 6.570 (average: 6.504)\n",
      "Train: [699][3/3]\ttraining loss 4.501 (average: 6.361)\n",
      "Test: [0/2]\tval Loss: 5.9092 (val loss average: 5.9092)\n",
      "Test: [1/2]\tval Loss: 5.7373 (val loss average: 5.8294)\n",
      "Train: [799][1/3]\ttraining loss 6.540 (average: 6.540)\n",
      "Train: [799][2/3]\ttraining loss 6.538 (average: 6.539)\n",
      "Train: [799][3/3]\ttraining loss 4.563 (average: 6.398)\n",
      "Test: [0/2]\tval Loss: 5.7845 (val loss average: 5.7845)\n",
      "Test: [1/2]\tval Loss: 5.7129 (val loss average: 5.7513)\n",
      "Train: [99][1/3]\ttraining loss 6.751 (average: 6.751)\n",
      "Train: [99][2/3]\ttraining loss 6.767 (average: 6.759)\n",
      "Train: [99][3/3]\ttraining loss 4.936 (average: 6.629)\n",
      "Test: [0/2]\tval Loss: 5.9942 (val loss average: 5.9942)\n",
      "Test: [1/2]\tval Loss: 5.8723 (val loss average: 5.9376)\n",
      "Train: [199][1/3]\ttraining loss 6.602 (average: 6.602)\n",
      "Train: [199][2/3]\ttraining loss 6.580 (average: 6.591)\n",
      "Train: [199][3/3]\ttraining loss 4.772 (average: 6.462)\n",
      "Test: [0/2]\tval Loss: 5.9235 (val loss average: 5.9235)\n",
      "Test: [1/2]\tval Loss: 5.7715 (val loss average: 5.8530)\n",
      "Train: [299][1/3]\ttraining loss 6.582 (average: 6.582)\n",
      "Train: [299][2/3]\ttraining loss 6.629 (average: 6.606)\n",
      "Train: [299][3/3]\ttraining loss 4.639 (average: 6.466)\n",
      "Test: [0/2]\tval Loss: 5.9476 (val loss average: 5.9476)\n",
      "Test: [1/2]\tval Loss: 5.7372 (val loss average: 5.8500)\n",
      "Train: [399][1/3]\ttraining loss 6.480 (average: 6.480)\n",
      "Train: [399][2/3]\ttraining loss 6.505 (average: 6.492)\n",
      "Train: [399][3/3]\ttraining loss 4.605 (average: 6.358)\n",
      "Test: [0/2]\tval Loss: 5.9269 (val loss average: 5.9269)\n",
      "Test: [1/2]\tval Loss: 5.6545 (val loss average: 5.8005)\n",
      "Train: [499][1/3]\ttraining loss 6.440 (average: 6.440)\n",
      "Train: [499][2/3]\ttraining loss 6.470 (average: 6.455)\n",
      "Train: [499][3/3]\ttraining loss 4.517 (average: 6.317)\n",
      "Test: [0/2]\tval Loss: 5.9181 (val loss average: 5.9181)\n",
      "Test: [1/2]\tval Loss: 5.7676 (val loss average: 5.8483)\n",
      "Train: [599][1/3]\ttraining loss 6.423 (average: 6.423)\n",
      "Train: [599][2/3]\ttraining loss 6.411 (average: 6.417)\n",
      "Train: [599][3/3]\ttraining loss 4.524 (average: 6.283)\n",
      "Test: [0/2]\tval Loss: 5.8256 (val loss average: 5.8256)\n",
      "Test: [1/2]\tval Loss: 5.7692 (val loss average: 5.7994)\n",
      "Train: [99][1/3]\ttraining loss 6.753 (average: 6.753)\n",
      "Train: [99][2/3]\ttraining loss 6.764 (average: 6.758)\n",
      "Train: [99][3/3]\ttraining loss 4.856 (average: 6.623)\n",
      "Test: [0/2]\tval Loss: 5.9717 (val loss average: 5.9717)\n",
      "Test: [1/2]\tval Loss: 5.8545 (val loss average: 5.9173)\n",
      "Train: [199][1/3]\ttraining loss 6.626 (average: 6.626)\n",
      "Train: [199][2/3]\ttraining loss 6.638 (average: 6.632)\n",
      "Train: [199][3/3]\ttraining loss 4.699 (average: 6.494)\n",
      "Test: [0/2]\tval Loss: 5.8644 (val loss average: 5.8644)\n",
      "Test: [1/2]\tval Loss: 5.7915 (val loss average: 5.8306)\n",
      "Train: [299][1/3]\ttraining loss 6.604 (average: 6.604)\n",
      "Train: [299][2/3]\ttraining loss 6.536 (average: 6.570)\n",
      "Train: [299][3/3]\ttraining loss 4.618 (average: 6.431)\n",
      "Test: [0/2]\tval Loss: 5.9372 (val loss average: 5.9372)\n",
      "Test: [1/2]\tval Loss: 5.7993 (val loss average: 5.8732)\n",
      "Train: [399][1/3]\ttraining loss 6.552 (average: 6.552)\n",
      "Train: [399][2/3]\ttraining loss 6.559 (average: 6.555)\n",
      "Train: [399][3/3]\ttraining loss 4.574 (average: 6.414)\n",
      "Test: [0/2]\tval Loss: 5.7604 (val loss average: 5.7604)\n",
      "Test: [1/2]\tval Loss: 5.6786 (val loss average: 5.7224)\n",
      "Train: [499][1/3]\ttraining loss 6.476 (average: 6.476)\n",
      "Train: [499][2/3]\ttraining loss 6.496 (average: 6.486)\n",
      "Train: [499][3/3]\ttraining loss 4.622 (average: 6.353)\n",
      "Test: [0/2]\tval Loss: 5.8349 (val loss average: 5.8349)\n",
      "Test: [1/2]\tval Loss: 5.6802 (val loss average: 5.7631)\n",
      "Train: [599][1/3]\ttraining loss 6.462 (average: 6.462)\n",
      "Train: [599][2/3]\ttraining loss 6.483 (average: 6.472)\n",
      "Train: [599][3/3]\ttraining loss 4.562 (average: 6.336)\n",
      "Test: [0/2]\tval Loss: 5.7380 (val loss average: 5.7380)\n",
      "Test: [1/2]\tval Loss: 5.6280 (val loss average: 5.6870)\n",
      "Train: [99][1/3]\ttraining loss 6.766 (average: 6.766)\n",
      "Train: [99][2/3]\ttraining loss 6.724 (average: 6.745)\n",
      "Train: [99][3/3]\ttraining loss 4.822 (average: 6.608)\n",
      "Test: [0/2]\tval Loss: 6.0423 (val loss average: 6.0423)\n",
      "Test: [1/2]\tval Loss: 5.8806 (val loss average: 5.9673)\n",
      "Train: [199][1/3]\ttraining loss 6.634 (average: 6.634)\n",
      "Train: [199][2/3]\ttraining loss 6.633 (average: 6.634)\n",
      "Train: [199][3/3]\ttraining loss 4.594 (average: 6.488)\n",
      "Test: [0/2]\tval Loss: 5.9694 (val loss average: 5.9694)\n",
      "Test: [1/2]\tval Loss: 5.8797 (val loss average: 5.9278)\n",
      "Train: [299][1/3]\ttraining loss 6.541 (average: 6.541)\n",
      "Train: [299][2/3]\ttraining loss 6.622 (average: 6.581)\n",
      "Train: [299][3/3]\ttraining loss 4.599 (average: 6.440)\n",
      "Test: [0/2]\tval Loss: 5.9830 (val loss average: 5.9830)\n",
      "Test: [1/2]\tval Loss: 5.8164 (val loss average: 5.9057)\n",
      "Train: [399][1/3]\ttraining loss 6.527 (average: 6.527)\n",
      "Train: [399][2/3]\ttraining loss 6.465 (average: 6.496)\n",
      "Train: [399][3/3]\ttraining loss 4.645 (average: 6.364)\n",
      "Test: [0/2]\tval Loss: 5.8830 (val loss average: 5.8830)\n",
      "Test: [1/2]\tval Loss: 5.7714 (val loss average: 5.8312)\n",
      "Train: [499][1/3]\ttraining loss 6.436 (average: 6.436)\n",
      "Train: [499][2/3]\ttraining loss 6.457 (average: 6.447)\n",
      "Train: [499][3/3]\ttraining loss 4.773 (average: 6.327)\n",
      "Test: [0/2]\tval Loss: 5.8635 (val loss average: 5.8635)\n",
      "Test: [1/2]\tval Loss: 5.7550 (val loss average: 5.8132)\n",
      "Train: [599][1/3]\ttraining loss 6.489 (average: 6.489)\n",
      "Train: [599][2/3]\ttraining loss 6.449 (average: 6.469)\n",
      "Train: [599][3/3]\ttraining loss 4.530 (average: 6.331)\n",
      "Test: [0/2]\tval Loss: 5.9908 (val loss average: 5.9908)\n",
      "Test: [1/2]\tval Loss: 5.9586 (val loss average: 5.9758)\n",
      "Train: [99][1/3]\ttraining loss 6.781 (average: 6.781)\n",
      "Train: [99][2/3]\ttraining loss 6.760 (average: 6.770)\n",
      "Train: [99][3/3]\ttraining loss 4.846 (average: 6.633)\n",
      "Test: [0/2]\tval Loss: 5.9671 (val loss average: 5.9671)\n",
      "Test: [1/2]\tval Loss: 5.8415 (val loss average: 5.9088)\n",
      "Train: [199][1/3]\ttraining loss 6.703 (average: 6.703)\n",
      "Train: [199][2/3]\ttraining loss 6.642 (average: 6.673)\n",
      "Train: [199][3/3]\ttraining loss 4.885 (average: 6.545)\n",
      "Test: [0/2]\tval Loss: 5.9860 (val loss average: 5.9860)\n",
      "Test: [1/2]\tval Loss: 5.7495 (val loss average: 5.8763)\n",
      "Train: [299][1/3]\ttraining loss 6.643 (average: 6.643)\n",
      "Train: [299][2/3]\ttraining loss 6.599 (average: 6.621)\n",
      "Train: [299][3/3]\ttraining loss 4.719 (average: 6.486)\n",
      "Test: [0/2]\tval Loss: 5.8910 (val loss average: 5.8910)\n",
      "Test: [1/2]\tval Loss: 5.7284 (val loss average: 5.8155)\n",
      "Train: [399][1/3]\ttraining loss 6.588 (average: 6.588)\n",
      "Train: [399][2/3]\ttraining loss 6.555 (average: 6.571)\n",
      "Train: [399][3/3]\ttraining loss 4.514 (average: 6.425)\n",
      "Test: [0/2]\tval Loss: 5.8080 (val loss average: 5.8080)\n",
      "Test: [1/2]\tval Loss: 5.6623 (val loss average: 5.7404)\n",
      "Train: [499][1/3]\ttraining loss 6.498 (average: 6.498)\n",
      "Train: [499][2/3]\ttraining loss 6.548 (average: 6.523)\n",
      "Train: [499][3/3]\ttraining loss 4.513 (average: 6.380)\n",
      "Test: [0/2]\tval Loss: 5.7994 (val loss average: 5.7994)\n",
      "Test: [1/2]\tval Loss: 5.6882 (val loss average: 5.7478)\n",
      "Train: [599][1/3]\ttraining loss 6.444 (average: 6.444)\n",
      "Train: [599][2/3]\ttraining loss 6.493 (average: 6.468)\n",
      "Train: [599][3/3]\ttraining loss 4.541 (average: 6.331)\n",
      "Test: [0/2]\tval Loss: 5.9151 (val loss average: 5.9151)\n",
      "Test: [1/2]\tval Loss: 5.7429 (val loss average: 5.8352)\n",
      "Train: [99][1/3]\ttraining loss 6.758 (average: 6.758)\n",
      "Train: [99][2/3]\ttraining loss 6.757 (average: 6.758)\n",
      "Train: [99][3/3]\ttraining loss 4.828 (average: 6.620)\n",
      "Test: [0/2]\tval Loss: 6.0168 (val loss average: 6.0168)\n",
      "Test: [1/2]\tval Loss: 5.8615 (val loss average: 5.9447)\n",
      "Train: [199][1/3]\ttraining loss 6.620 (average: 6.620)\n",
      "Train: [199][2/3]\ttraining loss 6.632 (average: 6.626)\n",
      "Train: [199][3/3]\ttraining loss 4.863 (average: 6.501)\n",
      "Test: [0/2]\tval Loss: 5.9466 (val loss average: 5.9466)\n",
      "Test: [1/2]\tval Loss: 5.8363 (val loss average: 5.8954)\n",
      "Train: [299][1/3]\ttraining loss 6.582 (average: 6.582)\n",
      "Train: [299][2/3]\ttraining loss 6.577 (average: 6.579)\n",
      "Train: [299][3/3]\ttraining loss 4.759 (average: 6.449)\n",
      "Test: [0/2]\tval Loss: 5.9648 (val loss average: 5.9648)\n",
      "Test: [1/2]\tval Loss: 5.8364 (val loss average: 5.9052)\n",
      "Train: [399][1/3]\ttraining loss 6.524 (average: 6.524)\n",
      "Train: [399][2/3]\ttraining loss 6.481 (average: 6.502)\n",
      "Train: [399][3/3]\ttraining loss 4.618 (average: 6.368)\n",
      "Test: [0/2]\tval Loss: 5.8953 (val loss average: 5.8953)\n",
      "Test: [1/2]\tval Loss: 5.7718 (val loss average: 5.8380)\n",
      "Train: [499][1/3]\ttraining loss 6.489 (average: 6.489)\n",
      "Train: [499][2/3]\ttraining loss 6.491 (average: 6.490)\n",
      "Train: [499][3/3]\ttraining loss 4.694 (average: 6.362)\n",
      "Test: [0/2]\tval Loss: 5.8421 (val loss average: 5.8421)\n",
      "Test: [1/2]\tval Loss: 5.7941 (val loss average: 5.8198)\n",
      "Train: [599][1/3]\ttraining loss 6.431 (average: 6.431)\n",
      "Train: [599][2/3]\ttraining loss 6.441 (average: 6.436)\n",
      "Train: [599][3/3]\ttraining loss 4.688 (average: 6.311)\n",
      "Test: [0/2]\tval Loss: 5.8572 (val loss average: 5.8572)\n",
      "Test: [1/2]\tval Loss: 5.7584 (val loss average: 5.8113)\n",
      "Train: [699][1/3]\ttraining loss 6.361 (average: 6.361)\n",
      "Train: [699][2/3]\ttraining loss 6.427 (average: 6.394)\n",
      "Train: [699][3/3]\ttraining loss 4.521 (average: 6.260)\n",
      "Test: [0/2]\tval Loss: 5.9345 (val loss average: 5.9345)\n",
      "Test: [1/2]\tval Loss: 5.7766 (val loss average: 5.8612)\n",
      "Train: [799][1/3]\ttraining loss 6.372 (average: 6.372)\n",
      "Train: [799][2/3]\ttraining loss 6.388 (average: 6.380)\n",
      "Train: [799][3/3]\ttraining loss 4.423 (average: 6.241)\n",
      "Test: [0/2]\tval Loss: 5.9896 (val loss average: 5.9896)\n",
      "Test: [1/2]\tval Loss: 5.8394 (val loss average: 5.9199)\n",
      "Train: [99][1/3]\ttraining loss 6.782 (average: 6.782)\n",
      "Train: [99][2/3]\ttraining loss 6.801 (average: 6.791)\n",
      "Train: [99][3/3]\ttraining loss 4.891 (average: 6.656)\n",
      "Test: [0/2]\tval Loss: 6.0254 (val loss average: 6.0254)\n",
      "Test: [1/2]\tval Loss: 5.9240 (val loss average: 5.9784)\n",
      "Train: [199][1/3]\ttraining loss 6.672 (average: 6.672)\n",
      "Train: [199][2/3]\ttraining loss 6.689 (average: 6.681)\n",
      "Train: [199][3/3]\ttraining loss 4.734 (average: 6.542)\n",
      "Test: [0/2]\tval Loss: 5.9335 (val loss average: 5.9335)\n",
      "Test: [1/2]\tval Loss: 5.8248 (val loss average: 5.8831)\n",
      "Train: [299][1/3]\ttraining loss 6.601 (average: 6.601)\n",
      "Train: [299][2/3]\ttraining loss 6.624 (average: 6.612)\n",
      "Train: [299][3/3]\ttraining loss 4.715 (average: 6.477)\n",
      "Test: [0/2]\tval Loss: 5.9691 (val loss average: 5.9691)\n",
      "Test: [1/2]\tval Loss: 5.7517 (val loss average: 5.8682)\n",
      "Train: [399][1/3]\ttraining loss 6.598 (average: 6.598)\n",
      "Train: [399][2/3]\ttraining loss 6.572 (average: 6.585)\n",
      "Train: [399][3/3]\ttraining loss 4.607 (average: 6.444)\n",
      "Test: [0/2]\tval Loss: 5.7302 (val loss average: 5.7302)\n",
      "Test: [1/2]\tval Loss: 5.7174 (val loss average: 5.7243)\n",
      "Train: [499][1/3]\ttraining loss 6.485 (average: 6.485)\n",
      "Train: [499][2/3]\ttraining loss 6.587 (average: 6.536)\n",
      "Train: [499][3/3]\ttraining loss 4.629 (average: 6.400)\n",
      "Test: [0/2]\tval Loss: 5.7636 (val loss average: 5.7636)\n",
      "Test: [1/2]\tval Loss: 5.6140 (val loss average: 5.6942)\n",
      "Train: [599][1/3]\ttraining loss 6.456 (average: 6.456)\n",
      "Train: [599][2/3]\ttraining loss 6.531 (average: 6.494)\n",
      "Train: [599][3/3]\ttraining loss 4.690 (average: 6.365)\n",
      "Test: [0/2]\tval Loss: 5.7718 (val loss average: 5.7718)\n",
      "Test: [1/2]\tval Loss: 5.7025 (val loss average: 5.7397)\n",
      "Train: [99][1/3]\ttraining loss 6.805 (average: 6.805)\n",
      "Train: [99][2/3]\ttraining loss 6.795 (average: 6.800)\n",
      "Train: [99][3/3]\ttraining loss 4.866 (average: 6.662)\n",
      "Test: [0/2]\tval Loss: 6.0450 (val loss average: 6.0450)\n",
      "Test: [1/2]\tval Loss: 5.8671 (val loss average: 5.9625)\n",
      "Train: [199][1/3]\ttraining loss 6.745 (average: 6.745)\n",
      "Train: [199][2/3]\ttraining loss 6.779 (average: 6.762)\n",
      "Train: [199][3/3]\ttraining loss 4.816 (average: 6.623)\n",
      "Test: [0/2]\tval Loss: 6.0061 (val loss average: 6.0061)\n",
      "Test: [1/2]\tval Loss: 5.8317 (val loss average: 5.9252)\n",
      "Train: [299][1/3]\ttraining loss 6.672 (average: 6.672)\n",
      "Train: [299][2/3]\ttraining loss 6.653 (average: 6.662)\n",
      "Train: [299][3/3]\ttraining loss 4.770 (average: 6.527)\n",
      "Test: [0/2]\tval Loss: 5.9771 (val loss average: 5.9771)\n",
      "Test: [1/2]\tval Loss: 5.8460 (val loss average: 5.9163)\n",
      "Train: [399][1/3]\ttraining loss 6.607 (average: 6.607)\n",
      "Train: [399][2/3]\ttraining loss 6.590 (average: 6.598)\n",
      "Train: [399][3/3]\ttraining loss 4.580 (average: 6.455)\n",
      "Test: [0/2]\tval Loss: 5.9172 (val loss average: 5.9172)\n",
      "Test: [1/2]\tval Loss: 5.7315 (val loss average: 5.8310)\n",
      "Train: [499][1/3]\ttraining loss 6.578 (average: 6.578)\n",
      "Train: [499][2/3]\ttraining loss 6.594 (average: 6.586)\n",
      "Train: [499][3/3]\ttraining loss 4.726 (average: 6.454)\n",
      "Test: [0/2]\tval Loss: 5.8784 (val loss average: 5.8784)\n",
      "Test: [1/2]\tval Loss: 5.7749 (val loss average: 5.8304)\n",
      "Train: [599][1/3]\ttraining loss 6.542 (average: 6.542)\n",
      "Train: [599][2/3]\ttraining loss 6.539 (average: 6.541)\n",
      "Train: [599][3/3]\ttraining loss 4.648 (average: 6.406)\n",
      "Test: [0/2]\tval Loss: 5.7714 (val loss average: 5.7714)\n",
      "Test: [1/2]\tval Loss: 5.7126 (val loss average: 5.7441)\n",
      "Train: [699][1/3]\ttraining loss 6.582 (average: 6.582)\n",
      "Train: [699][2/3]\ttraining loss 6.544 (average: 6.563)\n",
      "Train: [699][3/3]\ttraining loss 4.525 (average: 6.418)\n",
      "Test: [0/2]\tval Loss: 5.9279 (val loss average: 5.9279)\n",
      "Test: [1/2]\tval Loss: 5.7302 (val loss average: 5.8362)\n",
      "Train: [99][1/3]\ttraining loss 6.790 (average: 6.790)\n",
      "Train: [99][2/3]\ttraining loss 6.763 (average: 6.777)\n",
      "Train: [99][3/3]\ttraining loss 4.924 (average: 6.645)\n",
      "Test: [0/2]\tval Loss: 6.0483 (val loss average: 6.0483)\n",
      "Test: [1/2]\tval Loss: 5.9008 (val loss average: 5.9798)\n",
      "Train: [199][1/3]\ttraining loss 6.641 (average: 6.641)\n",
      "Train: [199][2/3]\ttraining loss 6.694 (average: 6.667)\n",
      "Train: [199][3/3]\ttraining loss 4.819 (average: 6.536)\n",
      "Test: [0/2]\tval Loss: 5.9650 (val loss average: 5.9650)\n",
      "Test: [1/2]\tval Loss: 5.7913 (val loss average: 5.8844)\n",
      "Train: [299][1/3]\ttraining loss 6.591 (average: 6.591)\n",
      "Train: [299][2/3]\ttraining loss 6.599 (average: 6.595)\n",
      "Train: [299][3/3]\ttraining loss 4.794 (average: 6.467)\n",
      "Test: [0/2]\tval Loss: 5.8619 (val loss average: 5.8619)\n",
      "Test: [1/2]\tval Loss: 5.7408 (val loss average: 5.8057)\n",
      "Train: [399][1/3]\ttraining loss 6.572 (average: 6.572)\n",
      "Train: [399][2/3]\ttraining loss 6.539 (average: 6.555)\n",
      "Train: [399][3/3]\ttraining loss 4.745 (average: 6.426)\n",
      "Test: [0/2]\tval Loss: 5.9726 (val loss average: 5.9726)\n",
      "Test: [1/2]\tval Loss: 5.6980 (val loss average: 5.8452)\n",
      "Train: [499][1/3]\ttraining loss 6.549 (average: 6.549)\n",
      "Train: [499][2/3]\ttraining loss 6.534 (average: 6.541)\n",
      "Train: [499][3/3]\ttraining loss 4.579 (average: 6.402)\n",
      "Test: [0/2]\tval Loss: 5.8612 (val loss average: 5.8612)\n",
      "Test: [1/2]\tval Loss: 5.8045 (val loss average: 5.8349)\n",
      "Train: [599][1/3]\ttraining loss 6.480 (average: 6.480)\n",
      "Train: [599][2/3]\ttraining loss 6.494 (average: 6.487)\n",
      "Train: [599][3/3]\ttraining loss 4.633 (average: 6.355)\n",
      "Test: [0/2]\tval Loss: 5.8904 (val loss average: 5.8904)\n",
      "Test: [1/2]\tval Loss: 5.7062 (val loss average: 5.8049)\n",
      "Train: [99][1/3]\ttraining loss 6.775 (average: 6.775)\n",
      "Train: [99][2/3]\ttraining loss 6.776 (average: 6.775)\n",
      "Train: [99][3/3]\ttraining loss 4.836 (average: 6.637)\n",
      "Test: [0/2]\tval Loss: 6.0332 (val loss average: 6.0332)\n",
      "Test: [1/2]\tval Loss: 5.9144 (val loss average: 5.9781)\n",
      "Train: [199][1/3]\ttraining loss 6.670 (average: 6.670)\n",
      "Train: [199][2/3]\ttraining loss 6.666 (average: 6.668)\n",
      "Train: [199][3/3]\ttraining loss 4.703 (average: 6.528)\n",
      "Test: [0/2]\tval Loss: 5.9649 (val loss average: 5.9649)\n",
      "Test: [1/2]\tval Loss: 5.8096 (val loss average: 5.8928)\n",
      "Train: [299][1/3]\ttraining loss 6.610 (average: 6.610)\n",
      "Train: [299][2/3]\ttraining loss 6.606 (average: 6.608)\n",
      "Train: [299][3/3]\ttraining loss 4.694 (average: 6.472)\n",
      "Test: [0/2]\tval Loss: 5.9536 (val loss average: 5.9536)\n",
      "Test: [1/2]\tval Loss: 5.8225 (val loss average: 5.8928)\n",
      "Train: [399][1/3]\ttraining loss 6.562 (average: 6.562)\n",
      "Train: [399][2/3]\ttraining loss 6.540 (average: 6.551)\n",
      "Train: [399][3/3]\ttraining loss 4.663 (average: 6.417)\n",
      "Test: [0/2]\tval Loss: 5.9500 (val loss average: 5.9500)\n",
      "Test: [1/2]\tval Loss: 5.7953 (val loss average: 5.8783)\n",
      "Train: [499][1/3]\ttraining loss 6.583 (average: 6.583)\n",
      "Train: [499][2/3]\ttraining loss 6.579 (average: 6.581)\n",
      "Train: [499][3/3]\ttraining loss 4.674 (average: 6.445)\n",
      "Test: [0/2]\tval Loss: 5.8909 (val loss average: 5.8909)\n",
      "Test: [1/2]\tval Loss: 5.7923 (val loss average: 5.8452)\n",
      "Train: [599][1/3]\ttraining loss 6.509 (average: 6.509)\n",
      "Train: [599][2/3]\ttraining loss 6.554 (average: 6.531)\n",
      "Train: [599][3/3]\ttraining loss 4.543 (average: 6.390)\n",
      "Test: [0/2]\tval Loss: 5.9641 (val loss average: 5.9641)\n",
      "Test: [1/2]\tval Loss: 5.7330 (val loss average: 5.8569)\n",
      "Train: [99][1/3]\ttraining loss 6.779 (average: 6.779)\n",
      "Train: [99][2/3]\ttraining loss 6.759 (average: 6.769)\n",
      "Train: [99][3/3]\ttraining loss 4.880 (average: 6.634)\n",
      "Test: [0/2]\tval Loss: 5.9994 (val loss average: 5.9994)\n",
      "Test: [1/2]\tval Loss: 5.8872 (val loss average: 5.9473)\n",
      "Train: [199][1/3]\ttraining loss 6.617 (average: 6.617)\n",
      "Train: [199][2/3]\ttraining loss 6.635 (average: 6.626)\n",
      "Train: [199][3/3]\ttraining loss 4.766 (average: 6.493)\n",
      "Test: [0/2]\tval Loss: 5.9204 (val loss average: 5.9204)\n",
      "Test: [1/2]\tval Loss: 5.6539 (val loss average: 5.7968)\n",
      "Train: [299][1/3]\ttraining loss 6.576 (average: 6.576)\n",
      "Train: [299][2/3]\ttraining loss 6.559 (average: 6.567)\n",
      "Train: [299][3/3]\ttraining loss 4.700 (average: 6.434)\n",
      "Test: [0/2]\tval Loss: 5.7527 (val loss average: 5.7527)\n",
      "Test: [1/2]\tval Loss: 5.6813 (val loss average: 5.7196)\n",
      "Train: [399][1/3]\ttraining loss 6.532 (average: 6.532)\n",
      "Train: [399][2/3]\ttraining loss 6.443 (average: 6.488)\n",
      "Train: [399][3/3]\ttraining loss 4.578 (average: 6.352)\n",
      "Test: [0/2]\tval Loss: 5.6638 (val loss average: 5.6638)\n",
      "Test: [1/2]\tval Loss: 5.6747 (val loss average: 5.6689)\n",
      "Train: [499][1/3]\ttraining loss 6.470 (average: 6.470)\n",
      "Train: [499][2/3]\ttraining loss 6.452 (average: 6.461)\n",
      "Train: [499][3/3]\ttraining loss 4.547 (average: 6.325)\n",
      "Test: [0/2]\tval Loss: 5.7852 (val loss average: 5.7852)\n",
      "Test: [1/2]\tval Loss: 5.7070 (val loss average: 5.7489)\n",
      "Train: [599][1/3]\ttraining loss 6.492 (average: 6.492)\n",
      "Train: [599][2/3]\ttraining loss 6.431 (average: 6.461)\n",
      "Train: [599][3/3]\ttraining loss 4.470 (average: 6.319)\n",
      "Test: [0/2]\tval Loss: 5.7705 (val loss average: 5.7705)\n",
      "Test: [1/2]\tval Loss: 5.6522 (val loss average: 5.7156)\n",
      "Train: [99][1/3]\ttraining loss 6.775 (average: 6.775)\n",
      "Train: [99][2/3]\ttraining loss 6.783 (average: 6.779)\n",
      "Train: [99][3/3]\ttraining loss 4.881 (average: 6.644)\n",
      "Test: [0/2]\tval Loss: 6.0276 (val loss average: 6.0276)\n",
      "Test: [1/2]\tval Loss: 5.8848 (val loss average: 5.9614)\n",
      "Train: [199][1/3]\ttraining loss 6.648 (average: 6.648)\n",
      "Train: [199][2/3]\ttraining loss 6.608 (average: 6.628)\n",
      "Train: [199][3/3]\ttraining loss 4.725 (average: 6.492)\n",
      "Test: [0/2]\tval Loss: 5.9223 (val loss average: 5.9223)\n",
      "Test: [1/2]\tval Loss: 5.8361 (val loss average: 5.8823)\n",
      "Train: [299][1/3]\ttraining loss 6.569 (average: 6.569)\n",
      "Train: [299][2/3]\ttraining loss 6.523 (average: 6.546)\n",
      "Train: [299][3/3]\ttraining loss 4.699 (average: 6.415)\n",
      "Test: [0/2]\tval Loss: 5.8858 (val loss average: 5.8858)\n",
      "Test: [1/2]\tval Loss: 5.7244 (val loss average: 5.8109)\n",
      "Train: [399][1/3]\ttraining loss 6.565 (average: 6.565)\n",
      "Train: [399][2/3]\ttraining loss 6.575 (average: 6.570)\n",
      "Train: [399][3/3]\ttraining loss 4.479 (average: 6.421)\n",
      "Test: [0/2]\tval Loss: 5.9465 (val loss average: 5.9465)\n",
      "Test: [1/2]\tval Loss: 5.6923 (val loss average: 5.8286)\n",
      "Train: [499][1/3]\ttraining loss 6.597 (average: 6.597)\n",
      "Train: [499][2/3]\ttraining loss 6.527 (average: 6.562)\n",
      "Train: [499][3/3]\ttraining loss 4.515 (average: 6.416)\n",
      "Test: [0/2]\tval Loss: 5.8196 (val loss average: 5.8196)\n",
      "Test: [1/2]\tval Loss: 5.7213 (val loss average: 5.7740)\n",
      "Train: [599][1/3]\ttraining loss 6.467 (average: 6.467)\n",
      "Train: [599][2/3]\ttraining loss 6.437 (average: 6.452)\n",
      "Train: [599][3/3]\ttraining loss 4.560 (average: 6.317)\n",
      "Test: [0/2]\tval Loss: 5.9318 (val loss average: 5.9318)\n",
      "Test: [1/2]\tval Loss: 5.7625 (val loss average: 5.8533)\n",
      "Train: [99][1/3]\ttraining loss 6.777 (average: 6.777)\n",
      "Train: [99][2/3]\ttraining loss 6.754 (average: 6.765)\n",
      "Train: [99][3/3]\ttraining loss 4.828 (average: 6.627)\n",
      "Test: [0/2]\tval Loss: 6.0540 (val loss average: 6.0540)\n",
      "Test: [1/2]\tval Loss: 5.8987 (val loss average: 5.9820)\n",
      "Train: [199][1/3]\ttraining loss 6.594 (average: 6.594)\n",
      "Train: [199][2/3]\ttraining loss 6.672 (average: 6.633)\n",
      "Train: [199][3/3]\ttraining loss 4.806 (average: 6.503)\n",
      "Test: [0/2]\tval Loss: 6.0295 (val loss average: 6.0295)\n",
      "Test: [1/2]\tval Loss: 5.8043 (val loss average: 5.9250)\n",
      "Train: [299][1/3]\ttraining loss 6.595 (average: 6.595)\n",
      "Train: [299][2/3]\ttraining loss 6.570 (average: 6.582)\n",
      "Train: [299][3/3]\ttraining loss 4.583 (average: 6.440)\n",
      "Test: [0/2]\tval Loss: 5.9482 (val loss average: 5.9482)\n",
      "Test: [1/2]\tval Loss: 5.7504 (val loss average: 5.8564)\n",
      "Train: [399][1/3]\ttraining loss 6.509 (average: 6.509)\n",
      "Train: [399][2/3]\ttraining loss 6.468 (average: 6.488)\n",
      "Train: [399][3/3]\ttraining loss 4.510 (average: 6.347)\n",
      "Test: [0/2]\tval Loss: 5.9613 (val loss average: 5.9613)\n",
      "Test: [1/2]\tval Loss: 5.6444 (val loss average: 5.8143)\n",
      "Train: [499][1/3]\ttraining loss 6.439 (average: 6.439)\n",
      "Train: [499][2/3]\ttraining loss 6.492 (average: 6.466)\n",
      "Train: [499][3/3]\ttraining loss 4.540 (average: 6.329)\n",
      "Test: [0/2]\tval Loss: 5.9314 (val loss average: 5.9314)\n",
      "Test: [1/2]\tval Loss: 5.8257 (val loss average: 5.8824)\n",
      "Train: [599][1/3]\ttraining loss 6.406 (average: 6.406)\n",
      "Train: [599][2/3]\ttraining loss 6.423 (average: 6.415)\n",
      "Train: [599][3/3]\ttraining loss 4.507 (average: 6.279)\n",
      "Test: [0/2]\tval Loss: 5.9908 (val loss average: 5.9908)\n",
      "Test: [1/2]\tval Loss: 5.8378 (val loss average: 5.9198)\n",
      "Train: [99][1/3]\ttraining loss 6.743 (average: 6.743)\n",
      "Train: [99][2/3]\ttraining loss 6.763 (average: 6.753)\n",
      "Train: [99][3/3]\ttraining loss 4.889 (average: 6.620)\n",
      "Test: [0/2]\tval Loss: 6.0195 (val loss average: 6.0195)\n",
      "Test: [1/2]\tval Loss: 5.8724 (val loss average: 5.9513)\n",
      "Train: [199][1/3]\ttraining loss 6.652 (average: 6.652)\n",
      "Train: [199][2/3]\ttraining loss 6.629 (average: 6.641)\n",
      "Train: [199][3/3]\ttraining loss 4.830 (average: 6.512)\n",
      "Test: [0/2]\tval Loss: 5.8600 (val loss average: 5.8600)\n",
      "Test: [1/2]\tval Loss: 5.6640 (val loss average: 5.7691)\n",
      "Train: [299][1/3]\ttraining loss 6.564 (average: 6.564)\n",
      "Train: [299][2/3]\ttraining loss 6.539 (average: 6.552)\n",
      "Train: [299][3/3]\ttraining loss 4.705 (average: 6.420)\n",
      "Test: [0/2]\tval Loss: 5.8612 (val loss average: 5.8612)\n",
      "Test: [1/2]\tval Loss: 5.5991 (val loss average: 5.7396)\n",
      "Train: [399][1/3]\ttraining loss 6.524 (average: 6.524)\n",
      "Train: [399][2/3]\ttraining loss 6.546 (average: 6.535)\n",
      "Train: [399][3/3]\ttraining loss 4.607 (average: 6.398)\n",
      "Test: [0/2]\tval Loss: 5.7575 (val loss average: 5.7575)\n",
      "Test: [1/2]\tval Loss: 5.5816 (val loss average: 5.6759)\n",
      "Train: [499][1/3]\ttraining loss 6.476 (average: 6.476)\n",
      "Train: [499][2/3]\ttraining loss 6.485 (average: 6.480)\n",
      "Train: [499][3/3]\ttraining loss 4.584 (average: 6.345)\n",
      "Test: [0/2]\tval Loss: 5.7475 (val loss average: 5.7475)\n",
      "Test: [1/2]\tval Loss: 5.7235 (val loss average: 5.7364)\n",
      "Train: [599][1/3]\ttraining loss 6.460 (average: 6.460)\n",
      "Train: [599][2/3]\ttraining loss 6.491 (average: 6.475)\n",
      "Train: [599][3/3]\ttraining loss 4.516 (average: 6.336)\n",
      "Test: [0/2]\tval Loss: 5.7052 (val loss average: 5.7052)\n",
      "Test: [1/2]\tval Loss: 5.7149 (val loss average: 5.7097)\n",
      "Train: [99][1/3]\ttraining loss 6.792 (average: 6.792)\n",
      "Train: [99][2/3]\ttraining loss 6.782 (average: 6.787)\n",
      "Train: [99][3/3]\ttraining loss 4.823 (average: 6.647)\n",
      "Test: [0/2]\tval Loss: 6.0485 (val loss average: 6.0485)\n",
      "Test: [1/2]\tval Loss: 5.9126 (val loss average: 5.9855)\n",
      "Train: [199][1/3]\ttraining loss 6.655 (average: 6.655)\n",
      "Train: [199][2/3]\ttraining loss 6.708 (average: 6.681)\n",
      "Train: [199][3/3]\ttraining loss 4.783 (average: 6.546)\n",
      "Test: [0/2]\tval Loss: 5.9748 (val loss average: 5.9748)\n",
      "Test: [1/2]\tval Loss: 5.8208 (val loss average: 5.9033)\n",
      "Train: [299][1/3]\ttraining loss 6.545 (average: 6.545)\n",
      "Train: [299][2/3]\ttraining loss 6.574 (average: 6.559)\n",
      "Train: [299][3/3]\ttraining loss 4.643 (average: 6.423)\n",
      "Test: [0/2]\tval Loss: 5.9288 (val loss average: 5.9288)\n",
      "Test: [1/2]\tval Loss: 5.7094 (val loss average: 5.8270)\n",
      "Train: [399][1/3]\ttraining loss 6.512 (average: 6.512)\n",
      "Train: [399][2/3]\ttraining loss 6.535 (average: 6.524)\n",
      "Train: [399][3/3]\ttraining loss 4.719 (average: 6.395)\n",
      "Test: [0/2]\tval Loss: 5.8657 (val loss average: 5.8657)\n",
      "Test: [1/2]\tval Loss: 5.8361 (val loss average: 5.8520)\n",
      "Train: [499][1/3]\ttraining loss 6.504 (average: 6.504)\n",
      "Train: [499][2/3]\ttraining loss 6.495 (average: 6.499)\n",
      "Train: [499][3/3]\ttraining loss 4.572 (average: 6.362)\n",
      "Test: [0/2]\tval Loss: 5.8988 (val loss average: 5.8988)\n",
      "Test: [1/2]\tval Loss: 5.7134 (val loss average: 5.8128)\n",
      "Train: [599][1/3]\ttraining loss 6.489 (average: 6.489)\n",
      "Train: [599][2/3]\ttraining loss 6.467 (average: 6.478)\n",
      "Train: [599][3/3]\ttraining loss 4.479 (average: 6.335)\n",
      "Test: [0/2]\tval Loss: 5.9168 (val loss average: 5.9168)\n",
      "Test: [1/2]\tval Loss: 5.7923 (val loss average: 5.8591)\n",
      "Train: [99][1/3]\ttraining loss 6.790 (average: 6.790)\n",
      "Train: [99][2/3]\ttraining loss 6.788 (average: 6.789)\n",
      "Train: [99][3/3]\ttraining loss 4.851 (average: 6.651)\n",
      "Test: [0/2]\tval Loss: 6.0466 (val loss average: 6.0466)\n",
      "Test: [1/2]\tval Loss: 5.8634 (val loss average: 5.9616)\n",
      "Train: [199][1/3]\ttraining loss 6.667 (average: 6.667)\n",
      "Train: [199][2/3]\ttraining loss 6.672 (average: 6.669)\n",
      "Train: [199][3/3]\ttraining loss 4.765 (average: 6.534)\n",
      "Test: [0/2]\tval Loss: 5.9374 (val loss average: 5.9374)\n",
      "Test: [1/2]\tval Loss: 5.8051 (val loss average: 5.8760)\n",
      "Train: [299][1/3]\ttraining loss 6.635 (average: 6.635)\n",
      "Train: [299][2/3]\ttraining loss 6.600 (average: 6.617)\n",
      "Train: [299][3/3]\ttraining loss 4.696 (average: 6.481)\n",
      "Test: [0/2]\tval Loss: 5.9507 (val loss average: 5.9507)\n",
      "Test: [1/2]\tval Loss: 5.7819 (val loss average: 5.8724)\n",
      "Train: [399][1/3]\ttraining loss 6.596 (average: 6.596)\n",
      "Train: [399][2/3]\ttraining loss 6.595 (average: 6.595)\n",
      "Train: [399][3/3]\ttraining loss 4.599 (average: 6.453)\n",
      "Test: [0/2]\tval Loss: 5.9119 (val loss average: 5.9119)\n",
      "Test: [1/2]\tval Loss: 5.7394 (val loss average: 5.8319)\n",
      "Train: [499][1/3]\ttraining loss 6.464 (average: 6.464)\n",
      "Train: [499][2/3]\ttraining loss 6.535 (average: 6.500)\n",
      "Train: [499][3/3]\ttraining loss 4.447 (average: 6.353)\n",
      "Test: [0/2]\tval Loss: 5.9066 (val loss average: 5.9066)\n",
      "Test: [1/2]\tval Loss: 5.7056 (val loss average: 5.8133)\n",
      "Train: [599][1/3]\ttraining loss 6.540 (average: 6.540)\n",
      "Train: [599][2/3]\ttraining loss 6.479 (average: 6.509)\n",
      "Train: [599][3/3]\ttraining loss 4.600 (average: 6.373)\n",
      "Test: [0/2]\tval Loss: 5.9304 (val loss average: 5.9304)\n",
      "Test: [1/2]\tval Loss: 5.6952 (val loss average: 5.8213)\n",
      "Train: [699][1/3]\ttraining loss 6.412 (average: 6.412)\n",
      "Train: [699][2/3]\ttraining loss 6.431 (average: 6.422)\n",
      "Train: [699][3/3]\ttraining loss 4.638 (average: 6.295)\n",
      "Test: [0/2]\tval Loss: 5.9319 (val loss average: 5.9319)\n",
      "Test: [1/2]\tval Loss: 5.6725 (val loss average: 5.8116)\n",
      "Train: [799][1/3]\ttraining loss 6.408 (average: 6.408)\n",
      "Train: [799][2/3]\ttraining loss 6.460 (average: 6.434)\n",
      "Train: [799][3/3]\ttraining loss 4.368 (average: 6.287)\n",
      "Test: [0/2]\tval Loss: 5.8298 (val loss average: 5.8298)\n",
      "Test: [1/2]\tval Loss: 5.7900 (val loss average: 5.8114)\n",
      "Train: [99][1/3]\ttraining loss 6.772 (average: 6.772)\n",
      "Train: [99][2/3]\ttraining loss 6.752 (average: 6.762)\n",
      "Train: [99][3/3]\ttraining loss 4.762 (average: 6.620)\n",
      "Test: [0/2]\tval Loss: 5.9983 (val loss average: 5.9983)\n",
      "Test: [1/2]\tval Loss: 5.8967 (val loss average: 5.9511)\n",
      "Train: [199][1/3]\ttraining loss 6.672 (average: 6.672)\n",
      "Train: [199][2/3]\ttraining loss 6.610 (average: 6.641)\n",
      "Train: [199][3/3]\ttraining loss 4.803 (average: 6.510)\n",
      "Test: [0/2]\tval Loss: 5.9357 (val loss average: 5.9357)\n",
      "Test: [1/2]\tval Loss: 5.8655 (val loss average: 5.9031)\n",
      "Train: [299][1/3]\ttraining loss 6.542 (average: 6.542)\n",
      "Train: [299][2/3]\ttraining loss 6.540 (average: 6.541)\n",
      "Train: [299][3/3]\ttraining loss 4.607 (average: 6.404)\n",
      "Test: [0/2]\tval Loss: 5.9821 (val loss average: 5.9821)\n",
      "Test: [1/2]\tval Loss: 5.7629 (val loss average: 5.8804)\n",
      "Train: [399][1/3]\ttraining loss 6.589 (average: 6.589)\n",
      "Train: [399][2/3]\ttraining loss 6.561 (average: 6.575)\n",
      "Train: [399][3/3]\ttraining loss 4.563 (average: 6.432)\n",
      "Test: [0/2]\tval Loss: 5.9156 (val loss average: 5.9156)\n",
      "Test: [1/2]\tval Loss: 5.6944 (val loss average: 5.8130)\n",
      "Train: [499][1/3]\ttraining loss 6.507 (average: 6.507)\n",
      "Train: [499][2/3]\ttraining loss 6.517 (average: 6.512)\n",
      "Train: [499][3/3]\ttraining loss 4.580 (average: 6.375)\n",
      "Test: [0/2]\tval Loss: 5.9333 (val loss average: 5.9333)\n",
      "Test: [1/2]\tval Loss: 5.7804 (val loss average: 5.8624)\n",
      "Train: [599][1/3]\ttraining loss 6.498 (average: 6.498)\n",
      "Train: [599][2/3]\ttraining loss 6.570 (average: 6.534)\n",
      "Train: [599][3/3]\ttraining loss 4.645 (average: 6.400)\n",
      "Test: [0/2]\tval Loss: 5.9632 (val loss average: 5.9632)\n",
      "Test: [1/2]\tval Loss: 5.6957 (val loss average: 5.8391)\n",
      "Train: [99][1/3]\ttraining loss 6.767 (average: 6.767)\n",
      "Train: [99][2/3]\ttraining loss 6.783 (average: 6.775)\n",
      "Train: [99][3/3]\ttraining loss 4.894 (average: 6.641)\n",
      "Test: [0/2]\tval Loss: 6.0333 (val loss average: 6.0333)\n",
      "Test: [1/2]\tval Loss: 5.8881 (val loss average: 5.9660)\n",
      "Train: [199][1/3]\ttraining loss 6.657 (average: 6.657)\n",
      "Train: [199][2/3]\ttraining loss 6.660 (average: 6.659)\n",
      "Train: [199][3/3]\ttraining loss 4.695 (average: 6.519)\n",
      "Test: [0/2]\tval Loss: 5.9710 (val loss average: 5.9710)\n",
      "Test: [1/2]\tval Loss: 5.8718 (val loss average: 5.9250)\n",
      "Train: [299][1/3]\ttraining loss 6.564 (average: 6.564)\n",
      "Train: [299][2/3]\ttraining loss 6.571 (average: 6.568)\n",
      "Train: [299][3/3]\ttraining loss 4.728 (average: 6.437)\n",
      "Test: [0/2]\tval Loss: 5.9198 (val loss average: 5.9198)\n",
      "Test: [1/2]\tval Loss: 5.7341 (val loss average: 5.8336)\n",
      "Train: [399][1/3]\ttraining loss 6.483 (average: 6.483)\n",
      "Train: [399][2/3]\ttraining loss 6.509 (average: 6.496)\n",
      "Train: [399][3/3]\ttraining loss 4.573 (average: 6.359)\n",
      "Test: [0/2]\tval Loss: 5.8608 (val loss average: 5.8608)\n",
      "Test: [1/2]\tval Loss: 5.6447 (val loss average: 5.7605)\n",
      "Train: [499][1/3]\ttraining loss 6.480 (average: 6.480)\n",
      "Train: [499][2/3]\ttraining loss 6.466 (average: 6.473)\n",
      "Train: [499][3/3]\ttraining loss 4.656 (average: 6.344)\n",
      "Test: [0/2]\tval Loss: 5.7899 (val loss average: 5.7899)\n",
      "Test: [1/2]\tval Loss: 5.7583 (val loss average: 5.7752)\n",
      "Train: [599][1/3]\ttraining loss 6.427 (average: 6.427)\n",
      "Train: [599][2/3]\ttraining loss 6.431 (average: 6.429)\n",
      "Train: [599][3/3]\ttraining loss 4.444 (average: 6.288)\n",
      "Test: [0/2]\tval Loss: 5.7631 (val loss average: 5.7631)\n",
      "Test: [1/2]\tval Loss: 5.6558 (val loss average: 5.7133)\n",
      "Train: [99][1/3]\ttraining loss 6.774 (average: 6.774)\n",
      "Train: [99][2/3]\ttraining loss 6.778 (average: 6.776)\n",
      "Train: [99][3/3]\ttraining loss 4.898 (average: 6.642)\n",
      "Test: [0/2]\tval Loss: 6.0257 (val loss average: 6.0257)\n",
      "Test: [1/2]\tval Loss: 5.8826 (val loss average: 5.9593)\n",
      "Train: [199][1/3]\ttraining loss 6.704 (average: 6.704)\n",
      "Train: [199][2/3]\ttraining loss 6.671 (average: 6.688)\n",
      "Train: [199][3/3]\ttraining loss 4.795 (average: 6.553)\n",
      "Test: [0/2]\tval Loss: 5.9603 (val loss average: 5.9603)\n",
      "Test: [1/2]\tval Loss: 5.7938 (val loss average: 5.8831)\n",
      "Train: [299][1/3]\ttraining loss 6.590 (average: 6.590)\n",
      "Train: [299][2/3]\ttraining loss 6.619 (average: 6.604)\n",
      "Train: [299][3/3]\ttraining loss 4.697 (average: 6.469)\n",
      "Test: [0/2]\tval Loss: 5.8400 (val loss average: 5.8400)\n",
      "Test: [1/2]\tval Loss: 5.8561 (val loss average: 5.8475)\n",
      "Train: [399][1/3]\ttraining loss 6.541 (average: 6.541)\n",
      "Train: [399][2/3]\ttraining loss 6.550 (average: 6.545)\n",
      "Train: [399][3/3]\ttraining loss 4.804 (average: 6.421)\n",
      "Test: [0/2]\tval Loss: 5.8943 (val loss average: 5.8943)\n",
      "Test: [1/2]\tval Loss: 5.7145 (val loss average: 5.8109)\n",
      "Train: [499][1/3]\ttraining loss 6.545 (average: 6.545)\n",
      "Train: [499][2/3]\ttraining loss 6.606 (average: 6.576)\n",
      "Train: [499][3/3]\ttraining loss 4.744 (average: 6.445)\n",
      "Test: [0/2]\tval Loss: 5.9508 (val loss average: 5.9508)\n",
      "Test: [1/2]\tval Loss: 5.7984 (val loss average: 5.8801)\n",
      "Train: [599][1/3]\ttraining loss 6.553 (average: 6.553)\n",
      "Train: [599][2/3]\ttraining loss 6.489 (average: 6.521)\n",
      "Train: [599][3/3]\ttraining loss 4.606 (average: 6.384)\n",
      "Test: [0/2]\tval Loss: 5.9187 (val loss average: 5.9187)\n",
      "Test: [1/2]\tval Loss: 5.8062 (val loss average: 5.8665)\n",
      "Train: [99][1/3]\ttraining loss 6.774 (average: 6.774)\n",
      "Train: [99][2/3]\ttraining loss 6.763 (average: 6.768)\n",
      "Train: [99][3/3]\ttraining loss 4.849 (average: 6.632)\n",
      "Test: [0/2]\tval Loss: 5.9735 (val loss average: 5.9735)\n",
      "Test: [1/2]\tval Loss: 5.8506 (val loss average: 5.9165)\n",
      "Train: [199][1/3]\ttraining loss 6.634 (average: 6.634)\n",
      "Train: [199][2/3]\ttraining loss 6.602 (average: 6.618)\n",
      "Train: [199][3/3]\ttraining loss 4.774 (average: 6.487)\n",
      "Test: [0/2]\tval Loss: 5.8924 (val loss average: 5.8924)\n",
      "Test: [1/2]\tval Loss: 5.7252 (val loss average: 5.8148)\n",
      "Train: [299][1/3]\ttraining loss 6.583 (average: 6.583)\n",
      "Train: [299][2/3]\ttraining loss 6.579 (average: 6.581)\n",
      "Train: [299][3/3]\ttraining loss 4.534 (average: 6.435)\n",
      "Test: [0/2]\tval Loss: 5.8945 (val loss average: 5.8945)\n",
      "Test: [1/2]\tval Loss: 5.8068 (val loss average: 5.8538)\n",
      "Train: [399][1/3]\ttraining loss 6.514 (average: 6.514)\n",
      "Train: [399][2/3]\ttraining loss 6.541 (average: 6.528)\n",
      "Train: [399][3/3]\ttraining loss 4.746 (average: 6.401)\n",
      "Test: [0/2]\tval Loss: 5.9117 (val loss average: 5.9117)\n",
      "Test: [1/2]\tval Loss: 5.7718 (val loss average: 5.8468)\n",
      "Train: [499][1/3]\ttraining loss 6.484 (average: 6.484)\n",
      "Train: [499][2/3]\ttraining loss 6.513 (average: 6.498)\n",
      "Train: [499][3/3]\ttraining loss 4.745 (average: 6.374)\n",
      "Test: [0/2]\tval Loss: 5.8071 (val loss average: 5.8071)\n",
      "Test: [1/2]\tval Loss: 5.7797 (val loss average: 5.7944)\n",
      "Train: [599][1/3]\ttraining loss 6.499 (average: 6.499)\n",
      "Train: [599][2/3]\ttraining loss 6.556 (average: 6.528)\n",
      "Train: [599][3/3]\ttraining loss 4.602 (average: 6.390)\n",
      "Test: [0/2]\tval Loss: 5.9298 (val loss average: 5.9298)\n",
      "Test: [1/2]\tval Loss: 5.7085 (val loss average: 5.8271)\n",
      "Train: [99][1/3]\ttraining loss 6.770 (average: 6.770)\n",
      "Train: [99][2/3]\ttraining loss 6.766 (average: 6.768)\n",
      "Train: [99][3/3]\ttraining loss 4.834 (average: 6.630)\n",
      "Test: [0/2]\tval Loss: 6.0358 (val loss average: 6.0358)\n",
      "Test: [1/2]\tval Loss: 5.8926 (val loss average: 5.9693)\n",
      "Train: [199][1/3]\ttraining loss 6.628 (average: 6.628)\n",
      "Train: [199][2/3]\ttraining loss 6.617 (average: 6.622)\n",
      "Train: [199][3/3]\ttraining loss 4.828 (average: 6.495)\n",
      "Test: [0/2]\tval Loss: 5.9955 (val loss average: 5.9955)\n",
      "Test: [1/2]\tval Loss: 5.7921 (val loss average: 5.9011)\n",
      "Train: [299][1/3]\ttraining loss 6.625 (average: 6.625)\n",
      "Train: [299][2/3]\ttraining loss 6.581 (average: 6.603)\n",
      "Train: [299][3/3]\ttraining loss 4.597 (average: 6.460)\n",
      "Test: [0/2]\tval Loss: 5.9368 (val loss average: 5.9368)\n",
      "Test: [1/2]\tval Loss: 5.7723 (val loss average: 5.8605)\n",
      "Train: [399][1/3]\ttraining loss 6.507 (average: 6.507)\n",
      "Train: [399][2/3]\ttraining loss 6.493 (average: 6.500)\n",
      "Train: [399][3/3]\ttraining loss 4.550 (average: 6.361)\n",
      "Test: [0/2]\tval Loss: 5.9130 (val loss average: 5.9130)\n",
      "Test: [1/2]\tval Loss: 5.7682 (val loss average: 5.8458)\n",
      "Train: [499][1/3]\ttraining loss 6.587 (average: 6.587)\n",
      "Train: [499][2/3]\ttraining loss 6.528 (average: 6.558)\n",
      "Train: [499][3/3]\ttraining loss 4.535 (average: 6.414)\n",
      "Test: [0/2]\tval Loss: 5.9410 (val loss average: 5.9410)\n",
      "Test: [1/2]\tval Loss: 5.8217 (val loss average: 5.8857)\n",
      "Train: [599][1/3]\ttraining loss 6.460 (average: 6.460)\n",
      "Train: [599][2/3]\ttraining loss 6.538 (average: 6.499)\n",
      "Train: [599][3/3]\ttraining loss 4.596 (average: 6.363)\n",
      "Test: [0/2]\tval Loss: 5.9481 (val loss average: 5.9481)\n",
      "Test: [1/2]\tval Loss: 5.7319 (val loss average: 5.8478)\n",
      "Train: [99][1/3]\ttraining loss 6.775 (average: 6.775)\n",
      "Train: [99][2/3]\ttraining loss 6.748 (average: 6.762)\n",
      "Train: [99][3/3]\ttraining loss 4.798 (average: 6.622)\n",
      "Test: [0/2]\tval Loss: 5.9791 (val loss average: 5.9791)\n",
      "Test: [1/2]\tval Loss: 5.8310 (val loss average: 5.9104)\n",
      "Train: [199][1/3]\ttraining loss 6.682 (average: 6.682)\n",
      "Train: [199][2/3]\ttraining loss 6.668 (average: 6.675)\n",
      "Train: [199][3/3]\ttraining loss 4.753 (average: 6.538)\n",
      "Test: [0/2]\tval Loss: 5.8917 (val loss average: 5.8917)\n",
      "Test: [1/2]\tval Loss: 5.7629 (val loss average: 5.8319)\n",
      "Train: [299][1/3]\ttraining loss 6.563 (average: 6.563)\n",
      "Train: [299][2/3]\ttraining loss 6.546 (average: 6.555)\n",
      "Train: [299][3/3]\ttraining loss 4.800 (average: 6.430)\n",
      "Test: [0/2]\tval Loss: 5.8193 (val loss average: 5.8193)\n",
      "Test: [1/2]\tval Loss: 5.7106 (val loss average: 5.7688)\n",
      "Train: [399][1/3]\ttraining loss 6.478 (average: 6.478)\n",
      "Train: [399][2/3]\ttraining loss 6.500 (average: 6.489)\n",
      "Train: [399][3/3]\ttraining loss 4.577 (average: 6.353)\n",
      "Test: [0/2]\tval Loss: 5.8225 (val loss average: 5.8225)\n",
      "Test: [1/2]\tval Loss: 5.6802 (val loss average: 5.7565)\n",
      "Train: [499][1/3]\ttraining loss 6.426 (average: 6.426)\n",
      "Train: [499][2/3]\ttraining loss 6.508 (average: 6.467)\n",
      "Train: [499][3/3]\ttraining loss 4.622 (average: 6.336)\n",
      "Test: [0/2]\tval Loss: 5.8571 (val loss average: 5.8571)\n",
      "Test: [1/2]\tval Loss: 5.7779 (val loss average: 5.8203)\n",
      "Train: [599][1/3]\ttraining loss 6.430 (average: 6.430)\n",
      "Train: [599][2/3]\ttraining loss 6.524 (average: 6.477)\n",
      "Train: [599][3/3]\ttraining loss 4.440 (average: 6.332)\n",
      "Test: [0/2]\tval Loss: 5.8332 (val loss average: 5.8332)\n",
      "Test: [1/2]\tval Loss: 5.6523 (val loss average: 5.7493)\n",
      "Train: [99][1/3]\ttraining loss 6.776 (average: 6.776)\n",
      "Train: [99][2/3]\ttraining loss 6.770 (average: 6.773)\n",
      "Train: [99][3/3]\ttraining loss 4.910 (average: 6.640)\n",
      "Test: [0/2]\tval Loss: 6.0461 (val loss average: 6.0461)\n",
      "Test: [1/2]\tval Loss: 5.8731 (val loss average: 5.9658)\n",
      "Train: [199][1/3]\ttraining loss 6.664 (average: 6.664)\n",
      "Train: [199][2/3]\ttraining loss 6.670 (average: 6.667)\n",
      "Train: [199][3/3]\ttraining loss 4.718 (average: 6.528)\n",
      "Test: [0/2]\tval Loss: 5.9536 (val loss average: 5.9536)\n",
      "Test: [1/2]\tval Loss: 5.7880 (val loss average: 5.8768)\n",
      "Train: [299][1/3]\ttraining loss 6.557 (average: 6.557)\n",
      "Train: [299][2/3]\ttraining loss 6.537 (average: 6.547)\n",
      "Train: [299][3/3]\ttraining loss 4.545 (average: 6.404)\n",
      "Test: [0/2]\tval Loss: 5.8850 (val loss average: 5.8850)\n",
      "Test: [1/2]\tval Loss: 5.8025 (val loss average: 5.8467)\n",
      "Train: [399][1/3]\ttraining loss 6.543 (average: 6.543)\n",
      "Train: [399][2/3]\ttraining loss 6.526 (average: 6.535)\n",
      "Train: [399][3/3]\ttraining loss 4.573 (average: 6.395)\n",
      "Test: [0/2]\tval Loss: 5.9196 (val loss average: 5.9196)\n",
      "Test: [1/2]\tval Loss: 5.8771 (val loss average: 5.8999)\n",
      "Train: [499][1/3]\ttraining loss 6.517 (average: 6.517)\n",
      "Train: [499][2/3]\ttraining loss 6.456 (average: 6.487)\n",
      "Train: [499][3/3]\ttraining loss 4.714 (average: 6.360)\n",
      "Test: [0/2]\tval Loss: 5.9553 (val loss average: 5.9553)\n",
      "Test: [1/2]\tval Loss: 5.7002 (val loss average: 5.8369)\n",
      "Train: [599][1/3]\ttraining loss 6.470 (average: 6.470)\n",
      "Train: [599][2/3]\ttraining loss 6.508 (average: 6.489)\n",
      "Train: [599][3/3]\ttraining loss 4.626 (average: 6.357)\n",
      "Test: [0/2]\tval Loss: 5.7424 (val loss average: 5.7424)\n",
      "Test: [1/2]\tval Loss: 5.7859 (val loss average: 5.7626)\n",
      "Train: [99][1/3]\ttraining loss 6.800 (average: 6.800)\n",
      "Train: [99][2/3]\ttraining loss 6.799 (average: 6.799)\n",
      "Train: [99][3/3]\ttraining loss 4.884 (average: 6.663)\n",
      "Test: [0/2]\tval Loss: 6.0080 (val loss average: 6.0080)\n",
      "Test: [1/2]\tval Loss: 5.9174 (val loss average: 5.9660)\n",
      "Train: [199][1/3]\ttraining loss 6.704 (average: 6.704)\n",
      "Train: [199][2/3]\ttraining loss 6.695 (average: 6.700)\n",
      "Train: [199][3/3]\ttraining loss 4.789 (average: 6.564)\n",
      "Test: [0/2]\tval Loss: 5.9548 (val loss average: 5.9548)\n",
      "Test: [1/2]\tval Loss: 5.7996 (val loss average: 5.8828)\n",
      "Train: [299][1/3]\ttraining loss 6.594 (average: 6.594)\n",
      "Train: [299][2/3]\ttraining loss 6.702 (average: 6.648)\n",
      "Train: [299][3/3]\ttraining loss 4.708 (average: 6.510)\n",
      "Test: [0/2]\tval Loss: 5.8807 (val loss average: 5.8807)\n",
      "Test: [1/2]\tval Loss: 5.7325 (val loss average: 5.8120)\n",
      "Train: [399][1/3]\ttraining loss 6.626 (average: 6.626)\n",
      "Train: [399][2/3]\ttraining loss 6.619 (average: 6.623)\n",
      "Train: [399][3/3]\ttraining loss 4.641 (average: 6.482)\n",
      "Test: [0/2]\tval Loss: 5.8682 (val loss average: 5.8682)\n",
      "Test: [1/2]\tval Loss: 5.8535 (val loss average: 5.8614)\n",
      "Train: [499][1/3]\ttraining loss 6.520 (average: 6.520)\n",
      "Train: [499][2/3]\ttraining loss 6.507 (average: 6.514)\n",
      "Train: [499][3/3]\ttraining loss 4.675 (average: 6.383)\n",
      "Test: [0/2]\tval Loss: 5.9104 (val loss average: 5.9104)\n",
      "Test: [1/2]\tval Loss: 5.7118 (val loss average: 5.8182)\n",
      "Train: [599][1/3]\ttraining loss 6.556 (average: 6.556)\n",
      "Train: [599][2/3]\ttraining loss 6.524 (average: 6.540)\n",
      "Train: [599][3/3]\ttraining loss 4.678 (average: 6.407)\n",
      "Test: [0/2]\tval Loss: 5.8995 (val loss average: 5.8995)\n",
      "Test: [1/2]\tval Loss: 5.7995 (val loss average: 5.8531)\n",
      "Train: [99][1/3]\ttraining loss 6.775 (average: 6.775)\n",
      "Train: [99][2/3]\ttraining loss 6.790 (average: 6.782)\n",
      "Train: [99][3/3]\ttraining loss 4.893 (average: 6.648)\n",
      "Test: [0/2]\tval Loss: 6.0268 (val loss average: 6.0268)\n",
      "Test: [1/2]\tval Loss: 5.8742 (val loss average: 5.9560)\n",
      "Train: [199][1/3]\ttraining loss 6.632 (average: 6.632)\n",
      "Train: [199][2/3]\ttraining loss 6.650 (average: 6.641)\n",
      "Train: [199][3/3]\ttraining loss 4.775 (average: 6.508)\n",
      "Test: [0/2]\tval Loss: 6.0130 (val loss average: 6.0130)\n",
      "Test: [1/2]\tval Loss: 5.8826 (val loss average: 5.9525)\n",
      "Train: [299][1/3]\ttraining loss 6.464 (average: 6.464)\n",
      "Train: [299][2/3]\ttraining loss 6.567 (average: 6.516)\n",
      "Train: [299][3/3]\ttraining loss 4.729 (average: 6.389)\n",
      "Test: [0/2]\tval Loss: 5.9044 (val loss average: 5.9044)\n",
      "Test: [1/2]\tval Loss: 5.7723 (val loss average: 5.8431)\n",
      "Train: [399][1/3]\ttraining loss 6.576 (average: 6.576)\n",
      "Train: [399][2/3]\ttraining loss 6.555 (average: 6.566)\n",
      "Train: [399][3/3]\ttraining loss 4.749 (average: 6.436)\n",
      "Test: [0/2]\tval Loss: 5.8050 (val loss average: 5.8050)\n",
      "Test: [1/2]\tval Loss: 5.7202 (val loss average: 5.7657)\n",
      "Train: [499][1/3]\ttraining loss 6.483 (average: 6.483)\n",
      "Train: [499][2/3]\ttraining loss 6.514 (average: 6.498)\n",
      "Train: [499][3/3]\ttraining loss 4.604 (average: 6.363)\n",
      "Test: [0/2]\tval Loss: 5.8287 (val loss average: 5.8287)\n",
      "Test: [1/2]\tval Loss: 5.7378 (val loss average: 5.7865)\n",
      "Train: [599][1/3]\ttraining loss 6.492 (average: 6.492)\n",
      "Train: [599][2/3]\ttraining loss 6.409 (average: 6.451)\n",
      "Train: [599][3/3]\ttraining loss 4.698 (average: 6.326)\n",
      "Test: [0/2]\tval Loss: 5.8514 (val loss average: 5.8514)\n",
      "Test: [1/2]\tval Loss: 5.6083 (val loss average: 5.7386)\n",
      "Train: [99][1/3]\ttraining loss 6.760 (average: 6.760)\n",
      "Train: [99][2/3]\ttraining loss 6.755 (average: 6.757)\n",
      "Train: [99][3/3]\ttraining loss 4.860 (average: 6.622)\n",
      "Test: [0/2]\tval Loss: 6.0486 (val loss average: 6.0486)\n",
      "Test: [1/2]\tval Loss: 5.8666 (val loss average: 5.9642)\n",
      "Train: [199][1/3]\ttraining loss 6.607 (average: 6.607)\n",
      "Train: [199][2/3]\ttraining loss 6.626 (average: 6.616)\n",
      "Train: [199][3/3]\ttraining loss 4.585 (average: 6.472)\n",
      "Test: [0/2]\tval Loss: 5.9914 (val loss average: 5.9914)\n",
      "Test: [1/2]\tval Loss: 5.8066 (val loss average: 5.9057)\n",
      "Train: [299][1/3]\ttraining loss 6.599 (average: 6.599)\n",
      "Train: [299][2/3]\ttraining loss 6.490 (average: 6.545)\n",
      "Train: [299][3/3]\ttraining loss 4.505 (average: 6.399)\n",
      "Test: [0/2]\tval Loss: 5.9475 (val loss average: 5.9475)\n",
      "Test: [1/2]\tval Loss: 5.7273 (val loss average: 5.8453)\n",
      "Train: [399][1/3]\ttraining loss 6.530 (average: 6.530)\n",
      "Train: [399][2/3]\ttraining loss 6.583 (average: 6.556)\n",
      "Train: [399][3/3]\ttraining loss 4.846 (average: 6.434)\n",
      "Test: [0/2]\tval Loss: 5.8796 (val loss average: 5.8796)\n",
      "Test: [1/2]\tval Loss: 5.7690 (val loss average: 5.8283)\n",
      "Train: [499][1/3]\ttraining loss 6.471 (average: 6.471)\n",
      "Train: [499][2/3]\ttraining loss 6.509 (average: 6.490)\n",
      "Train: [499][3/3]\ttraining loss 4.756 (average: 6.366)\n",
      "Test: [0/2]\tval Loss: 5.9232 (val loss average: 5.9232)\n",
      "Test: [1/2]\tval Loss: 5.6422 (val loss average: 5.7928)\n",
      "Train: [599][1/3]\ttraining loss 6.400 (average: 6.400)\n",
      "Train: [599][2/3]\ttraining loss 6.541 (average: 6.470)\n",
      "Train: [599][3/3]\ttraining loss 4.372 (average: 6.321)\n",
      "Test: [0/2]\tval Loss: 5.8336 (val loss average: 5.8336)\n",
      "Test: [1/2]\tval Loss: 5.7736 (val loss average: 5.8058)\n",
      "Train: [99][1/3]\ttraining loss 6.768 (average: 6.768)\n",
      "Train: [99][2/3]\ttraining loss 6.776 (average: 6.772)\n",
      "Train: [99][3/3]\ttraining loss 4.797 (average: 6.631)\n",
      "Test: [0/2]\tval Loss: 5.9962 (val loss average: 5.9962)\n",
      "Test: [1/2]\tval Loss: 5.8345 (val loss average: 5.9212)\n",
      "Train: [199][1/3]\ttraining loss 6.708 (average: 6.708)\n",
      "Train: [199][2/3]\ttraining loss 6.650 (average: 6.679)\n",
      "Train: [199][3/3]\ttraining loss 4.702 (average: 6.538)\n",
      "Test: [0/2]\tval Loss: 5.9539 (val loss average: 5.9539)\n",
      "Test: [1/2]\tval Loss: 5.7959 (val loss average: 5.8806)\n",
      "Train: [299][1/3]\ttraining loss 6.638 (average: 6.638)\n",
      "Train: [299][2/3]\ttraining loss 6.693 (average: 6.666)\n",
      "Train: [299][3/3]\ttraining loss 4.578 (average: 6.517)\n",
      "Test: [0/2]\tval Loss: 5.9029 (val loss average: 5.9029)\n",
      "Test: [1/2]\tval Loss: 5.7906 (val loss average: 5.8508)\n",
      "Train: [399][1/3]\ttraining loss 6.511 (average: 6.511)\n",
      "Train: [399][2/3]\ttraining loss 6.535 (average: 6.523)\n",
      "Train: [399][3/3]\ttraining loss 4.666 (average: 6.391)\n",
      "Test: [0/2]\tval Loss: 5.9286 (val loss average: 5.9286)\n",
      "Test: [1/2]\tval Loss: 5.6957 (val loss average: 5.8206)\n",
      "Train: [499][1/3]\ttraining loss 6.587 (average: 6.587)\n",
      "Train: [499][2/3]\ttraining loss 6.520 (average: 6.554)\n",
      "Train: [499][3/3]\ttraining loss 4.662 (average: 6.419)\n",
      "Test: [0/2]\tval Loss: 5.9314 (val loss average: 5.9314)\n",
      "Test: [1/2]\tval Loss: 5.7806 (val loss average: 5.8614)\n",
      "Train: [599][1/3]\ttraining loss 6.547 (average: 6.547)\n",
      "Train: [599][2/3]\ttraining loss 6.505 (average: 6.526)\n",
      "Train: [599][3/3]\ttraining loss 4.733 (average: 6.398)\n",
      "Test: [0/2]\tval Loss: 5.8890 (val loss average: 5.8890)\n",
      "Test: [1/2]\tval Loss: 5.7487 (val loss average: 5.8239)\n",
      "Train: [99][1/3]\ttraining loss 6.744 (average: 6.744)\n",
      "Train: [99][2/3]\ttraining loss 6.727 (average: 6.735)\n",
      "Train: [99][3/3]\ttraining loss 4.848 (average: 6.601)\n",
      "Test: [0/2]\tval Loss: 6.0194 (val loss average: 6.0194)\n",
      "Test: [1/2]\tval Loss: 5.8859 (val loss average: 5.9574)\n",
      "Train: [199][1/3]\ttraining loss 6.646 (average: 6.646)\n",
      "Train: [199][2/3]\ttraining loss 6.620 (average: 6.633)\n",
      "Train: [199][3/3]\ttraining loss 4.751 (average: 6.499)\n",
      "Test: [0/2]\tval Loss: 5.8967 (val loss average: 5.8967)\n",
      "Test: [1/2]\tval Loss: 5.7670 (val loss average: 5.8365)\n",
      "Train: [299][1/3]\ttraining loss 6.628 (average: 6.628)\n",
      "Train: [299][2/3]\ttraining loss 6.568 (average: 6.598)\n",
      "Train: [299][3/3]\ttraining loss 4.606 (average: 6.456)\n",
      "Test: [0/2]\tval Loss: 5.8755 (val loss average: 5.8755)\n",
      "Test: [1/2]\tval Loss: 5.7221 (val loss average: 5.8044)\n",
      "Train: [399][1/3]\ttraining loss 6.538 (average: 6.538)\n",
      "Train: [399][2/3]\ttraining loss 6.583 (average: 6.560)\n",
      "Train: [399][3/3]\ttraining loss 4.767 (average: 6.433)\n",
      "Test: [0/2]\tval Loss: 5.8837 (val loss average: 5.8837)\n",
      "Test: [1/2]\tval Loss: 5.7790 (val loss average: 5.8351)\n",
      "Train: [499][1/3]\ttraining loss 6.579 (average: 6.579)\n",
      "Train: [499][2/3]\ttraining loss 6.583 (average: 6.581)\n",
      "Train: [499][3/3]\ttraining loss 4.658 (average: 6.444)\n",
      "Test: [0/2]\tval Loss: 5.9196 (val loss average: 5.9196)\n",
      "Test: [1/2]\tval Loss: 5.6997 (val loss average: 5.8176)\n",
      "Train: [599][1/3]\ttraining loss 6.523 (average: 6.523)\n",
      "Train: [599][2/3]\ttraining loss 6.498 (average: 6.511)\n",
      "Train: [599][3/3]\ttraining loss 4.706 (average: 6.382)\n",
      "Test: [0/2]\tval Loss: 5.8130 (val loss average: 5.8130)\n",
      "Test: [1/2]\tval Loss: 5.7506 (val loss average: 5.7840)\n",
      "Train: [699][1/3]\ttraining loss 6.514 (average: 6.514)\n",
      "Train: [699][2/3]\ttraining loss 6.402 (average: 6.458)\n",
      "Train: [699][3/3]\ttraining loss 4.680 (average: 6.332)\n",
      "Test: [0/2]\tval Loss: 5.8408 (val loss average: 5.8408)\n",
      "Test: [1/2]\tval Loss: 5.7138 (val loss average: 5.7819)\n",
      "Train: [99][1/3]\ttraining loss 6.768 (average: 6.768)\n",
      "Train: [99][2/3]\ttraining loss 6.777 (average: 6.772)\n",
      "Train: [99][3/3]\ttraining loss 4.801 (average: 6.632)\n",
      "Test: [0/2]\tval Loss: 6.0035 (val loss average: 6.0035)\n",
      "Test: [1/2]\tval Loss: 5.8929 (val loss average: 5.9522)\n",
      "Train: [199][1/3]\ttraining loss 6.626 (average: 6.626)\n",
      "Train: [199][2/3]\ttraining loss 6.647 (average: 6.637)\n",
      "Train: [199][3/3]\ttraining loss 4.768 (average: 6.504)\n",
      "Test: [0/2]\tval Loss: 5.9845 (val loss average: 5.9845)\n",
      "Test: [1/2]\tval Loss: 5.8015 (val loss average: 5.8996)\n",
      "Train: [299][1/3]\ttraining loss 6.529 (average: 6.529)\n",
      "Train: [299][2/3]\ttraining loss 6.531 (average: 6.530)\n",
      "Train: [299][3/3]\ttraining loss 4.754 (average: 6.403)\n",
      "Test: [0/2]\tval Loss: 5.9388 (val loss average: 5.9388)\n",
      "Test: [1/2]\tval Loss: 5.7685 (val loss average: 5.8598)\n",
      "Train: [399][1/3]\ttraining loss 6.510 (average: 6.510)\n",
      "Train: [399][2/3]\ttraining loss 6.569 (average: 6.539)\n",
      "Train: [399][3/3]\ttraining loss 4.590 (average: 6.400)\n",
      "Test: [0/2]\tval Loss: 5.8735 (val loss average: 5.8735)\n",
      "Test: [1/2]\tval Loss: 5.7445 (val loss average: 5.8136)\n",
      "Train: [499][1/3]\ttraining loss 6.551 (average: 6.551)\n",
      "Train: [499][2/3]\ttraining loss 6.483 (average: 6.517)\n",
      "Train: [499][3/3]\ttraining loss 4.605 (average: 6.381)\n",
      "Test: [0/2]\tval Loss: 5.9274 (val loss average: 5.9274)\n",
      "Test: [1/2]\tval Loss: 5.7919 (val loss average: 5.8645)\n",
      "Train: [599][1/3]\ttraining loss 6.505 (average: 6.505)\n",
      "Train: [599][2/3]\ttraining loss 6.448 (average: 6.477)\n",
      "Train: [599][3/3]\ttraining loss 4.534 (average: 6.338)\n",
      "Test: [0/2]\tval Loss: 5.9139 (val loss average: 5.9139)\n",
      "Test: [1/2]\tval Loss: 5.8982 (val loss average: 5.9066)\n",
      "Train: [99][1/3]\ttraining loss 6.740 (average: 6.740)\n",
      "Train: [99][2/3]\ttraining loss 6.722 (average: 6.731)\n",
      "Train: [99][3/3]\ttraining loss 4.814 (average: 6.594)\n",
      "Test: [0/2]\tval Loss: 6.0050 (val loss average: 6.0050)\n",
      "Test: [1/2]\tval Loss: 5.8556 (val loss average: 5.9357)\n",
      "Train: [199][1/3]\ttraining loss 6.630 (average: 6.630)\n",
      "Train: [199][2/3]\ttraining loss 6.645 (average: 6.637)\n",
      "Train: [199][3/3]\ttraining loss 4.756 (average: 6.503)\n",
      "Test: [0/2]\tval Loss: 5.9112 (val loss average: 5.9112)\n",
      "Test: [1/2]\tval Loss: 5.7422 (val loss average: 5.8328)\n",
      "Train: [299][1/3]\ttraining loss 6.551 (average: 6.551)\n",
      "Train: [299][2/3]\ttraining loss 6.563 (average: 6.557)\n",
      "Train: [299][3/3]\ttraining loss 4.558 (average: 6.415)\n",
      "Test: [0/2]\tval Loss: 5.7642 (val loss average: 5.7642)\n",
      "Test: [1/2]\tval Loss: 5.5856 (val loss average: 5.6813)\n",
      "Train: [399][1/3]\ttraining loss 6.469 (average: 6.469)\n",
      "Train: [399][2/3]\ttraining loss 6.560 (average: 6.515)\n",
      "Train: [399][3/3]\ttraining loss 4.780 (average: 6.391)\n",
      "Test: [0/2]\tval Loss: 5.8363 (val loss average: 5.8363)\n",
      "Test: [1/2]\tval Loss: 5.6421 (val loss average: 5.7462)\n",
      "Train: [499][1/3]\ttraining loss 6.451 (average: 6.451)\n",
      "Train: [499][2/3]\ttraining loss 6.483 (average: 6.467)\n",
      "Train: [499][3/3]\ttraining loss 4.518 (average: 6.328)\n",
      "Test: [0/2]\tval Loss: 5.7568 (val loss average: 5.7568)\n",
      "Test: [1/2]\tval Loss: 5.6950 (val loss average: 5.7281)\n",
      "Train: [599][1/3]\ttraining loss 6.428 (average: 6.428)\n",
      "Train: [599][2/3]\ttraining loss 6.494 (average: 6.461)\n",
      "Train: [599][3/3]\ttraining loss 4.716 (average: 6.337)\n",
      "Test: [0/2]\tval Loss: 5.8342 (val loss average: 5.8342)\n",
      "Test: [1/2]\tval Loss: 5.6948 (val loss average: 5.7695)\n",
      "Train: [699][1/3]\ttraining loss 6.515 (average: 6.515)\n",
      "Train: [699][2/3]\ttraining loss 6.482 (average: 6.499)\n",
      "Train: [699][3/3]\ttraining loss 4.480 (average: 6.355)\n",
      "Test: [0/2]\tval Loss: 5.9185 (val loss average: 5.9185)\n",
      "Test: [1/2]\tval Loss: 5.8914 (val loss average: 5.9059)\n",
      "Train: [99][1/3]\ttraining loss 6.770 (average: 6.770)\n",
      "Train: [99][2/3]\ttraining loss 6.765 (average: 6.767)\n",
      "Train: [99][3/3]\ttraining loss 4.871 (average: 6.632)\n",
      "Test: [0/2]\tval Loss: 5.9559 (val loss average: 5.9559)\n",
      "Test: [1/2]\tval Loss: 5.8302 (val loss average: 5.8976)\n",
      "Train: [199][1/3]\ttraining loss 6.616 (average: 6.616)\n",
      "Train: [199][2/3]\ttraining loss 6.639 (average: 6.628)\n",
      "Train: [199][3/3]\ttraining loss 4.834 (average: 6.500)\n",
      "Test: [0/2]\tval Loss: 5.9412 (val loss average: 5.9412)\n",
      "Test: [1/2]\tval Loss: 5.7704 (val loss average: 5.8620)\n",
      "Train: [299][1/3]\ttraining loss 6.573 (average: 6.573)\n",
      "Train: [299][2/3]\ttraining loss 6.595 (average: 6.584)\n",
      "Train: [299][3/3]\ttraining loss 4.635 (average: 6.445)\n",
      "Test: [0/2]\tval Loss: 5.8611 (val loss average: 5.8611)\n",
      "Test: [1/2]\tval Loss: 5.7844 (val loss average: 5.8255)\n",
      "Train: [399][1/3]\ttraining loss 6.548 (average: 6.548)\n",
      "Train: [399][2/3]\ttraining loss 6.480 (average: 6.514)\n",
      "Train: [399][3/3]\ttraining loss 4.632 (average: 6.380)\n",
      "Test: [0/2]\tval Loss: 5.8206 (val loss average: 5.8206)\n",
      "Test: [1/2]\tval Loss: 5.7146 (val loss average: 5.7714)\n",
      "Train: [499][1/3]\ttraining loss 6.423 (average: 6.423)\n",
      "Train: [499][2/3]\ttraining loss 6.460 (average: 6.442)\n",
      "Train: [499][3/3]\ttraining loss 4.458 (average: 6.300)\n",
      "Test: [0/2]\tval Loss: 5.9368 (val loss average: 5.9368)\n",
      "Test: [1/2]\tval Loss: 5.7945 (val loss average: 5.8707)\n",
      "Train: [599][1/3]\ttraining loss 6.433 (average: 6.433)\n",
      "Train: [599][2/3]\ttraining loss 6.449 (average: 6.441)\n",
      "Train: [599][3/3]\ttraining loss 4.352 (average: 6.292)\n",
      "Test: [0/2]\tval Loss: 5.9318 (val loss average: 5.9318)\n",
      "Test: [1/2]\tval Loss: 5.7324 (val loss average: 5.8393)\n",
      "Train: [99][1/3]\ttraining loss 6.814 (average: 6.814)\n",
      "Train: [99][2/3]\ttraining loss 6.794 (average: 6.804)\n",
      "Train: [99][3/3]\ttraining loss 4.929 (average: 6.671)\n",
      "Test: [0/2]\tval Loss: 6.0115 (val loss average: 6.0115)\n",
      "Test: [1/2]\tval Loss: 5.8687 (val loss average: 5.9452)\n",
      "Train: [199][1/3]\ttraining loss 6.701 (average: 6.701)\n",
      "Train: [199][2/3]\ttraining loss 6.703 (average: 6.702)\n",
      "Train: [199][3/3]\ttraining loss 4.837 (average: 6.569)\n",
      "Test: [0/2]\tval Loss: 6.0107 (val loss average: 6.0107)\n",
      "Test: [1/2]\tval Loss: 5.8109 (val loss average: 5.9180)\n",
      "Train: [299][1/3]\ttraining loss 6.606 (average: 6.606)\n",
      "Train: [299][2/3]\ttraining loss 6.612 (average: 6.609)\n",
      "Train: [299][3/3]\ttraining loss 4.702 (average: 6.473)\n",
      "Test: [0/2]\tval Loss: 5.8962 (val loss average: 5.8962)\n",
      "Test: [1/2]\tval Loss: 5.7303 (val loss average: 5.8193)\n",
      "Train: [399][1/3]\ttraining loss 6.574 (average: 6.574)\n",
      "Train: [399][2/3]\ttraining loss 6.520 (average: 6.547)\n",
      "Train: [399][3/3]\ttraining loss 4.668 (average: 6.413)\n",
      "Test: [0/2]\tval Loss: 5.8536 (val loss average: 5.8536)\n",
      "Test: [1/2]\tval Loss: 5.7332 (val loss average: 5.7977)\n",
      "Train: [499][1/3]\ttraining loss 6.518 (average: 6.518)\n",
      "Train: [499][2/3]\ttraining loss 6.528 (average: 6.523)\n",
      "Train: [499][3/3]\ttraining loss 4.628 (average: 6.388)\n",
      "Test: [0/2]\tval Loss: 5.8772 (val loss average: 5.8772)\n",
      "Test: [1/2]\tval Loss: 5.6259 (val loss average: 5.7606)\n",
      "Train: [599][1/3]\ttraining loss 6.471 (average: 6.471)\n",
      "Train: [599][2/3]\ttraining loss 6.479 (average: 6.475)\n",
      "Train: [599][3/3]\ttraining loss 4.524 (average: 6.336)\n",
      "Test: [0/2]\tval Loss: 5.8892 (val loss average: 5.8892)\n",
      "Test: [1/2]\tval Loss: 5.6695 (val loss average: 5.7873)\n",
      "Train: [699][1/3]\ttraining loss 6.475 (average: 6.475)\n",
      "Train: [699][2/3]\ttraining loss 6.454 (average: 6.464)\n",
      "Train: [699][3/3]\ttraining loss 4.487 (average: 6.324)\n",
      "Test: [0/2]\tval Loss: 5.8954 (val loss average: 5.8954)\n",
      "Test: [1/2]\tval Loss: 5.7918 (val loss average: 5.8473)\n",
      "Train: [99][1/3]\ttraining loss 6.760 (average: 6.760)\n",
      "Train: [99][2/3]\ttraining loss 6.767 (average: 6.764)\n",
      "Train: [99][3/3]\ttraining loss 4.896 (average: 6.631)\n",
      "Test: [0/2]\tval Loss: 5.9829 (val loss average: 5.9829)\n",
      "Test: [1/2]\tval Loss: 5.8223 (val loss average: 5.9084)\n",
      "Train: [199][1/3]\ttraining loss 6.681 (average: 6.681)\n",
      "Train: [199][2/3]\ttraining loss 6.584 (average: 6.633)\n",
      "Train: [199][3/3]\ttraining loss 4.698 (average: 6.495)\n",
      "Test: [0/2]\tval Loss: 5.8961 (val loss average: 5.8961)\n",
      "Test: [1/2]\tval Loss: 5.7698 (val loss average: 5.8375)\n",
      "Train: [299][1/3]\ttraining loss 6.559 (average: 6.559)\n",
      "Train: [299][2/3]\ttraining loss 6.579 (average: 6.569)\n",
      "Train: [299][3/3]\ttraining loss 4.683 (average: 6.435)\n",
      "Test: [0/2]\tval Loss: 5.9006 (val loss average: 5.9006)\n",
      "Test: [1/2]\tval Loss: 5.7762 (val loss average: 5.8429)\n",
      "Train: [399][1/3]\ttraining loss 6.540 (average: 6.540)\n",
      "Train: [399][2/3]\ttraining loss 6.573 (average: 6.557)\n",
      "Train: [399][3/3]\ttraining loss 4.642 (average: 6.420)\n",
      "Test: [0/2]\tval Loss: 5.9167 (val loss average: 5.9167)\n",
      "Test: [1/2]\tval Loss: 5.7451 (val loss average: 5.8371)\n",
      "Train: [499][1/3]\ttraining loss 6.510 (average: 6.510)\n",
      "Train: [499][2/3]\ttraining loss 6.561 (average: 6.536)\n",
      "Train: [499][3/3]\ttraining loss 4.706 (average: 6.405)\n",
      "Test: [0/2]\tval Loss: 5.9041 (val loss average: 5.9041)\n",
      "Test: [1/2]\tval Loss: 5.7340 (val loss average: 5.8252)\n",
      "Train: [599][1/3]\ttraining loss 6.541 (average: 6.541)\n",
      "Train: [599][2/3]\ttraining loss 6.498 (average: 6.520)\n",
      "Train: [599][3/3]\ttraining loss 4.707 (average: 6.391)\n",
      "Test: [0/2]\tval Loss: 5.9028 (val loss average: 5.9028)\n",
      "Test: [1/2]\tval Loss: 5.7212 (val loss average: 5.8185)\n",
      "Train: [699][1/3]\ttraining loss 6.490 (average: 6.490)\n",
      "Train: [699][2/3]\ttraining loss 6.483 (average: 6.486)\n",
      "Train: [699][3/3]\ttraining loss 4.592 (average: 6.352)\n",
      "Test: [0/2]\tval Loss: 5.7798 (val loss average: 5.7798)\n",
      "Test: [1/2]\tval Loss: 5.7224 (val loss average: 5.7531)\n",
      "Train: [799][1/3]\ttraining loss 6.472 (average: 6.472)\n",
      "Train: [799][2/3]\ttraining loss 6.437 (average: 6.454)\n",
      "Train: [799][3/3]\ttraining loss 4.567 (average: 6.320)\n",
      "Test: [0/2]\tval Loss: 5.8362 (val loss average: 5.8362)\n",
      "Test: [1/2]\tval Loss: 5.7451 (val loss average: 5.7939)\n",
      "Train: [99][1/3]\ttraining loss 6.762 (average: 6.762)\n",
      "Train: [99][2/3]\ttraining loss 6.763 (average: 6.762)\n",
      "Train: [99][3/3]\ttraining loss 4.890 (average: 6.629)\n",
      "Test: [0/2]\tval Loss: 6.0212 (val loss average: 6.0212)\n",
      "Test: [1/2]\tval Loss: 5.7988 (val loss average: 5.9180)\n",
      "Train: [199][1/3]\ttraining loss 6.642 (average: 6.642)\n",
      "Train: [199][2/3]\ttraining loss 6.662 (average: 6.652)\n",
      "Train: [199][3/3]\ttraining loss 4.694 (average: 6.513)\n",
      "Test: [0/2]\tval Loss: 5.9640 (val loss average: 5.9640)\n",
      "Test: [1/2]\tval Loss: 5.7742 (val loss average: 5.8760)\n",
      "Train: [299][1/3]\ttraining loss 6.599 (average: 6.599)\n",
      "Train: [299][2/3]\ttraining loss 6.634 (average: 6.617)\n",
      "Train: [299][3/3]\ttraining loss 4.738 (average: 6.483)\n",
      "Test: [0/2]\tval Loss: 5.8890 (val loss average: 5.8890)\n",
      "Test: [1/2]\tval Loss: 5.7864 (val loss average: 5.8414)\n",
      "Train: [399][1/3]\ttraining loss 6.600 (average: 6.600)\n",
      "Train: [399][2/3]\ttraining loss 6.577 (average: 6.588)\n",
      "Train: [399][3/3]\ttraining loss 4.633 (average: 6.449)\n",
      "Test: [0/2]\tval Loss: 5.8551 (val loss average: 5.8551)\n",
      "Test: [1/2]\tval Loss: 5.8591 (val loss average: 5.8569)\n",
      "Train: [499][1/3]\ttraining loss 6.606 (average: 6.606)\n",
      "Train: [499][2/3]\ttraining loss 6.647 (average: 6.626)\n",
      "Train: [499][3/3]\ttraining loss 4.673 (average: 6.487)\n",
      "Test: [0/2]\tval Loss: 5.8746 (val loss average: 5.8746)\n",
      "Test: [1/2]\tval Loss: 5.7658 (val loss average: 5.8241)\n",
      "Train: [599][1/3]\ttraining loss 6.565 (average: 6.565)\n",
      "Train: [599][2/3]\ttraining loss 6.530 (average: 6.548)\n",
      "Train: [599][3/3]\ttraining loss 4.511 (average: 6.403)\n",
      "Test: [0/2]\tval Loss: 5.7707 (val loss average: 5.7707)\n",
      "Test: [1/2]\tval Loss: 5.6720 (val loss average: 5.7249)\n",
      "Train: [699][1/3]\ttraining loss 6.482 (average: 6.482)\n",
      "Train: [699][2/3]\ttraining loss 6.505 (average: 6.494)\n",
      "Train: [699][3/3]\ttraining loss 4.464 (average: 6.349)\n",
      "Test: [0/2]\tval Loss: 5.8869 (val loss average: 5.8869)\n",
      "Test: [1/2]\tval Loss: 5.6498 (val loss average: 5.7769)\n",
      "Train: [99][1/3]\ttraining loss 6.765 (average: 6.765)\n",
      "Train: [99][2/3]\ttraining loss 6.761 (average: 6.763)\n",
      "Train: [99][3/3]\ttraining loss 4.898 (average: 6.630)\n",
      "Test: [0/2]\tval Loss: 5.9754 (val loss average: 5.9754)\n",
      "Test: [1/2]\tval Loss: 5.8669 (val loss average: 5.9251)\n",
      "Train: [199][1/3]\ttraining loss 6.645 (average: 6.645)\n",
      "Train: [199][2/3]\ttraining loss 6.621 (average: 6.633)\n",
      "Train: [199][3/3]\ttraining loss 4.790 (average: 6.502)\n",
      "Test: [0/2]\tval Loss: 5.9292 (val loss average: 5.9292)\n",
      "Test: [1/2]\tval Loss: 5.7600 (val loss average: 5.8507)\n",
      "Train: [299][1/3]\ttraining loss 6.645 (average: 6.645)\n",
      "Train: [299][2/3]\ttraining loss 6.599 (average: 6.622)\n",
      "Train: [299][3/3]\ttraining loss 4.639 (average: 6.481)\n",
      "Test: [0/2]\tval Loss: 5.8228 (val loss average: 5.8228)\n",
      "Test: [1/2]\tval Loss: 5.6955 (val loss average: 5.7638)\n",
      "Train: [399][1/3]\ttraining loss 6.499 (average: 6.499)\n",
      "Train: [399][2/3]\ttraining loss 6.555 (average: 6.527)\n",
      "Train: [399][3/3]\ttraining loss 4.562 (average: 6.387)\n",
      "Test: [0/2]\tval Loss: 5.8665 (val loss average: 5.8665)\n",
      "Test: [1/2]\tval Loss: 5.6628 (val loss average: 5.7720)\n",
      "Train: [499][1/3]\ttraining loss 6.455 (average: 6.455)\n",
      "Train: [499][2/3]\ttraining loss 6.501 (average: 6.478)\n",
      "Train: [499][3/3]\ttraining loss 4.725 (average: 6.353)\n",
      "Test: [0/2]\tval Loss: 5.7992 (val loss average: 5.7992)\n",
      "Test: [1/2]\tval Loss: 5.6665 (val loss average: 5.7376)\n",
      "Train: [599][1/3]\ttraining loss 6.431 (average: 6.431)\n",
      "Train: [599][2/3]\ttraining loss 6.540 (average: 6.486)\n",
      "Train: [599][3/3]\ttraining loss 4.515 (average: 6.345)\n",
      "Test: [0/2]\tval Loss: 5.7967 (val loss average: 5.7967)\n",
      "Test: [1/2]\tval Loss: 5.7141 (val loss average: 5.7584)\n",
      "Train: [99][1/3]\ttraining loss 6.747 (average: 6.747)\n",
      "Train: [99][2/3]\ttraining loss 6.763 (average: 6.755)\n",
      "Train: [99][3/3]\ttraining loss 4.920 (average: 6.624)\n",
      "Test: [0/2]\tval Loss: 6.0370 (val loss average: 6.0370)\n",
      "Test: [1/2]\tval Loss: 5.8198 (val loss average: 5.9362)\n",
      "Train: [199][1/3]\ttraining loss 6.665 (average: 6.665)\n",
      "Train: [199][2/3]\ttraining loss 6.626 (average: 6.646)\n",
      "Train: [199][3/3]\ttraining loss 4.718 (average: 6.509)\n",
      "Test: [0/2]\tval Loss: 5.8802 (val loss average: 5.8802)\n",
      "Test: [1/2]\tval Loss: 5.8036 (val loss average: 5.8446)\n",
      "Train: [299][1/3]\ttraining loss 6.567 (average: 6.567)\n",
      "Train: [299][2/3]\ttraining loss 6.576 (average: 6.572)\n",
      "Train: [299][3/3]\ttraining loss 4.609 (average: 6.432)\n",
      "Test: [0/2]\tval Loss: 5.9569 (val loss average: 5.9569)\n",
      "Test: [1/2]\tval Loss: 5.6981 (val loss average: 5.8368)\n",
      "Train: [399][1/3]\ttraining loss 6.521 (average: 6.521)\n",
      "Train: [399][2/3]\ttraining loss 6.581 (average: 6.551)\n",
      "Train: [399][3/3]\ttraining loss 4.730 (average: 6.421)\n",
      "Test: [0/2]\tval Loss: 5.8119 (val loss average: 5.8119)\n",
      "Test: [1/2]\tval Loss: 5.6872 (val loss average: 5.7540)\n",
      "Train: [499][1/3]\ttraining loss 6.570 (average: 6.570)\n",
      "Train: [499][2/3]\ttraining loss 6.517 (average: 6.544)\n",
      "Train: [499][3/3]\ttraining loss 4.754 (average: 6.416)\n",
      "Test: [0/2]\tval Loss: 5.7881 (val loss average: 5.7881)\n",
      "Test: [1/2]\tval Loss: 5.7800 (val loss average: 5.7843)\n",
      "Train: [599][1/3]\ttraining loss 6.562 (average: 6.562)\n",
      "Train: [599][2/3]\ttraining loss 6.497 (average: 6.529)\n",
      "Train: [599][3/3]\ttraining loss 4.679 (average: 6.398)\n",
      "Test: [0/2]\tval Loss: 5.7335 (val loss average: 5.7335)\n",
      "Test: [1/2]\tval Loss: 5.6766 (val loss average: 5.7071)\n",
      "Train: [99][1/3]\ttraining loss 6.784 (average: 6.784)\n",
      "Train: [99][2/3]\ttraining loss 6.774 (average: 6.779)\n",
      "Train: [99][3/3]\ttraining loss 4.890 (average: 6.644)\n",
      "Test: [0/2]\tval Loss: 6.0109 (val loss average: 6.0109)\n",
      "Test: [1/2]\tval Loss: 5.8605 (val loss average: 5.9411)\n",
      "Train: [199][1/3]\ttraining loss 6.707 (average: 6.707)\n",
      "Train: [199][2/3]\ttraining loss 6.665 (average: 6.686)\n",
      "Train: [199][3/3]\ttraining loss 4.662 (average: 6.542)\n",
      "Test: [0/2]\tval Loss: 5.9235 (val loss average: 5.9235)\n",
      "Test: [1/2]\tval Loss: 5.7784 (val loss average: 5.8562)\n",
      "Train: [299][1/3]\ttraining loss 6.557 (average: 6.557)\n",
      "Train: [299][2/3]\ttraining loss 6.521 (average: 6.539)\n",
      "Train: [299][3/3]\ttraining loss 4.734 (average: 6.410)\n",
      "Test: [0/2]\tval Loss: 5.8989 (val loss average: 5.8989)\n",
      "Test: [1/2]\tval Loss: 5.8554 (val loss average: 5.8787)\n",
      "Train: [399][1/3]\ttraining loss 6.436 (average: 6.436)\n",
      "Train: [399][2/3]\ttraining loss 6.494 (average: 6.465)\n",
      "Train: [399][3/3]\ttraining loss 4.582 (average: 6.331)\n",
      "Test: [0/2]\tval Loss: 5.8848 (val loss average: 5.8848)\n",
      "Test: [1/2]\tval Loss: 5.7540 (val loss average: 5.8241)\n",
      "Train: [499][1/3]\ttraining loss 6.447 (average: 6.447)\n",
      "Train: [499][2/3]\ttraining loss 6.444 (average: 6.445)\n",
      "Train: [499][3/3]\ttraining loss 4.572 (average: 6.312)\n",
      "Test: [0/2]\tval Loss: 5.9191 (val loss average: 5.9191)\n",
      "Test: [1/2]\tval Loss: 5.7527 (val loss average: 5.8419)\n",
      "Train: [299][1/3]\ttraining loss 6.544 (average: 6.544)\n",
      "Train: [299][2/3]\ttraining loss 6.608 (average: 6.576)\n",
      "Train: [299][3/3]\ttraining loss 4.613 (average: 6.436)\n",
      "Test: [0/2]\tval Loss: 5.8774 (val loss average: 5.8774)\n",
      "Test: [1/2]\tval Loss: 5.8460 (val loss average: 5.8628)\n",
      "Train: [399][1/3]\ttraining loss 6.549 (average: 6.549)\n",
      "Train: [399][2/3]\ttraining loss 6.513 (average: 6.531)\n",
      "Train: [399][3/3]\ttraining loss 4.800 (average: 6.408)\n",
      "Test: [0/2]\tval Loss: 5.8410 (val loss average: 5.8410)\n",
      "Test: [1/2]\tval Loss: 5.7671 (val loss average: 5.8067)\n",
      "Train: [499][1/3]\ttraining loss 6.506 (average: 6.506)\n",
      "Train: [499][2/3]\ttraining loss 6.530 (average: 6.518)\n",
      "Train: [499][3/3]\ttraining loss 4.582 (average: 6.381)\n",
      "Test: [0/2]\tval Loss: 5.8364 (val loss average: 5.8364)\n",
      "Test: [1/2]\tval Loss: 5.8150 (val loss average: 5.8265)\n",
      "Train: [599][1/3]\ttraining loss 6.503 (average: 6.503)\n",
      "Train: [599][2/3]\ttraining loss 6.474 (average: 6.489)\n",
      "Train: [599][3/3]\ttraining loss 4.778 (average: 6.367)\n",
      "Test: [0/2]\tval Loss: 5.9070 (val loss average: 5.9070)\n",
      "Test: [1/2]\tval Loss: 5.6914 (val loss average: 5.8070)\n",
      "Train: [99][1/3]\ttraining loss 6.799 (average: 6.799)\n",
      "Train: [99][2/3]\ttraining loss 6.781 (average: 6.790)\n",
      "Train: [99][3/3]\ttraining loss 4.818 (average: 6.650)\n",
      "Test: [0/2]\tval Loss: 6.0109 (val loss average: 6.0109)\n",
      "Test: [1/2]\tval Loss: 5.8640 (val loss average: 5.9427)\n",
      "Train: [199][1/3]\ttraining loss 6.696 (average: 6.696)\n",
      "Train: [199][2/3]\ttraining loss 6.638 (average: 6.667)\n",
      "Train: [199][3/3]\ttraining loss 4.683 (average: 6.526)\n",
      "Test: [0/2]\tval Loss: 5.9629 (val loss average: 5.9629)\n",
      "Test: [1/2]\tval Loss: 5.7271 (val loss average: 5.8535)\n",
      "Train: [299][1/3]\ttraining loss 6.554 (average: 6.554)\n",
      "Train: [299][2/3]\ttraining loss 6.638 (average: 6.596)\n",
      "Train: [299][3/3]\ttraining loss 4.717 (average: 6.462)\n",
      "Test: [0/2]\tval Loss: 5.8488 (val loss average: 5.8488)\n",
      "Test: [1/2]\tval Loss: 5.7182 (val loss average: 5.7882)\n",
      "Train: [399][1/3]\ttraining loss 6.532 (average: 6.532)\n",
      "Train: [399][2/3]\ttraining loss 6.611 (average: 6.571)\n",
      "Train: [399][3/3]\ttraining loss 4.668 (average: 6.436)\n",
      "Test: [0/2]\tval Loss: 5.8319 (val loss average: 5.8319)\n",
      "Test: [1/2]\tval Loss: 5.6899 (val loss average: 5.7660)\n",
      "Train: [499][1/3]\ttraining loss 6.559 (average: 6.559)\n",
      "Train: [499][2/3]\ttraining loss 6.507 (average: 6.533)\n",
      "Train: [499][3/3]\ttraining loss 4.541 (average: 6.391)\n",
      "Test: [0/2]\tval Loss: 5.9583 (val loss average: 5.9583)\n",
      "Test: [1/2]\tval Loss: 5.7336 (val loss average: 5.8540)\n",
      "Train: [599][1/3]\ttraining loss 6.523 (average: 6.523)\n",
      "Train: [599][2/3]\ttraining loss 6.492 (average: 6.507)\n",
      "Train: [599][3/3]\ttraining loss 4.549 (average: 6.368)\n",
      "Test: [0/2]\tval Loss: 5.9398 (val loss average: 5.9398)\n",
      "Test: [1/2]\tval Loss: 5.6854 (val loss average: 5.8218)\n",
      "Train: [99][1/3]\ttraining loss 6.760 (average: 6.760)\n",
      "Train: [99][2/3]\ttraining loss 6.755 (average: 6.758)\n",
      "Train: [99][3/3]\ttraining loss 4.829 (average: 6.620)\n",
      "Test: [0/2]\tval Loss: 6.0239 (val loss average: 6.0239)\n",
      "Test: [1/2]\tval Loss: 5.8766 (val loss average: 5.9555)\n",
      "Train: [199][1/3]\ttraining loss 6.641 (average: 6.641)\n",
      "Train: [199][2/3]\ttraining loss 6.662 (average: 6.652)\n",
      "Train: [199][3/3]\ttraining loss 4.652 (average: 6.509)\n",
      "Test: [0/2]\tval Loss: 5.9016 (val loss average: 5.9016)\n",
      "Test: [1/2]\tval Loss: 5.6978 (val loss average: 5.8071)\n",
      "Train: [299][1/3]\ttraining loss 6.574 (average: 6.574)\n",
      "Train: [299][2/3]\ttraining loss 6.625 (average: 6.599)\n",
      "Train: [299][3/3]\ttraining loss 4.754 (average: 6.468)\n",
      "Test: [0/2]\tval Loss: 5.8921 (val loss average: 5.8921)\n",
      "Test: [1/2]\tval Loss: 5.6994 (val loss average: 5.8027)\n",
      "Train: [399][1/3]\ttraining loss 6.626 (average: 6.626)\n",
      "Train: [399][2/3]\ttraining loss 6.585 (average: 6.605)\n",
      "Train: [399][3/3]\ttraining loss 4.528 (average: 6.458)\n",
      "Test: [0/2]\tval Loss: 5.8616 (val loss average: 5.8616)\n",
      "Test: [1/2]\tval Loss: 5.6981 (val loss average: 5.7857)\n",
      "Train: [499][1/3]\ttraining loss 6.553 (average: 6.553)\n",
      "Train: [499][2/3]\ttraining loss 6.589 (average: 6.571)\n",
      "Train: [499][3/3]\ttraining loss 4.698 (average: 6.438)\n",
      "Test: [0/2]\tval Loss: 5.8542 (val loss average: 5.8542)\n",
      "Test: [1/2]\tval Loss: 5.7116 (val loss average: 5.7881)\n",
      "Train: [599][1/3]\ttraining loss 6.562 (average: 6.562)\n",
      "Train: [599][2/3]\ttraining loss 6.515 (average: 6.539)\n",
      "Train: [599][3/3]\ttraining loss 4.535 (average: 6.396)\n",
      "Test: [0/2]\tval Loss: 5.8374 (val loss average: 5.8374)\n",
      "Test: [1/2]\tval Loss: 5.7241 (val loss average: 5.7848)\n",
      "Train: [699][1/3]\ttraining loss 6.486 (average: 6.486)\n",
      "Train: [699][2/3]\ttraining loss 6.470 (average: 6.478)\n",
      "Train: [699][3/3]\ttraining loss 4.757 (average: 6.355)\n",
      "Test: [0/2]\tval Loss: 5.7639 (val loss average: 5.7639)\n",
      "Test: [1/2]\tval Loss: 5.6590 (val loss average: 5.7152)\n",
      "Train: [799][1/3]\ttraining loss 6.361 (average: 6.361)\n",
      "Train: [799][2/3]\ttraining loss 6.469 (average: 6.415)\n",
      "Train: [799][3/3]\ttraining loss 4.674 (average: 6.291)\n",
      "Test: [0/2]\tval Loss: 5.8224 (val loss average: 5.8224)\n",
      "Test: [1/2]\tval Loss: 5.7826 (val loss average: 5.8040)\n",
      "Train: [99][1/3]\ttraining loss 6.780 (average: 6.780)\n",
      "Train: [99][2/3]\ttraining loss 6.758 (average: 6.769)\n",
      "Train: [99][3/3]\ttraining loss 4.874 (average: 6.634)\n",
      "Test: [0/2]\tval Loss: 5.9890 (val loss average: 5.9890)\n",
      "Test: [1/2]\tval Loss: 5.9149 (val loss average: 5.9546)\n",
      "Train: [199][1/3]\ttraining loss 6.643 (average: 6.643)\n",
      "Train: [199][2/3]\ttraining loss 6.705 (average: 6.674)\n",
      "Train: [199][3/3]\ttraining loss 4.929 (average: 6.550)\n",
      "Test: [0/2]\tval Loss: 5.9756 (val loss average: 5.9756)\n",
      "Test: [1/2]\tval Loss: 5.8871 (val loss average: 5.9345)\n",
      "Train: [299][1/3]\ttraining loss 6.585 (average: 6.585)\n",
      "Train: [299][2/3]\ttraining loss 6.607 (average: 6.596)\n",
      "Train: [299][3/3]\ttraining loss 4.623 (average: 6.456)\n",
      "Test: [0/2]\tval Loss: 5.8941 (val loss average: 5.8941)\n",
      "Test: [1/2]\tval Loss: 5.6865 (val loss average: 5.7978)\n",
      "Train: [399][1/3]\ttraining loss 6.517 (average: 6.517)\n",
      "Train: [399][2/3]\ttraining loss 6.554 (average: 6.535)\n",
      "Train: [399][3/3]\ttraining loss 4.612 (average: 6.398)\n",
      "Test: [0/2]\tval Loss: 5.8723 (val loss average: 5.8723)\n",
      "Test: [1/2]\tval Loss: 5.6035 (val loss average: 5.7476)\n",
      "Train: [499][1/3]\ttraining loss 6.575 (average: 6.575)\n",
      "Train: [499][2/3]\ttraining loss 6.549 (average: 6.562)\n",
      "Train: [499][3/3]\ttraining loss 4.631 (average: 6.424)\n",
      "Test: [0/2]\tval Loss: 5.7549 (val loss average: 5.7549)\n",
      "Test: [1/2]\tval Loss: 5.6026 (val loss average: 5.6842)\n",
      "Train: [599][1/3]\ttraining loss 6.446 (average: 6.446)\n",
      "Train: [599][2/3]\ttraining loss 6.488 (average: 6.467)\n",
      "Train: [599][3/3]\ttraining loss 4.610 (average: 6.335)\n",
      "Test: [0/2]\tval Loss: 5.8558 (val loss average: 5.8558)\n",
      "Test: [1/2]\tval Loss: 5.6090 (val loss average: 5.7413)\n",
      "Train: [699][1/3]\ttraining loss 6.460 (average: 6.460)\n",
      "Train: [699][2/3]\ttraining loss 6.479 (average: 6.470)\n",
      "Train: [699][3/3]\ttraining loss 4.681 (average: 6.342)\n",
      "Test: [0/2]\tval Loss: 5.8051 (val loss average: 5.8051)\n",
      "Test: [1/2]\tval Loss: 5.6930 (val loss average: 5.7531)\n",
      "Train: [799][1/3]\ttraining loss 6.427 (average: 6.427)\n",
      "Train: [799][2/3]\ttraining loss 6.442 (average: 6.434)\n",
      "Train: [799][3/3]\ttraining loss 4.621 (average: 6.305)\n",
      "Test: [0/2]\tval Loss: 5.8134 (val loss average: 5.8134)\n",
      "Test: [1/2]\tval Loss: 5.6162 (val loss average: 5.7219)\n",
      "Train: [99][1/3]\ttraining loss 6.775 (average: 6.775)\n",
      "Train: [99][2/3]\ttraining loss 6.764 (average: 6.770)\n",
      "Train: [99][3/3]\ttraining loss 4.905 (average: 6.637)\n",
      "Test: [0/2]\tval Loss: 6.0644 (val loss average: 6.0644)\n",
      "Test: [1/2]\tval Loss: 5.8680 (val loss average: 5.9733)\n",
      "Train: [199][1/3]\ttraining loss 6.643 (average: 6.643)\n",
      "Train: [199][2/3]\ttraining loss 6.630 (average: 6.637)\n",
      "Train: [199][3/3]\ttraining loss 4.809 (average: 6.507)\n",
      "Test: [0/2]\tval Loss: 5.9218 (val loss average: 5.9218)\n",
      "Test: [1/2]\tval Loss: 5.7826 (val loss average: 5.8572)\n",
      "Train: [299][1/3]\ttraining loss 6.587 (average: 6.587)\n",
      "Train: [299][2/3]\ttraining loss 6.627 (average: 6.607)\n",
      "Train: [299][3/3]\ttraining loss 4.620 (average: 6.466)\n",
      "Test: [0/2]\tval Loss: 5.8927 (val loss average: 5.8927)\n",
      "Test: [1/2]\tval Loss: 5.7297 (val loss average: 5.8171)\n",
      "Train: [399][1/3]\ttraining loss 6.623 (average: 6.623)\n",
      "Train: [399][2/3]\ttraining loss 6.556 (average: 6.590)\n",
      "Train: [399][3/3]\ttraining loss 4.667 (average: 6.453)\n",
      "Test: [0/2]\tval Loss: 5.8750 (val loss average: 5.8750)\n",
      "Test: [1/2]\tval Loss: 5.6504 (val loss average: 5.7708)\n",
      "Train: [499][1/3]\ttraining loss 6.515 (average: 6.515)\n",
      "Train: [499][2/3]\ttraining loss 6.539 (average: 6.527)\n",
      "Train: [499][3/3]\ttraining loss 4.558 (average: 6.387)\n",
      "Test: [0/2]\tval Loss: 5.8759 (val loss average: 5.8759)\n",
      "Test: [1/2]\tval Loss: 5.7346 (val loss average: 5.8104)\n",
      "Train: [599][1/3]\ttraining loss 6.511 (average: 6.511)\n",
      "Train: [599][2/3]\ttraining loss 6.568 (average: 6.540)\n",
      "Train: [599][3/3]\ttraining loss 4.500 (average: 6.395)\n",
      "Test: [0/2]\tval Loss: 5.9069 (val loss average: 5.9069)\n",
      "Test: [1/2]\tval Loss: 5.6796 (val loss average: 5.8014)\n",
      "Train: [99][1/3]\ttraining loss 6.776 (average: 6.776)\n",
      "Train: [99][2/3]\ttraining loss 6.807 (average: 6.792)\n",
      "Train: [99][3/3]\ttraining loss 4.860 (average: 6.654)\n",
      "Test: [0/2]\tval Loss: 6.0151 (val loss average: 6.0151)\n",
      "Test: [1/2]\tval Loss: 5.8768 (val loss average: 5.9510)\n",
      "Train: [199][1/3]\ttraining loss 6.632 (average: 6.632)\n",
      "Train: [199][2/3]\ttraining loss 6.658 (average: 6.645)\n",
      "Train: [199][3/3]\ttraining loss 4.748 (average: 6.510)\n",
      "Test: [0/2]\tval Loss: 5.8603 (val loss average: 5.8603)\n",
      "Test: [1/2]\tval Loss: 5.6543 (val loss average: 5.7648)\n",
      "Train: [299][1/3]\ttraining loss 6.616 (average: 6.616)\n",
      "Train: [299][2/3]\ttraining loss 6.598 (average: 6.607)\n",
      "Train: [299][3/3]\ttraining loss 4.742 (average: 6.474)\n",
      "Test: [0/2]\tval Loss: 5.7383 (val loss average: 5.7383)\n",
      "Test: [1/2]\tval Loss: 5.5729 (val loss average: 5.6616)\n",
      "Train: [399][1/3]\ttraining loss 6.503 (average: 6.503)\n",
      "Train: [399][2/3]\ttraining loss 6.511 (average: 6.507)\n",
      "Train: [399][3/3]\ttraining loss 4.642 (average: 6.374)\n",
      "Test: [0/2]\tval Loss: 5.7833 (val loss average: 5.7833)\n",
      "Test: [1/2]\tval Loss: 5.5263 (val loss average: 5.6641)\n",
      "Train: [499][1/3]\ttraining loss 6.422 (average: 6.422)\n",
      "Train: [499][2/3]\ttraining loss 6.525 (average: 6.473)\n",
      "Train: [499][3/3]\ttraining loss 4.660 (average: 6.344)\n",
      "Test: [0/2]\tval Loss: 5.6667 (val loss average: 5.6667)\n",
      "Test: [1/2]\tval Loss: 5.6194 (val loss average: 5.6447)\n",
      "Train: [599][1/3]\ttraining loss 6.520 (average: 6.520)\n",
      "Train: [599][2/3]\ttraining loss 6.445 (average: 6.483)\n",
      "Train: [599][3/3]\ttraining loss 4.674 (average: 6.354)\n",
      "Test: [0/2]\tval Loss: 5.7254 (val loss average: 5.7254)\n",
      "Test: [1/2]\tval Loss: 5.5621 (val loss average: 5.6496)\n",
      "Train: [99][1/3]\ttraining loss 6.805 (average: 6.805)\n",
      "Train: [99][2/3]\ttraining loss 6.776 (average: 6.791)\n",
      "Train: [99][3/3]\ttraining loss 4.939 (average: 6.659)\n",
      "Test: [0/2]\tval Loss: 6.0258 (val loss average: 6.0258)\n",
      "Test: [1/2]\tval Loss: 5.8733 (val loss average: 5.9550)\n",
      "Train: [199][1/3]\ttraining loss 6.676 (average: 6.676)\n",
      "Train: [199][2/3]\ttraining loss 6.676 (average: 6.676)\n",
      "Train: [199][3/3]\ttraining loss 4.716 (average: 6.536)\n",
      "Test: [0/2]\tval Loss: 5.8650 (val loss average: 5.8650)\n",
      "Test: [1/2]\tval Loss: 5.6891 (val loss average: 5.7834)\n",
      "Train: [299][1/3]\ttraining loss 6.567 (average: 6.567)\n",
      "Train: [299][2/3]\ttraining loss 6.586 (average: 6.577)\n",
      "Train: [299][3/3]\ttraining loss 4.746 (average: 6.446)\n",
      "Test: [0/2]\tval Loss: 5.7742 (val loss average: 5.7742)\n",
      "Test: [1/2]\tval Loss: 5.6367 (val loss average: 5.7104)\n",
      "Train: [399][1/3]\ttraining loss 6.532 (average: 6.532)\n",
      "Train: [399][2/3]\ttraining loss 6.584 (average: 6.558)\n",
      "Train: [399][3/3]\ttraining loss 4.736 (average: 6.428)\n",
      "Test: [0/2]\tval Loss: 5.6904 (val loss average: 5.6904)\n",
      "Test: [1/2]\tval Loss: 5.6698 (val loss average: 5.6808)\n",
      "Train: [499][1/3]\ttraining loss 6.524 (average: 6.524)\n",
      "Train: [499][2/3]\ttraining loss 6.511 (average: 6.518)\n",
      "Train: [499][3/3]\ttraining loss 4.656 (average: 6.385)\n",
      "Test: [0/2]\tval Loss: 5.8620 (val loss average: 5.8620)\n",
      "Test: [1/2]\tval Loss: 5.6306 (val loss average: 5.7546)\n",
      "Train: [599][1/3]\ttraining loss 6.495 (average: 6.495)\n",
      "Train: [599][2/3]\ttraining loss 6.446 (average: 6.471)\n",
      "Train: [599][3/3]\ttraining loss 4.691 (average: 6.344)\n",
      "Test: [0/2]\tval Loss: 5.7067 (val loss average: 5.7067)\n",
      "Test: [1/2]\tval Loss: 5.6421 (val loss average: 5.6767)\n",
      "Train: [99][1/3]\ttraining loss 6.788 (average: 6.788)\n",
      "Train: [99][2/3]\ttraining loss 6.749 (average: 6.769)\n",
      "Train: [99][3/3]\ttraining loss 4.772 (average: 6.626)\n",
      "Test: [0/2]\tval Loss: 6.0231 (val loss average: 6.0231)\n",
      "Test: [1/2]\tval Loss: 5.8845 (val loss average: 5.9588)\n",
      "Train: [199][1/3]\ttraining loss 6.606 (average: 6.606)\n",
      "Train: [199][2/3]\ttraining loss 6.615 (average: 6.611)\n",
      "Train: [199][3/3]\ttraining loss 4.689 (average: 6.474)\n",
      "Test: [0/2]\tval Loss: 5.8517 (val loss average: 5.8517)\n",
      "Test: [1/2]\tval Loss: 5.7166 (val loss average: 5.7890)\n",
      "Train: [299][1/3]\ttraining loss 6.481 (average: 6.481)\n",
      "Train: [299][2/3]\ttraining loss 6.559 (average: 6.520)\n",
      "Train: [299][3/3]\ttraining loss 4.709 (average: 6.391)\n",
      "Test: [0/2]\tval Loss: 5.8838 (val loss average: 5.8838)\n",
      "Test: [1/2]\tval Loss: 5.7171 (val loss average: 5.8065)\n",
      "Train: [399][1/3]\ttraining loss 6.484 (average: 6.484)\n",
      "Train: [399][2/3]\ttraining loss 6.422 (average: 6.453)\n",
      "Train: [399][3/3]\ttraining loss 4.565 (average: 6.319)\n",
      "Test: [0/2]\tval Loss: 5.8632 (val loss average: 5.8632)\n",
      "Test: [1/2]\tval Loss: 5.6367 (val loss average: 5.7581)\n",
      "Train: [499][1/3]\ttraining loss 6.488 (average: 6.488)\n",
      "Train: [499][2/3]\ttraining loss 6.372 (average: 6.430)\n",
      "Train: [499][3/3]\ttraining loss 4.555 (average: 6.296)\n",
      "Test: [0/2]\tval Loss: 5.9487 (val loss average: 5.9487)\n",
      "Test: [1/2]\tval Loss: 5.7764 (val loss average: 5.8688)\n",
      "Train: [599][1/3]\ttraining loss 6.451 (average: 6.451)\n",
      "Train: [599][2/3]\ttraining loss 6.470 (average: 6.460)\n",
      "Train: [599][3/3]\ttraining loss 4.522 (average: 6.322)\n",
      "Test: [0/2]\tval Loss: 5.8033 (val loss average: 5.8033)\n",
      "Test: [1/2]\tval Loss: 5.6650 (val loss average: 5.7391)\n",
      "Train: [699][1/3]\ttraining loss 6.405 (average: 6.405)\n",
      "Train: [699][2/3]\ttraining loss 6.402 (average: 6.403)\n",
      "Train: [699][3/3]\ttraining loss 4.550 (average: 6.271)\n",
      "Test: [0/2]\tval Loss: 5.8183 (val loss average: 5.8183)\n",
      "Test: [1/2]\tval Loss: 5.5603 (val loss average: 5.6986)\n",
      "Train: [99][1/3]\ttraining loss 6.773 (average: 6.773)\n",
      "Train: [99][2/3]\ttraining loss 6.761 (average: 6.767)\n",
      "Train: [99][3/3]\ttraining loss 4.894 (average: 6.633)\n",
      "Test: [0/2]\tval Loss: 6.0133 (val loss average: 6.0133)\n",
      "Test: [1/2]\tval Loss: 5.8729 (val loss average: 5.9481)\n",
      "Train: [199][1/3]\ttraining loss 6.659 (average: 6.659)\n",
      "Train: [199][2/3]\ttraining loss 6.650 (average: 6.654)\n",
      "Train: [199][3/3]\ttraining loss 4.743 (average: 6.518)\n",
      "Test: [0/2]\tval Loss: 5.9517 (val loss average: 5.9517)\n",
      "Test: [1/2]\tval Loss: 5.8043 (val loss average: 5.8833)\n",
      "Train: [299][1/3]\ttraining loss 6.570 (average: 6.570)\n",
      "Train: [299][2/3]\ttraining loss 6.620 (average: 6.595)\n",
      "Train: [299][3/3]\ttraining loss 4.617 (average: 6.454)\n",
      "Test: [0/2]\tval Loss: 5.8919 (val loss average: 5.8919)\n",
      "Test: [1/2]\tval Loss: 5.8113 (val loss average: 5.8545)\n",
      "Train: [399][1/3]\ttraining loss 6.461 (average: 6.461)\n",
      "Train: [399][2/3]\ttraining loss 6.539 (average: 6.500)\n",
      "Train: [399][3/3]\ttraining loss 4.727 (average: 6.374)\n",
      "Test: [0/2]\tval Loss: 5.8618 (val loss average: 5.8618)\n",
      "Test: [1/2]\tval Loss: 5.9123 (val loss average: 5.8852)\n",
      "Train: [499][1/3]\ttraining loss 6.487 (average: 6.487)\n",
      "Train: [499][2/3]\ttraining loss 6.458 (average: 6.472)\n",
      "Train: [499][3/3]\ttraining loss 4.654 (average: 6.343)\n",
      "Test: [0/2]\tval Loss: 5.8512 (val loss average: 5.8512)\n",
      "Test: [1/2]\tval Loss: 5.7860 (val loss average: 5.8210)\n",
      "Train: [599][1/3]\ttraining loss 6.448 (average: 6.448)\n",
      "Train: [599][2/3]\ttraining loss 6.504 (average: 6.476)\n",
      "Train: [599][3/3]\ttraining loss 4.536 (average: 6.338)\n",
      "Test: [0/2]\tval Loss: 5.9311 (val loss average: 5.9311)\n",
      "Test: [1/2]\tval Loss: 5.7944 (val loss average: 5.8677)\n",
      "Train: [99][1/3]\ttraining loss 6.758 (average: 6.758)\n",
      "Train: [99][2/3]\ttraining loss 6.753 (average: 6.755)\n",
      "Train: [99][3/3]\ttraining loss 4.817 (average: 6.617)\n",
      "Test: [0/2]\tval Loss: 5.9278 (val loss average: 5.9278)\n",
      "Test: [1/2]\tval Loss: 5.8014 (val loss average: 5.8691)\n",
      "Train: [199][1/3]\ttraining loss 6.668 (average: 6.668)\n",
      "Train: [199][2/3]\ttraining loss 6.664 (average: 6.666)\n",
      "Train: [199][3/3]\ttraining loss 4.789 (average: 6.532)\n",
      "Test: [0/2]\tval Loss: 5.9271 (val loss average: 5.9271)\n",
      "Test: [1/2]\tval Loss: 5.7425 (val loss average: 5.8415)\n",
      "Train: [299][1/3]\ttraining loss 6.580 (average: 6.580)\n",
      "Train: [299][2/3]\ttraining loss 6.609 (average: 6.595)\n",
      "Train: [299][3/3]\ttraining loss 4.543 (average: 6.449)\n",
      "Test: [0/2]\tval Loss: 5.8712 (val loss average: 5.8712)\n",
      "Test: [1/2]\tval Loss: 5.7206 (val loss average: 5.8014)\n",
      "Train: [399][1/3]\ttraining loss 6.529 (average: 6.529)\n",
      "Train: [399][2/3]\ttraining loss 6.642 (average: 6.586)\n",
      "Train: [399][3/3]\ttraining loss 4.644 (average: 6.448)\n",
      "Test: [0/2]\tval Loss: 5.7976 (val loss average: 5.7976)\n",
      "Test: [1/2]\tval Loss: 5.6439 (val loss average: 5.7263)\n",
      "Train: [499][1/3]\ttraining loss 6.561 (average: 6.561)\n",
      "Train: [499][2/3]\ttraining loss 6.645 (average: 6.603)\n",
      "Train: [499][3/3]\ttraining loss 4.665 (average: 6.465)\n",
      "Test: [0/2]\tval Loss: 5.8343 (val loss average: 5.8343)\n",
      "Test: [1/2]\tval Loss: 5.7233 (val loss average: 5.7828)\n",
      "Train: [599][1/3]\ttraining loss 6.598 (average: 6.598)\n",
      "Train: [599][2/3]\ttraining loss 6.513 (average: 6.556)\n",
      "Train: [599][3/3]\ttraining loss 4.701 (average: 6.424)\n",
      "Test: [0/2]\tval Loss: 5.7712 (val loss average: 5.7712)\n",
      "Test: [1/2]\tval Loss: 5.7451 (val loss average: 5.7591)\n",
      "Train: [99][1/3]\ttraining loss 6.721 (average: 6.721)\n",
      "Train: [99][2/3]\ttraining loss 6.771 (average: 6.746)\n",
      "Train: [99][3/3]\ttraining loss 4.824 (average: 6.609)\n",
      "Test: [0/2]\tval Loss: 6.0362 (val loss average: 6.0362)\n",
      "Test: [1/2]\tval Loss: 5.8853 (val loss average: 5.9662)\n",
      "Train: [199][1/3]\ttraining loss 6.659 (average: 6.659)\n",
      "Train: [199][2/3]\ttraining loss 6.646 (average: 6.652)\n",
      "Train: [199][3/3]\ttraining loss 4.732 (average: 6.516)\n",
      "Test: [0/2]\tval Loss: 5.9872 (val loss average: 5.9872)\n",
      "Test: [1/2]\tval Loss: 5.8106 (val loss average: 5.9053)\n",
      "Train: [299][1/3]\ttraining loss 6.541 (average: 6.541)\n",
      "Train: [299][2/3]\ttraining loss 6.548 (average: 6.545)\n",
      "Train: [299][3/3]\ttraining loss 4.620 (average: 6.408)\n",
      "Test: [0/2]\tval Loss: 5.8989 (val loss average: 5.8989)\n",
      "Test: [1/2]\tval Loss: 5.7964 (val loss average: 5.8513)\n",
      "Train: [399][1/3]\ttraining loss 6.514 (average: 6.514)\n",
      "Train: [399][2/3]\ttraining loss 6.553 (average: 6.534)\n",
      "Train: [399][3/3]\ttraining loss 4.567 (average: 6.394)\n",
      "Test: [0/2]\tval Loss: 5.9249 (val loss average: 5.9249)\n",
      "Test: [1/2]\tval Loss: 5.6997 (val loss average: 5.8204)\n",
      "Train: [499][1/3]\ttraining loss 6.543 (average: 6.543)\n",
      "Train: [499][2/3]\ttraining loss 6.536 (average: 6.539)\n",
      "Train: [499][3/3]\ttraining loss 4.681 (average: 6.407)\n",
      "Test: [0/2]\tval Loss: 5.9357 (val loss average: 5.9357)\n",
      "Test: [1/2]\tval Loss: 5.8202 (val loss average: 5.8821)\n",
      "Train: [599][1/3]\ttraining loss 6.490 (average: 6.490)\n",
      "Train: [599][2/3]\ttraining loss 6.498 (average: 6.494)\n",
      "Train: [599][3/3]\ttraining loss 4.560 (average: 6.356)\n",
      "Test: [0/2]\tval Loss: 5.8464 (val loss average: 5.8464)\n",
      "Test: [1/2]\tval Loss: 5.7779 (val loss average: 5.8146)\n",
      "Train: [699][1/3]\ttraining loss 6.460 (average: 6.460)\n",
      "Train: [699][2/3]\ttraining loss 6.485 (average: 6.472)\n",
      "Train: [699][3/3]\ttraining loss 4.630 (average: 6.341)\n",
      "Test: [0/2]\tval Loss: 5.8197 (val loss average: 5.8197)\n",
      "Test: [1/2]\tval Loss: 5.6255 (val loss average: 5.7296)\n",
      "Train: [99][1/3]\ttraining loss 6.798 (average: 6.798)\n",
      "Train: [99][2/3]\ttraining loss 6.817 (average: 6.807)\n",
      "Train: [99][3/3]\ttraining loss 4.857 (average: 6.668)\n",
      "Test: [0/2]\tval Loss: 6.0447 (val loss average: 6.0447)\n",
      "Test: [1/2]\tval Loss: 5.8957 (val loss average: 5.9756)\n",
      "Train: [199][1/3]\ttraining loss 6.703 (average: 6.703)\n",
      "Train: [199][2/3]\ttraining loss 6.730 (average: 6.717)\n",
      "Train: [199][3/3]\ttraining loss 4.759 (average: 6.577)\n",
      "Test: [0/2]\tval Loss: 6.0155 (val loss average: 6.0155)\n",
      "Test: [1/2]\tval Loss: 5.8738 (val loss average: 5.9498)\n",
      "Train: [299][1/3]\ttraining loss 6.562 (average: 6.562)\n",
      "Train: [299][2/3]\ttraining loss 6.601 (average: 6.581)\n",
      "Train: [299][3/3]\ttraining loss 4.724 (average: 6.449)\n",
      "Test: [0/2]\tval Loss: 5.9192 (val loss average: 5.9192)\n",
      "Test: [1/2]\tval Loss: 5.8023 (val loss average: 5.8650)\n",
      "Train: [399][1/3]\ttraining loss 6.556 (average: 6.556)\n",
      "Train: [399][2/3]\ttraining loss 6.557 (average: 6.557)\n",
      "Train: [399][3/3]\ttraining loss 4.670 (average: 6.422)\n",
      "Test: [0/2]\tval Loss: 5.9568 (val loss average: 5.9568)\n",
      "Test: [1/2]\tval Loss: 5.7814 (val loss average: 5.8754)\n",
      "Train: [499][1/3]\ttraining loss 6.466 (average: 6.466)\n",
      "Train: [499][2/3]\ttraining loss 6.536 (average: 6.501)\n",
      "Train: [499][3/3]\ttraining loss 4.800 (average: 6.380)\n",
      "Test: [0/2]\tval Loss: 5.8800 (val loss average: 5.8800)\n",
      "Test: [1/2]\tval Loss: 5.8216 (val loss average: 5.8529)\n",
      "Train: [599][1/3]\ttraining loss 6.523 (average: 6.523)\n",
      "Train: [599][2/3]\ttraining loss 6.536 (average: 6.530)\n",
      "Train: [599][3/3]\ttraining loss 4.459 (average: 6.382)\n",
      "Test: [0/2]\tval Loss: 5.9465 (val loss average: 5.9465)\n",
      "Test: [1/2]\tval Loss: 5.7518 (val loss average: 5.8562)\n",
      "Train: [699][1/3]\ttraining loss 6.496 (average: 6.496)\n",
      "Train: [699][2/3]\ttraining loss 6.473 (average: 6.485)\n",
      "Train: [699][3/3]\ttraining loss 4.537 (average: 6.346)\n",
      "Test: [0/2]\tval Loss: 5.8753 (val loss average: 5.8753)\n",
      "Test: [1/2]\tval Loss: 5.7384 (val loss average: 5.8118)\n",
      "Train: [799][1/3]\ttraining loss 6.403 (average: 6.403)\n",
      "Train: [799][2/3]\ttraining loss 6.456 (average: 6.430)\n",
      "Train: [799][3/3]\ttraining loss 4.504 (average: 6.292)\n",
      "Test: [0/2]\tval Loss: 5.9491 (val loss average: 5.9491)\n",
      "Test: [1/2]\tval Loss: 5.8695 (val loss average: 5.9121)\n",
      "Train: [899][1/3]\ttraining loss 6.366 (average: 6.366)\n",
      "Train: [899][2/3]\ttraining loss 6.418 (average: 6.392)\n",
      "Train: [899][3/3]\ttraining loss 4.679 (average: 6.270)\n",
      "Test: [0/2]\tval Loss: 5.8564 (val loss average: 5.8564)\n",
      "Test: [1/2]\tval Loss: 5.7992 (val loss average: 5.8299)\n",
      "Train: [99][1/3]\ttraining loss 6.713 (average: 6.713)\n",
      "Train: [99][2/3]\ttraining loss 6.739 (average: 6.726)\n",
      "Train: [99][3/3]\ttraining loss 4.809 (average: 6.589)\n",
      "Test: [0/2]\tval Loss: 5.9652 (val loss average: 5.9652)\n",
      "Test: [1/2]\tval Loss: 5.7920 (val loss average: 5.8849)\n",
      "Train: [199][1/3]\ttraining loss 6.635 (average: 6.635)\n",
      "Train: [199][2/3]\ttraining loss 6.636 (average: 6.635)\n",
      "Train: [199][3/3]\ttraining loss 4.678 (average: 6.496)\n",
      "Test: [0/2]\tval Loss: 5.9409 (val loss average: 5.9409)\n",
      "Test: [1/2]\tval Loss: 5.8211 (val loss average: 5.8853)\n",
      "Train: [299][1/3]\ttraining loss 6.538 (average: 6.538)\n",
      "Train: [299][2/3]\ttraining loss 6.567 (average: 6.552)\n",
      "Train: [299][3/3]\ttraining loss 4.780 (average: 6.426)\n",
      "Test: [0/2]\tval Loss: 5.8467 (val loss average: 5.8467)\n",
      "Test: [1/2]\tval Loss: 5.6812 (val loss average: 5.7699)\n",
      "Train: [399][1/3]\ttraining loss 6.543 (average: 6.543)\n",
      "Train: [399][2/3]\ttraining loss 6.503 (average: 6.523)\n",
      "Train: [399][3/3]\ttraining loss 4.563 (average: 6.383)\n",
      "Test: [0/2]\tval Loss: 5.9143 (val loss average: 5.9143)\n",
      "Test: [1/2]\tval Loss: 5.8059 (val loss average: 5.8640)\n",
      "Train: [499][1/3]\ttraining loss 6.414 (average: 6.414)\n",
      "Train: [499][2/3]\ttraining loss 6.438 (average: 6.426)\n",
      "Train: [499][3/3]\ttraining loss 4.597 (average: 6.296)\n",
      "Test: [0/2]\tval Loss: 5.8808 (val loss average: 5.8808)\n",
      "Test: [1/2]\tval Loss: 5.7773 (val loss average: 5.8328)\n",
      "Train: [599][1/3]\ttraining loss 6.437 (average: 6.437)\n",
      "Train: [599][2/3]\ttraining loss 6.436 (average: 6.437)\n",
      "Train: [599][3/3]\ttraining loss 4.603 (average: 6.306)\n",
      "Test: [0/2]\tval Loss: 5.7844 (val loss average: 5.7844)\n",
      "Test: [1/2]\tval Loss: 5.6498 (val loss average: 5.7220)\n",
      "Train: [699][1/3]\ttraining loss 6.444 (average: 6.444)\n",
      "Train: [699][2/3]\ttraining loss 6.415 (average: 6.430)\n",
      "Train: [699][3/3]\ttraining loss 4.381 (average: 6.284)\n",
      "Test: [0/2]\tval Loss: 5.8048 (val loss average: 5.8048)\n",
      "Test: [1/2]\tval Loss: 5.7861 (val loss average: 5.7961)\n",
      "Train: [99][1/3]\ttraining loss 6.775 (average: 6.775)\n",
      "Train: [99][2/3]\ttraining loss 6.774 (average: 6.775)\n",
      "Train: [99][3/3]\ttraining loss 4.799 (average: 6.634)\n",
      "Test: [0/2]\tval Loss: 6.0411 (val loss average: 6.0411)\n",
      "Test: [1/2]\tval Loss: 5.8477 (val loss average: 5.9514)\n",
      "Train: [199][1/3]\ttraining loss 6.663 (average: 6.663)\n",
      "Train: [199][2/3]\ttraining loss 6.666 (average: 6.664)\n",
      "Train: [199][3/3]\ttraining loss 4.803 (average: 6.532)\n",
      "Test: [0/2]\tval Loss: 5.9041 (val loss average: 5.9041)\n",
      "Test: [1/2]\tval Loss: 5.7723 (val loss average: 5.8430)\n",
      "Train: [299][1/3]\ttraining loss 6.565 (average: 6.565)\n",
      "Train: [299][2/3]\ttraining loss 6.569 (average: 6.567)\n",
      "Train: [299][3/3]\ttraining loss 4.705 (average: 6.434)\n",
      "Test: [0/2]\tval Loss: 5.8768 (val loss average: 5.8768)\n",
      "Test: [1/2]\tval Loss: 5.6717 (val loss average: 5.7816)\n",
      "Train: [399][1/3]\ttraining loss 6.528 (average: 6.528)\n",
      "Train: [399][2/3]\ttraining loss 6.582 (average: 6.555)\n",
      "Train: [399][3/3]\ttraining loss 4.661 (average: 6.420)\n",
      "Test: [0/2]\tval Loss: 5.8620 (val loss average: 5.8620)\n",
      "Test: [1/2]\tval Loss: 5.6227 (val loss average: 5.7509)\n",
      "Train: [499][1/3]\ttraining loss 6.496 (average: 6.496)\n",
      "Train: [499][2/3]\ttraining loss 6.502 (average: 6.499)\n",
      "Train: [499][3/3]\ttraining loss 4.622 (average: 6.365)\n",
      "Test: [0/2]\tval Loss: 5.7994 (val loss average: 5.7994)\n",
      "Test: [1/2]\tval Loss: 5.7626 (val loss average: 5.7823)\n",
      "Train: [599][1/3]\ttraining loss 6.500 (average: 6.500)\n",
      "Train: [599][2/3]\ttraining loss 6.469 (average: 6.485)\n",
      "Train: [599][3/3]\ttraining loss 4.725 (average: 6.359)\n",
      "Test: [0/2]\tval Loss: 5.7115 (val loss average: 5.7115)\n",
      "Test: [1/2]\tval Loss: 5.6934 (val loss average: 5.7031)\n",
      "Train: [99][1/3]\ttraining loss 6.791 (average: 6.791)\n",
      "Train: [99][2/3]\ttraining loss 6.778 (average: 6.784)\n",
      "Train: [99][3/3]\ttraining loss 4.853 (average: 6.647)\n",
      "Test: [0/2]\tval Loss: 6.0597 (val loss average: 6.0597)\n",
      "Test: [1/2]\tval Loss: 5.8608 (val loss average: 5.9674)\n",
      "Train: [199][1/3]\ttraining loss 6.674 (average: 6.674)\n",
      "Train: [199][2/3]\ttraining loss 6.737 (average: 6.705)\n",
      "Train: [199][3/3]\ttraining loss 4.789 (average: 6.569)\n",
      "Test: [0/2]\tval Loss: 6.0119 (val loss average: 6.0119)\n",
      "Test: [1/2]\tval Loss: 5.7789 (val loss average: 5.9038)\n",
      "Train: [299][1/3]\ttraining loss 6.575 (average: 6.575)\n",
      "Train: [299][2/3]\ttraining loss 6.563 (average: 6.569)\n",
      "Train: [299][3/3]\ttraining loss 4.650 (average: 6.432)\n",
      "Test: [0/2]\tval Loss: 5.9286 (val loss average: 5.9286)\n",
      "Test: [1/2]\tval Loss: 5.7683 (val loss average: 5.8542)\n",
      "Train: [399][1/3]\ttraining loss 6.493 (average: 6.493)\n",
      "Train: [399][2/3]\ttraining loss 6.538 (average: 6.515)\n",
      "Train: [399][3/3]\ttraining loss 4.691 (average: 6.385)\n",
      "Test: [0/2]\tval Loss: 5.9906 (val loss average: 5.9906)\n",
      "Test: [1/2]\tval Loss: 5.7814 (val loss average: 5.8936)\n",
      "Train: [499][1/3]\ttraining loss 6.451 (average: 6.451)\n",
      "Train: [499][2/3]\ttraining loss 6.432 (average: 6.441)\n",
      "Train: [499][3/3]\ttraining loss 4.541 (average: 6.306)\n",
      "Test: [0/2]\tval Loss: 5.9996 (val loss average: 5.9996)\n",
      "Test: [1/2]\tval Loss: 5.8615 (val loss average: 5.9355)\n",
      "Train: [599][1/3]\ttraining loss 6.464 (average: 6.464)\n",
      "Train: [599][2/3]\ttraining loss 6.417 (average: 6.440)\n",
      "Train: [599][3/3]\ttraining loss 4.465 (average: 6.300)\n",
      "Test: [0/2]\tval Loss: 6.0191 (val loss average: 6.0191)\n",
      "Test: [1/2]\tval Loss: 5.7405 (val loss average: 5.8899)\n",
      "Train: [699][1/3]\ttraining loss 6.424 (average: 6.424)\n",
      "Train: [699][2/3]\ttraining loss 6.401 (average: 6.412)\n",
      "Train: [699][3/3]\ttraining loss 4.426 (average: 6.271)\n",
      "Test: [0/2]\tval Loss: 6.0223 (val loss average: 6.0223)\n",
      "Test: [1/2]\tval Loss: 5.9486 (val loss average: 5.9881)\n",
      "Train: [99][1/3]\ttraining loss 6.814 (average: 6.814)\n",
      "Train: [99][2/3]\ttraining loss 6.796 (average: 6.805)\n",
      "Train: [99][3/3]\ttraining loss 4.917 (average: 6.671)\n",
      "Test: [0/2]\tval Loss: 6.0627 (val loss average: 6.0627)\n",
      "Test: [1/2]\tval Loss: 5.8958 (val loss average: 5.9853)\n",
      "Train: [199][1/3]\ttraining loss 6.679 (average: 6.679)\n",
      "Train: [199][2/3]\ttraining loss 6.674 (average: 6.677)\n",
      "Train: [199][3/3]\ttraining loss 4.811 (average: 6.544)\n",
      "Test: [0/2]\tval Loss: 6.0270 (val loss average: 6.0270)\n",
      "Test: [1/2]\tval Loss: 5.8105 (val loss average: 5.9266)\n",
      "Train: [299][1/3]\ttraining loss 6.558 (average: 6.558)\n",
      "Train: [299][2/3]\ttraining loss 6.576 (average: 6.567)\n",
      "Train: [299][3/3]\ttraining loss 4.693 (average: 6.433)\n",
      "Test: [0/2]\tval Loss: 5.9327 (val loss average: 5.9327)\n",
      "Test: [1/2]\tval Loss: 5.7877 (val loss average: 5.8654)\n",
      "Train: [399][1/3]\ttraining loss 6.511 (average: 6.511)\n",
      "Train: [399][2/3]\ttraining loss 6.537 (average: 6.524)\n",
      "Train: [399][3/3]\ttraining loss 4.722 (average: 6.395)\n",
      "Test: [0/2]\tval Loss: 5.7195 (val loss average: 5.7195)\n",
      "Test: [1/2]\tval Loss: 5.8073 (val loss average: 5.7602)\n",
      "Train: [499][1/3]\ttraining loss 6.434 (average: 6.434)\n",
      "Train: [499][2/3]\ttraining loss 6.500 (average: 6.467)\n",
      "Train: [499][3/3]\ttraining loss 4.486 (average: 6.326)\n",
      "Test: [0/2]\tval Loss: 5.8085 (val loss average: 5.8085)\n",
      "Test: [1/2]\tval Loss: 5.7618 (val loss average: 5.7868)\n",
      "Train: [599][1/3]\ttraining loss 6.393 (average: 6.393)\n",
      "Train: [599][2/3]\ttraining loss 6.452 (average: 6.422)\n",
      "Train: [599][3/3]\ttraining loss 4.636 (average: 6.295)\n",
      "Test: [0/2]\tval Loss: 5.8215 (val loss average: 5.8215)\n",
      "Test: [1/2]\tval Loss: 5.6189 (val loss average: 5.7275)\n",
      "Train: [99][1/3]\ttraining loss 6.783 (average: 6.783)\n",
      "Train: [99][2/3]\ttraining loss 6.780 (average: 6.781)\n",
      "Train: [99][3/3]\ttraining loss 4.934 (average: 6.650)\n",
      "Test: [0/2]\tval Loss: 6.0519 (val loss average: 6.0519)\n",
      "Test: [1/2]\tval Loss: 5.9120 (val loss average: 5.9870)\n",
      "Train: [199][1/3]\ttraining loss 6.642 (average: 6.642)\n",
      "Train: [199][2/3]\ttraining loss 6.642 (average: 6.642)\n",
      "Train: [199][3/3]\ttraining loss 4.753 (average: 6.508)\n",
      "Test: [0/2]\tval Loss: 5.9557 (val loss average: 5.9557)\n",
      "Test: [1/2]\tval Loss: 5.7751 (val loss average: 5.8719)\n",
      "Train: [299][1/3]\ttraining loss 6.592 (average: 6.592)\n",
      "Train: [299][2/3]\ttraining loss 6.547 (average: 6.570)\n",
      "Train: [299][3/3]\ttraining loss 4.643 (average: 6.433)\n",
      "Test: [0/2]\tval Loss: 6.0115 (val loss average: 6.0115)\n",
      "Test: [1/2]\tval Loss: 5.8044 (val loss average: 5.9154)\n",
      "Train: [399][1/3]\ttraining loss 6.517 (average: 6.517)\n",
      "Train: [399][2/3]\ttraining loss 6.567 (average: 6.542)\n",
      "Train: [399][3/3]\ttraining loss 4.602 (average: 6.404)\n",
      "Test: [0/2]\tval Loss: 5.9463 (val loss average: 5.9463)\n",
      "Test: [1/2]\tval Loss: 5.8412 (val loss average: 5.8976)\n",
      "Train: [499][1/3]\ttraining loss 6.498 (average: 6.498)\n",
      "Train: [499][2/3]\ttraining loss 6.464 (average: 6.481)\n",
      "Train: [499][3/3]\ttraining loss 4.497 (average: 6.340)\n",
      "Test: [0/2]\tval Loss: 6.0032 (val loss average: 6.0032)\n",
      "Test: [1/2]\tval Loss: 5.8744 (val loss average: 5.9434)\n",
      "Train: [599][1/3]\ttraining loss 6.419 (average: 6.419)\n",
      "Train: [599][2/3]\ttraining loss 6.471 (average: 6.445)\n",
      "Train: [599][3/3]\ttraining loss 4.618 (average: 6.315)\n",
      "Test: [0/2]\tval Loss: 5.8670 (val loss average: 5.8670)\n",
      "Test: [1/2]\tval Loss: 5.8016 (val loss average: 5.8367)\n",
      "Train: [699][1/3]\ttraining loss 6.428 (average: 6.428)\n",
      "Train: [699][2/3]\ttraining loss 6.440 (average: 6.434)\n",
      "Train: [699][3/3]\ttraining loss 4.563 (average: 6.301)\n",
      "Test: [0/2]\tval Loss: 5.9536 (val loss average: 5.9536)\n",
      "Test: [1/2]\tval Loss: 5.8334 (val loss average: 5.8979)\n",
      "Train: [99][1/3]\ttraining loss 6.785 (average: 6.785)\n",
      "Train: [99][2/3]\ttraining loss 6.754 (average: 6.770)\n",
      "Train: [99][3/3]\ttraining loss 4.821 (average: 6.631)\n",
      "Test: [0/2]\tval Loss: 6.0049 (val loss average: 6.0049)\n",
      "Test: [1/2]\tval Loss: 5.8707 (val loss average: 5.9427)\n",
      "Train: [199][1/3]\ttraining loss 6.651 (average: 6.651)\n",
      "Train: [199][2/3]\ttraining loss 6.645 (average: 6.648)\n",
      "Train: [199][3/3]\ttraining loss 4.749 (average: 6.513)\n",
      "Test: [0/2]\tval Loss: 5.9208 (val loss average: 5.9208)\n",
      "Test: [1/2]\tval Loss: 5.7718 (val loss average: 5.8517)\n",
      "Train: [299][1/3]\ttraining loss 6.599 (average: 6.599)\n",
      "Train: [299][2/3]\ttraining loss 6.619 (average: 6.609)\n",
      "Train: [299][3/3]\ttraining loss 4.728 (average: 6.475)\n",
      "Test: [0/2]\tval Loss: 5.8561 (val loss average: 5.8561)\n",
      "Test: [1/2]\tval Loss: 5.7665 (val loss average: 5.8145)\n",
      "Train: [399][1/3]\ttraining loss 6.580 (average: 6.580)\n",
      "Train: [399][2/3]\ttraining loss 6.574 (average: 6.577)\n",
      "Train: [399][3/3]\ttraining loss 4.733 (average: 6.446)\n",
      "Test: [0/2]\tval Loss: 5.9173 (val loss average: 5.9173)\n",
      "Test: [1/2]\tval Loss: 5.7316 (val loss average: 5.8312)\n",
      "Train: [499][1/3]\ttraining loss 6.503 (average: 6.503)\n",
      "Train: [499][2/3]\ttraining loss 6.517 (average: 6.510)\n",
      "Train: [499][3/3]\ttraining loss 4.587 (average: 6.373)\n",
      "Test: [0/2]\tval Loss: 5.7805 (val loss average: 5.7805)\n",
      "Test: [1/2]\tval Loss: 5.7267 (val loss average: 5.7555)\n",
      "Train: [599][1/3]\ttraining loss 6.504 (average: 6.504)\n",
      "Train: [599][2/3]\ttraining loss 6.494 (average: 6.499)\n",
      "Train: [599][3/3]\ttraining loss 4.673 (average: 6.369)\n",
      "Test: [0/2]\tval Loss: 5.8287 (val loss average: 5.8287)\n",
      "Test: [1/2]\tval Loss: 5.6304 (val loss average: 5.7367)\n",
      "Train: [99][1/3]\ttraining loss 6.759 (average: 6.759)\n",
      "Train: [99][2/3]\ttraining loss 6.746 (average: 6.753)\n",
      "Train: [99][3/3]\ttraining loss 4.834 (average: 6.616)\n",
      "Test: [0/2]\tval Loss: 5.9741 (val loss average: 5.9741)\n",
      "Test: [1/2]\tval Loss: 5.8711 (val loss average: 5.9263)\n",
      "Train: [199][1/3]\ttraining loss 6.656 (average: 6.656)\n",
      "Train: [199][2/3]\ttraining loss 6.647 (average: 6.651)\n",
      "Train: [199][3/3]\ttraining loss 4.696 (average: 6.512)\n",
      "Test: [0/2]\tval Loss: 5.9960 (val loss average: 5.9960)\n",
      "Test: [1/2]\tval Loss: 5.7634 (val loss average: 5.8881)\n",
      "Train: [299][1/3]\ttraining loss 6.587 (average: 6.587)\n",
      "Train: [299][2/3]\ttraining loss 6.580 (average: 6.583)\n",
      "Train: [299][3/3]\ttraining loss 4.757 (average: 6.453)\n",
      "Test: [0/2]\tval Loss: 5.8382 (val loss average: 5.8382)\n",
      "Test: [1/2]\tval Loss: 5.7118 (val loss average: 5.7796)\n",
      "Train: [399][1/3]\ttraining loss 6.514 (average: 6.514)\n",
      "Train: [399][2/3]\ttraining loss 6.471 (average: 6.493)\n",
      "Train: [399][3/3]\ttraining loss 4.760 (average: 6.369)\n",
      "Test: [0/2]\tval Loss: 5.7513 (val loss average: 5.7513)\n",
      "Test: [1/2]\tval Loss: 5.7430 (val loss average: 5.7475)\n",
      "Train: [499][1/3]\ttraining loss 6.528 (average: 6.528)\n",
      "Train: [499][2/3]\ttraining loss 6.527 (average: 6.528)\n",
      "Train: [499][3/3]\ttraining loss 4.552 (average: 6.387)\n",
      "Test: [0/2]\tval Loss: 5.8552 (val loss average: 5.8552)\n",
      "Test: [1/2]\tval Loss: 5.7228 (val loss average: 5.7938)\n",
      "Train: [599][1/3]\ttraining loss 6.379 (average: 6.379)\n",
      "Train: [599][2/3]\ttraining loss 6.525 (average: 6.452)\n",
      "Train: [599][3/3]\ttraining loss 4.634 (average: 6.323)\n",
      "Test: [0/2]\tval Loss: 5.9064 (val loss average: 5.9064)\n",
      "Test: [1/2]\tval Loss: 5.7880 (val loss average: 5.8515)\n",
      "Train: [99][1/3]\ttraining loss 6.775 (average: 6.775)\n",
      "Train: [99][2/3]\ttraining loss 6.767 (average: 6.771)\n",
      "Train: [99][3/3]\ttraining loss 4.833 (average: 6.633)\n",
      "Test: [0/2]\tval Loss: 5.9854 (val loss average: 5.9854)\n",
      "Test: [1/2]\tval Loss: 5.8766 (val loss average: 5.9349)\n",
      "Train: [199][1/3]\ttraining loss 6.700 (average: 6.700)\n",
      "Train: [199][2/3]\ttraining loss 6.670 (average: 6.685)\n",
      "Train: [199][3/3]\ttraining loss 4.776 (average: 6.549)\n",
      "Test: [0/2]\tval Loss: 5.9836 (val loss average: 5.9836)\n",
      "Test: [1/2]\tval Loss: 5.8229 (val loss average: 5.9090)\n",
      "Train: [299][1/3]\ttraining loss 6.587 (average: 6.587)\n",
      "Train: [299][2/3]\ttraining loss 6.540 (average: 6.563)\n",
      "Train: [299][3/3]\ttraining loss 4.758 (average: 6.435)\n",
      "Test: [0/2]\tval Loss: 6.0054 (val loss average: 6.0054)\n",
      "Test: [1/2]\tval Loss: 5.7847 (val loss average: 5.9030)\n",
      "Train: [399][1/3]\ttraining loss 6.562 (average: 6.562)\n",
      "Train: [399][2/3]\ttraining loss 6.569 (average: 6.565)\n",
      "Train: [399][3/3]\ttraining loss 4.569 (average: 6.423)\n",
      "Test: [0/2]\tval Loss: 5.8876 (val loss average: 5.8876)\n",
      "Test: [1/2]\tval Loss: 5.8212 (val loss average: 5.8568)\n",
      "Train: [499][1/3]\ttraining loss 6.470 (average: 6.470)\n",
      "Train: [499][2/3]\ttraining loss 6.554 (average: 6.512)\n",
      "Train: [499][3/3]\ttraining loss 4.675 (average: 6.381)\n",
      "Test: [0/2]\tval Loss: 5.8367 (val loss average: 5.8367)\n",
      "Test: [1/2]\tval Loss: 5.7048 (val loss average: 5.7755)\n",
      "Train: [599][1/3]\ttraining loss 6.505 (average: 6.505)\n",
      "Train: [599][2/3]\ttraining loss 6.508 (average: 6.507)\n",
      "Train: [599][3/3]\ttraining loss 4.503 (average: 6.364)\n",
      "Test: [0/2]\tval Loss: 5.9077 (val loss average: 5.9077)\n",
      "Test: [1/2]\tval Loss: 5.6443 (val loss average: 5.7855)\n",
      "Train: [99][1/3]\ttraining loss 6.724 (average: 6.724)\n",
      "Train: [99][2/3]\ttraining loss 6.710 (average: 6.717)\n",
      "Train: [99][3/3]\ttraining loss 4.856 (average: 6.585)\n",
      "Test: [0/2]\tval Loss: 5.9783 (val loss average: 5.9783)\n",
      "Test: [1/2]\tval Loss: 5.7784 (val loss average: 5.8855)\n",
      "Train: [199][1/3]\ttraining loss 6.628 (average: 6.628)\n",
      "Train: [199][2/3]\ttraining loss 6.684 (average: 6.656)\n",
      "Train: [199][3/3]\ttraining loss 4.750 (average: 6.520)\n",
      "Test: [0/2]\tval Loss: 5.9576 (val loss average: 5.9576)\n",
      "Test: [1/2]\tval Loss: 5.7963 (val loss average: 5.8828)\n",
      "Train: [299][1/3]\ttraining loss 6.554 (average: 6.554)\n",
      "Train: [299][2/3]\ttraining loss 6.547 (average: 6.550)\n",
      "Train: [299][3/3]\ttraining loss 4.637 (average: 6.414)\n",
      "Test: [0/2]\tval Loss: 5.8534 (val loss average: 5.8534)\n",
      "Test: [1/2]\tval Loss: 5.7003 (val loss average: 5.7824)\n",
      "Train: [399][1/3]\ttraining loss 6.539 (average: 6.539)\n",
      "Train: [399][2/3]\ttraining loss 6.541 (average: 6.540)\n",
      "Train: [399][3/3]\ttraining loss 4.639 (average: 6.405)\n",
      "Test: [0/2]\tval Loss: 5.8800 (val loss average: 5.8800)\n",
      "Test: [1/2]\tval Loss: 5.7509 (val loss average: 5.8201)\n",
      "Train: [499][1/3]\ttraining loss 6.484 (average: 6.484)\n",
      "Train: [499][2/3]\ttraining loss 6.527 (average: 6.505)\n",
      "Train: [499][3/3]\ttraining loss 4.539 (average: 6.365)\n",
      "Test: [0/2]\tval Loss: 5.8363 (val loss average: 5.8363)\n",
      "Test: [1/2]\tval Loss: 5.7950 (val loss average: 5.8172)\n",
      "Train: [599][1/3]\ttraining loss 6.537 (average: 6.537)\n",
      "Train: [599][2/3]\ttraining loss 6.485 (average: 6.511)\n",
      "Train: [599][3/3]\ttraining loss 4.575 (average: 6.373)\n",
      "Test: [0/2]\tval Loss: 5.8875 (val loss average: 5.8875)\n",
      "Test: [1/2]\tval Loss: 5.7533 (val loss average: 5.8252)\n",
      "Train: [99][1/3]\ttraining loss 6.794 (average: 6.794)\n",
      "Train: [99][2/3]\ttraining loss 6.784 (average: 6.789)\n",
      "Train: [99][3/3]\ttraining loss 4.914 (average: 6.655)\n",
      "Test: [0/2]\tval Loss: 6.0021 (val loss average: 6.0021)\n",
      "Test: [1/2]\tval Loss: 5.8639 (val loss average: 5.9380)\n",
      "Train: [199][1/3]\ttraining loss 6.703 (average: 6.703)\n",
      "Train: [199][2/3]\ttraining loss 6.690 (average: 6.697)\n",
      "Train: [199][3/3]\ttraining loss 4.854 (average: 6.565)\n",
      "Test: [0/2]\tval Loss: 5.9856 (val loss average: 5.9856)\n",
      "Test: [1/2]\tval Loss: 5.7847 (val loss average: 5.8924)\n",
      "Train: [299][1/3]\ttraining loss 6.620 (average: 6.620)\n",
      "Train: [299][2/3]\ttraining loss 6.635 (average: 6.628)\n",
      "Train: [299][3/3]\ttraining loss 4.914 (average: 6.506)\n",
      "Test: [0/2]\tval Loss: 5.8587 (val loss average: 5.8587)\n",
      "Test: [1/2]\tval Loss: 5.6266 (val loss average: 5.7510)\n",
      "Train: [399][1/3]\ttraining loss 6.614 (average: 6.614)\n",
      "Train: [399][2/3]\ttraining loss 6.569 (average: 6.592)\n",
      "Train: [399][3/3]\ttraining loss 4.675 (average: 6.455)\n",
      "Test: [0/2]\tval Loss: 5.9345 (val loss average: 5.9345)\n",
      "Test: [1/2]\tval Loss: 5.7601 (val loss average: 5.8536)\n",
      "Train: [499][1/3]\ttraining loss 6.603 (average: 6.603)\n",
      "Train: [499][2/3]\ttraining loss 6.535 (average: 6.569)\n",
      "Train: [499][3/3]\ttraining loss 4.569 (average: 6.427)\n",
      "Test: [0/2]\tval Loss: 5.8387 (val loss average: 5.8387)\n",
      "Test: [1/2]\tval Loss: 5.5691 (val loss average: 5.7136)\n",
      "Train: [599][1/3]\ttraining loss 6.507 (average: 6.507)\n",
      "Train: [599][2/3]\ttraining loss 6.555 (average: 6.531)\n",
      "Train: [599][3/3]\ttraining loss 4.758 (average: 6.405)\n",
      "Test: [0/2]\tval Loss: 5.7420 (val loss average: 5.7420)\n",
      "Test: [1/2]\tval Loss: 5.7622 (val loss average: 5.7513)\n",
      "Train: [99][1/3]\ttraining loss 6.686 (average: 6.686)\n",
      "Train: [99][2/3]\ttraining loss 6.692 (average: 6.689)\n",
      "Train: [99][3/3]\ttraining loss 4.774 (average: 6.553)\n",
      "Test: [0/2]\tval Loss: 6.0305 (val loss average: 6.0305)\n",
      "Test: [1/2]\tval Loss: 5.8457 (val loss average: 5.9448)\n",
      "Train: [199][1/3]\ttraining loss 6.621 (average: 6.621)\n",
      "Train: [199][2/3]\ttraining loss 6.632 (average: 6.627)\n",
      "Train: [199][3/3]\ttraining loss 4.678 (average: 6.488)\n",
      "Test: [0/2]\tval Loss: 5.8928 (val loss average: 5.8928)\n",
      "Test: [1/2]\tval Loss: 5.7707 (val loss average: 5.8362)\n",
      "Train: [299][1/3]\ttraining loss 6.526 (average: 6.526)\n",
      "Train: [299][2/3]\ttraining loss 6.590 (average: 6.558)\n",
      "Train: [299][3/3]\ttraining loss 4.752 (average: 6.430)\n",
      "Test: [0/2]\tval Loss: 5.9467 (val loss average: 5.9467)\n",
      "Test: [1/2]\tval Loss: 5.7147 (val loss average: 5.8390)\n",
      "Train: [399][1/3]\ttraining loss 6.549 (average: 6.549)\n",
      "Train: [399][2/3]\ttraining loss 6.558 (average: 6.554)\n",
      "Train: [399][3/3]\ttraining loss 4.608 (average: 6.415)\n",
      "Test: [0/2]\tval Loss: 5.8983 (val loss average: 5.8983)\n",
      "Test: [1/2]\tval Loss: 5.7769 (val loss average: 5.8420)\n",
      "Train: [499][1/3]\ttraining loss 6.449 (average: 6.449)\n",
      "Train: [499][2/3]\ttraining loss 6.532 (average: 6.491)\n",
      "Train: [499][3/3]\ttraining loss 4.682 (average: 6.362)\n",
      "Test: [0/2]\tval Loss: 5.9217 (val loss average: 5.9217)\n",
      "Test: [1/2]\tval Loss: 5.8104 (val loss average: 5.8701)\n",
      "Train: [599][1/3]\ttraining loss 6.516 (average: 6.516)\n",
      "Train: [599][2/3]\ttraining loss 6.506 (average: 6.511)\n",
      "Train: [599][3/3]\ttraining loss 4.725 (average: 6.383)\n",
      "Test: [0/2]\tval Loss: 5.8486 (val loss average: 5.8486)\n",
      "Test: [1/2]\tval Loss: 5.6699 (val loss average: 5.7657)\n",
      "Train: [99][1/3]\ttraining loss 6.787 (average: 6.787)\n",
      "Train: [99][2/3]\ttraining loss 6.810 (average: 6.799)\n",
      "Train: [99][3/3]\ttraining loss 4.872 (average: 6.661)\n",
      "Test: [0/2]\tval Loss: 6.0560 (val loss average: 6.0560)\n",
      "Test: [1/2]\tval Loss: 5.9083 (val loss average: 5.9875)\n",
      "Train: [199][1/3]\ttraining loss 6.726 (average: 6.726)\n",
      "Train: [199][2/3]\ttraining loss 6.735 (average: 6.730)\n",
      "Train: [199][3/3]\ttraining loss 4.859 (average: 6.597)\n",
      "Test: [0/2]\tval Loss: 6.0278 (val loss average: 6.0278)\n",
      "Test: [1/2]\tval Loss: 5.9015 (val loss average: 5.9692)\n",
      "Train: [299][1/3]\ttraining loss 6.628 (average: 6.628)\n",
      "Train: [299][2/3]\ttraining loss 6.624 (average: 6.626)\n",
      "Train: [299][3/3]\ttraining loss 4.662 (average: 6.486)\n",
      "Test: [0/2]\tval Loss: 5.9318 (val loss average: 5.9318)\n",
      "Test: [1/2]\tval Loss: 5.7979 (val loss average: 5.8697)\n",
      "Train: [399][1/3]\ttraining loss 6.556 (average: 6.556)\n",
      "Train: [399][2/3]\ttraining loss 6.574 (average: 6.565)\n",
      "Train: [399][3/3]\ttraining loss 4.604 (average: 6.425)\n",
      "Test: [0/2]\tval Loss: 5.8172 (val loss average: 5.8172)\n",
      "Test: [1/2]\tval Loss: 5.7208 (val loss average: 5.7724)\n",
      "Train: [499][1/3]\ttraining loss 6.497 (average: 6.497)\n",
      "Train: [499][2/3]\ttraining loss 6.455 (average: 6.476)\n",
      "Train: [499][3/3]\ttraining loss 4.659 (average: 6.346)\n",
      "Test: [0/2]\tval Loss: 5.8904 (val loss average: 5.8904)\n",
      "Test: [1/2]\tval Loss: 5.7476 (val loss average: 5.8242)\n",
      "Train: [599][1/3]\ttraining loss 6.432 (average: 6.432)\n",
      "Train: [599][2/3]\ttraining loss 6.450 (average: 6.441)\n",
      "Train: [599][3/3]\ttraining loss 4.585 (average: 6.308)\n",
      "Test: [0/2]\tval Loss: 5.8495 (val loss average: 5.8495)\n",
      "Test: [1/2]\tval Loss: 5.9285 (val loss average: 5.8861)\n",
      "Train: [99][1/3]\ttraining loss 6.806 (average: 6.806)\n",
      "Train: [99][2/3]\ttraining loss 6.782 (average: 6.794)\n",
      "Train: [99][3/3]\ttraining loss 4.886 (average: 6.658)\n",
      "Test: [0/2]\tval Loss: 6.0498 (val loss average: 6.0498)\n",
      "Test: [1/2]\tval Loss: 5.9122 (val loss average: 5.9860)\n",
      "Train: [199][1/3]\ttraining loss 6.711 (average: 6.711)\n",
      "Train: [199][2/3]\ttraining loss 6.709 (average: 6.710)\n",
      "Train: [199][3/3]\ttraining loss 4.762 (average: 6.571)\n",
      "Test: [0/2]\tval Loss: 6.0121 (val loss average: 6.0121)\n",
      "Test: [1/2]\tval Loss: 5.8517 (val loss average: 5.9377)\n",
      "Train: [299][1/3]\ttraining loss 6.621 (average: 6.621)\n",
      "Train: [299][2/3]\ttraining loss 6.636 (average: 6.628)\n",
      "Train: [299][3/3]\ttraining loss 4.672 (average: 6.489)\n",
      "Test: [0/2]\tval Loss: 5.9095 (val loss average: 5.9095)\n",
      "Test: [1/2]\tval Loss: 5.8075 (val loss average: 5.8622)\n",
      "Train: [399][1/3]\ttraining loss 6.505 (average: 6.505)\n",
      "Train: [399][2/3]\ttraining loss 6.522 (average: 6.513)\n",
      "Train: [399][3/3]\ttraining loss 4.695 (average: 6.384)\n",
      "Test: [0/2]\tval Loss: 5.8613 (val loss average: 5.8613)\n",
      "Test: [1/2]\tval Loss: 5.6946 (val loss average: 5.7840)\n",
      "Train: [499][1/3]\ttraining loss 6.477 (average: 6.477)\n",
      "Train: [499][2/3]\ttraining loss 6.410 (average: 6.443)\n",
      "Train: [499][3/3]\ttraining loss 4.841 (average: 6.329)\n",
      "Test: [0/2]\tval Loss: 5.8902 (val loss average: 5.8902)\n",
      "Test: [1/2]\tval Loss: 5.7496 (val loss average: 5.8250)\n",
      "Train: [599][1/3]\ttraining loss 6.523 (average: 6.523)\n",
      "Train: [599][2/3]\ttraining loss 6.487 (average: 6.505)\n",
      "Train: [599][3/3]\ttraining loss 4.651 (average: 6.373)\n",
      "Test: [0/2]\tval Loss: 5.8503 (val loss average: 5.8503)\n",
      "Test: [1/2]\tval Loss: 5.6648 (val loss average: 5.7642)\n",
      "Train: [99][1/3]\ttraining loss 6.781 (average: 6.781)\n",
      "Train: [99][2/3]\ttraining loss 6.778 (average: 6.780)\n",
      "Train: [99][3/3]\ttraining loss 4.902 (average: 6.646)\n",
      "Test: [0/2]\tval Loss: 6.0178 (val loss average: 6.0178)\n",
      "Test: [1/2]\tval Loss: 5.8965 (val loss average: 5.9615)\n",
      "Train: [199][1/3]\ttraining loss 6.667 (average: 6.667)\n",
      "Train: [199][2/3]\ttraining loss 6.707 (average: 6.687)\n",
      "Train: [199][3/3]\ttraining loss 4.877 (average: 6.558)\n",
      "Test: [0/2]\tval Loss: 5.9388 (val loss average: 5.9388)\n",
      "Test: [1/2]\tval Loss: 5.7517 (val loss average: 5.8520)\n",
      "Train: [299][1/3]\ttraining loss 6.610 (average: 6.610)\n",
      "Train: [299][2/3]\ttraining loss 6.632 (average: 6.621)\n",
      "Train: [299][3/3]\ttraining loss 4.734 (average: 6.487)\n",
      "Test: [0/2]\tval Loss: 5.9074 (val loss average: 5.9074)\n",
      "Test: [1/2]\tval Loss: 5.7081 (val loss average: 5.8149)\n",
      "Train: [399][1/3]\ttraining loss 6.618 (average: 6.618)\n",
      "Train: [399][2/3]\ttraining loss 6.531 (average: 6.575)\n",
      "Train: [399][3/3]\ttraining loss 4.741 (average: 6.444)\n",
      "Test: [0/2]\tval Loss: 5.8243 (val loss average: 5.8243)\n",
      "Test: [1/2]\tval Loss: 5.7562 (val loss average: 5.7927)\n",
      "Train: [499][1/3]\ttraining loss 6.586 (average: 6.586)\n",
      "Train: [499][2/3]\ttraining loss 6.521 (average: 6.553)\n",
      "Train: [499][3/3]\ttraining loss 4.569 (average: 6.412)\n",
      "Test: [0/2]\tval Loss: 5.8253 (val loss average: 5.8253)\n",
      "Test: [1/2]\tval Loss: 5.6201 (val loss average: 5.7301)\n",
      "Train: [599][1/3]\ttraining loss 6.538 (average: 6.538)\n",
      "Train: [599][2/3]\ttraining loss 6.580 (average: 6.559)\n",
      "Train: [599][3/3]\ttraining loss 4.490 (average: 6.412)\n",
      "Test: [0/2]\tval Loss: 5.7371 (val loss average: 5.7371)\n",
      "Test: [1/2]\tval Loss: 5.6847 (val loss average: 5.7128)\n",
      "Train: [699][1/3]\ttraining loss 6.503 (average: 6.503)\n",
      "Train: [699][2/3]\ttraining loss 6.500 (average: 6.502)\n",
      "Train: [699][3/3]\ttraining loss 4.664 (average: 6.371)\n",
      "Test: [0/2]\tval Loss: 5.9567 (val loss average: 5.9567)\n",
      "Test: [1/2]\tval Loss: 5.7024 (val loss average: 5.8387)\n",
      "Train: [99][1/3]\ttraining loss 6.775 (average: 6.775)\n",
      "Train: [99][2/3]\ttraining loss 6.756 (average: 6.765)\n",
      "Train: [99][3/3]\ttraining loss 4.914 (average: 6.634)\n",
      "Test: [0/2]\tval Loss: 5.9726 (val loss average: 5.9726)\n",
      "Test: [1/2]\tval Loss: 5.8846 (val loss average: 5.9318)\n",
      "Train: [199][1/3]\ttraining loss 6.642 (average: 6.642)\n",
      "Train: [199][2/3]\ttraining loss 6.645 (average: 6.643)\n",
      "Train: [199][3/3]\ttraining loss 4.741 (average: 6.508)\n",
      "Test: [0/2]\tval Loss: 5.9611 (val loss average: 5.9611)\n",
      "Test: [1/2]\tval Loss: 5.7706 (val loss average: 5.8727)\n",
      "Train: [299][1/3]\ttraining loss 6.553 (average: 6.553)\n",
      "Train: [299][2/3]\ttraining loss 6.534 (average: 6.544)\n",
      "Train: [299][3/3]\ttraining loss 4.734 (average: 6.415)\n",
      "Test: [0/2]\tval Loss: 5.9506 (val loss average: 5.9506)\n",
      "Test: [1/2]\tval Loss: 5.6335 (val loss average: 5.8035)\n",
      "Train: [399][1/3]\ttraining loss 6.521 (average: 6.521)\n",
      "Train: [399][2/3]\ttraining loss 6.475 (average: 6.498)\n",
      "Train: [399][3/3]\ttraining loss 4.652 (average: 6.367)\n",
      "Test: [0/2]\tval Loss: 5.7680 (val loss average: 5.7680)\n",
      "Test: [1/2]\tval Loss: 5.5869 (val loss average: 5.6840)\n",
      "Train: [499][1/3]\ttraining loss 6.418 (average: 6.418)\n",
      "Train: [499][2/3]\ttraining loss 6.426 (average: 6.422)\n",
      "Train: [499][3/3]\ttraining loss 4.805 (average: 6.307)\n",
      "Test: [0/2]\tval Loss: 5.8712 (val loss average: 5.8712)\n",
      "Test: [1/2]\tval Loss: 5.7676 (val loss average: 5.8231)\n",
      "Train: [599][1/3]\ttraining loss 6.448 (average: 6.448)\n",
      "Train: [599][2/3]\ttraining loss 6.400 (average: 6.424)\n",
      "Train: [599][3/3]\ttraining loss 4.515 (average: 6.288)\n",
      "Test: [0/2]\tval Loss: 5.8813 (val loss average: 5.8813)\n",
      "Test: [1/2]\tval Loss: 5.6724 (val loss average: 5.7844)\n",
      "Train: [99][1/3]\ttraining loss 6.745 (average: 6.745)\n",
      "Train: [99][2/3]\ttraining loss 6.739 (average: 6.742)\n",
      "Train: [99][3/3]\ttraining loss 4.796 (average: 6.603)\n",
      "Test: [0/2]\tval Loss: 5.9594 (val loss average: 5.9594)\n",
      "Test: [1/2]\tval Loss: 5.8747 (val loss average: 5.9201)\n",
      "Train: [199][1/3]\ttraining loss 6.609 (average: 6.609)\n",
      "Train: [199][2/3]\ttraining loss 6.583 (average: 6.596)\n",
      "Train: [199][3/3]\ttraining loss 4.826 (average: 6.470)\n",
      "Test: [0/2]\tval Loss: 5.8690 (val loss average: 5.8690)\n",
      "Test: [1/2]\tval Loss: 5.7301 (val loss average: 5.8046)\n",
      "Train: [299][1/3]\ttraining loss 6.534 (average: 6.534)\n",
      "Train: [299][2/3]\ttraining loss 6.516 (average: 6.525)\n",
      "Train: [299][3/3]\ttraining loss 4.693 (average: 6.395)\n",
      "Test: [0/2]\tval Loss: 5.8166 (val loss average: 5.8166)\n",
      "Test: [1/2]\tval Loss: 5.7680 (val loss average: 5.7941)\n",
      "Train: [399][1/3]\ttraining loss 6.523 (average: 6.523)\n",
      "Train: [399][2/3]\ttraining loss 6.444 (average: 6.484)\n",
      "Train: [399][3/3]\ttraining loss 4.630 (average: 6.352)\n",
      "Test: [0/2]\tval Loss: 5.9084 (val loss average: 5.9084)\n",
      "Test: [1/2]\tval Loss: 5.7334 (val loss average: 5.8272)\n",
      "Train: [499][1/3]\ttraining loss 6.428 (average: 6.428)\n",
      "Train: [499][2/3]\ttraining loss 6.461 (average: 6.445)\n",
      "Train: [499][3/3]\ttraining loss 4.664 (average: 6.318)\n",
      "Test: [0/2]\tval Loss: 5.9273 (val loss average: 5.9273)\n",
      "Test: [1/2]\tval Loss: 5.7054 (val loss average: 5.8244)\n",
      "Train: [599][1/3]\ttraining loss 6.369 (average: 6.369)\n",
      "Train: [599][2/3]\ttraining loss 6.461 (average: 6.415)\n",
      "Train: [599][3/3]\ttraining loss 4.700 (average: 6.293)\n",
      "Test: [0/2]\tval Loss: 5.8516 (val loss average: 5.8516)\n",
      "Test: [1/2]\tval Loss: 5.7595 (val loss average: 5.8089)\n",
      "Train: [99][1/3]\ttraining loss 6.764 (average: 6.764)\n",
      "Train: [99][2/3]\ttraining loss 6.753 (average: 6.759)\n",
      "Train: [99][3/3]\ttraining loss 4.873 (average: 6.625)\n",
      "Test: [0/2]\tval Loss: 6.0078 (val loss average: 6.0078)\n",
      "Test: [1/2]\tval Loss: 5.7979 (val loss average: 5.9104)\n",
      "Train: [199][1/3]\ttraining loss 6.704 (average: 6.704)\n",
      "Train: [199][2/3]\ttraining loss 6.674 (average: 6.689)\n",
      "Train: [199][3/3]\ttraining loss 4.690 (average: 6.546)\n",
      "Test: [0/2]\tval Loss: 5.9805 (val loss average: 5.9805)\n",
      "Test: [1/2]\tval Loss: 5.8489 (val loss average: 5.9195)\n",
      "Train: [299][1/3]\ttraining loss 6.597 (average: 6.597)\n",
      "Train: [299][2/3]\ttraining loss 6.583 (average: 6.590)\n",
      "Train: [299][3/3]\ttraining loss 4.592 (average: 6.448)\n",
      "Test: [0/2]\tval Loss: 5.8314 (val loss average: 5.8314)\n",
      "Test: [1/2]\tval Loss: 5.6438 (val loss average: 5.7444)\n",
      "Train: [399][1/3]\ttraining loss 6.549 (average: 6.549)\n",
      "Train: [399][2/3]\ttraining loss 6.531 (average: 6.540)\n",
      "Train: [399][3/3]\ttraining loss 4.669 (average: 6.407)\n",
      "Test: [0/2]\tval Loss: 5.8220 (val loss average: 5.8220)\n",
      "Test: [1/2]\tval Loss: 5.6747 (val loss average: 5.7536)\n",
      "Train: [499][1/3]\ttraining loss 6.523 (average: 6.523)\n",
      "Train: [499][2/3]\ttraining loss 6.545 (average: 6.534)\n",
      "Train: [499][3/3]\ttraining loss 4.534 (average: 6.392)\n",
      "Test: [0/2]\tval Loss: 5.8997 (val loss average: 5.8997)\n",
      "Test: [1/2]\tval Loss: 5.7750 (val loss average: 5.8419)\n",
      "Train: [599][1/3]\ttraining loss 6.477 (average: 6.477)\n",
      "Train: [599][2/3]\ttraining loss 6.504 (average: 6.491)\n",
      "Train: [599][3/3]\ttraining loss 4.439 (average: 6.345)\n",
      "Test: [0/2]\tval Loss: 5.7391 (val loss average: 5.7391)\n",
      "Test: [1/2]\tval Loss: 5.6303 (val loss average: 5.6886)\n",
      "Train: [99][1/3]\ttraining loss 6.794 (average: 6.794)\n",
      "Train: [99][2/3]\ttraining loss 6.790 (average: 6.792)\n",
      "Train: [99][3/3]\ttraining loss 4.918 (average: 6.658)\n",
      "Test: [0/2]\tval Loss: 6.0213 (val loss average: 6.0213)\n",
      "Test: [1/2]\tval Loss: 5.8540 (val loss average: 5.9437)\n",
      "Train: [199][1/3]\ttraining loss 6.734 (average: 6.734)\n",
      "Train: [199][2/3]\ttraining loss 6.683 (average: 6.708)\n",
      "Train: [199][3/3]\ttraining loss 4.732 (average: 6.568)\n",
      "Test: [0/2]\tval Loss: 5.9227 (val loss average: 5.9227)\n",
      "Test: [1/2]\tval Loss: 5.7837 (val loss average: 5.8582)\n",
      "Train: [299][1/3]\ttraining loss 6.571 (average: 6.571)\n",
      "Train: [299][2/3]\ttraining loss 6.634 (average: 6.602)\n",
      "Train: [299][3/3]\ttraining loss 4.750 (average: 6.470)\n",
      "Test: [0/2]\tval Loss: 5.9008 (val loss average: 5.9008)\n",
      "Test: [1/2]\tval Loss: 5.7385 (val loss average: 5.8255)\n",
      "Train: [399][1/3]\ttraining loss 6.527 (average: 6.527)\n",
      "Train: [399][2/3]\ttraining loss 6.544 (average: 6.536)\n",
      "Train: [399][3/3]\ttraining loss 4.733 (average: 6.407)\n",
      "Test: [0/2]\tval Loss: 5.7624 (val loss average: 5.7624)\n",
      "Test: [1/2]\tval Loss: 5.6951 (val loss average: 5.7312)\n",
      "Train: [499][1/3]\ttraining loss 6.510 (average: 6.510)\n",
      "Train: [499][2/3]\ttraining loss 6.460 (average: 6.485)\n",
      "Train: [499][3/3]\ttraining loss 4.696 (average: 6.358)\n",
      "Test: [0/2]\tval Loss: 5.7910 (val loss average: 5.7910)\n",
      "Test: [1/2]\tval Loss: 5.7636 (val loss average: 5.7783)\n",
      "Train: [599][1/3]\ttraining loss 6.465 (average: 6.465)\n",
      "Train: [599][2/3]\ttraining loss 6.434 (average: 6.449)\n",
      "Train: [599][3/3]\ttraining loss 4.654 (average: 6.321)\n",
      "Test: [0/2]\tval Loss: 5.9055 (val loss average: 5.9055)\n",
      "Test: [1/2]\tval Loss: 5.6937 (val loss average: 5.8072)\n",
      "Train: [99][1/3]\ttraining loss 6.768 (average: 6.768)\n",
      "Train: [99][2/3]\ttraining loss 6.757 (average: 6.762)\n",
      "Train: [99][3/3]\ttraining loss 4.863 (average: 6.627)\n",
      "Test: [0/2]\tval Loss: 6.0066 (val loss average: 6.0066)\n",
      "Test: [1/2]\tval Loss: 5.8676 (val loss average: 5.9421)\n",
      "Train: [199][1/3]\ttraining loss 6.621 (average: 6.621)\n",
      "Train: [199][2/3]\ttraining loss 6.602 (average: 6.612)\n",
      "Train: [199][3/3]\ttraining loss 4.784 (average: 6.482)\n",
      "Test: [0/2]\tval Loss: 5.8541 (val loss average: 5.8541)\n",
      "Test: [1/2]\tval Loss: 5.7663 (val loss average: 5.8134)\n",
      "Train: [299][1/3]\ttraining loss 6.576 (average: 6.576)\n",
      "Train: [299][2/3]\ttraining loss 6.569 (average: 6.572)\n",
      "Train: [299][3/3]\ttraining loss 4.785 (average: 6.445)\n",
      "Test: [0/2]\tval Loss: 5.7988 (val loss average: 5.7988)\n",
      "Test: [1/2]\tval Loss: 5.6914 (val loss average: 5.7490)\n",
      "Train: [399][1/3]\ttraining loss 6.519 (average: 6.519)\n",
      "Train: [399][2/3]\ttraining loss 6.559 (average: 6.539)\n",
      "Train: [399][3/3]\ttraining loss 4.577 (average: 6.400)\n",
      "Test: [0/2]\tval Loss: 5.7981 (val loss average: 5.7981)\n",
      "Test: [1/2]\tval Loss: 5.6381 (val loss average: 5.7239)\n",
      "Train: [499][1/3]\ttraining loss 6.555 (average: 6.555)\n",
      "Train: [499][2/3]\ttraining loss 6.503 (average: 6.529)\n",
      "Train: [499][3/3]\ttraining loss 4.607 (average: 6.392)\n",
      "Test: [0/2]\tval Loss: 5.8024 (val loss average: 5.8024)\n",
      "Test: [1/2]\tval Loss: 5.6759 (val loss average: 5.7437)\n",
      "Train: [599][1/3]\ttraining loss 6.475 (average: 6.475)\n",
      "Train: [599][2/3]\ttraining loss 6.489 (average: 6.482)\n",
      "Train: [599][3/3]\ttraining loss 4.742 (average: 6.358)\n",
      "Test: [0/2]\tval Loss: 5.8343 (val loss average: 5.8343)\n",
      "Test: [1/2]\tval Loss: 5.6104 (val loss average: 5.7304)\n",
      "Train: [99][1/3]\ttraining loss 6.786 (average: 6.786)\n",
      "Train: [99][2/3]\ttraining loss 6.776 (average: 6.781)\n",
      "Train: [99][3/3]\ttraining loss 4.864 (average: 6.645)\n",
      "Test: [0/2]\tval Loss: 6.0329 (val loss average: 6.0329)\n",
      "Test: [1/2]\tval Loss: 5.8229 (val loss average: 5.9355)\n",
      "Train: [199][1/3]\ttraining loss 6.710 (average: 6.710)\n",
      "Train: [199][2/3]\ttraining loss 6.652 (average: 6.681)\n",
      "Train: [199][3/3]\ttraining loss 4.862 (average: 6.552)\n",
      "Test: [0/2]\tval Loss: 5.9498 (val loss average: 5.9498)\n",
      "Test: [1/2]\tval Loss: 5.8128 (val loss average: 5.8862)\n",
      "Train: [299][1/3]\ttraining loss 6.637 (average: 6.637)\n",
      "Train: [299][2/3]\ttraining loss 6.627 (average: 6.632)\n",
      "Train: [299][3/3]\ttraining loss 4.713 (average: 6.495)\n",
      "Test: [0/2]\tval Loss: 5.8646 (val loss average: 5.8646)\n",
      "Test: [1/2]\tval Loss: 5.7464 (val loss average: 5.8098)\n",
      "Train: [399][1/3]\ttraining loss 6.569 (average: 6.569)\n",
      "Train: [399][2/3]\ttraining loss 6.569 (average: 6.569)\n",
      "Train: [399][3/3]\ttraining loss 4.778 (average: 6.442)\n",
      "Test: [0/2]\tval Loss: 5.9132 (val loss average: 5.9132)\n",
      "Test: [1/2]\tval Loss: 5.6833 (val loss average: 5.8065)\n",
      "Train: [499][1/3]\ttraining loss 6.638 (average: 6.638)\n",
      "Train: [499][2/3]\ttraining loss 6.598 (average: 6.618)\n",
      "Train: [499][3/3]\ttraining loss 4.646 (average: 6.477)\n",
      "Test: [0/2]\tval Loss: 5.9103 (val loss average: 5.9103)\n",
      "Test: [1/2]\tval Loss: 5.6724 (val loss average: 5.7999)\n",
      "Train: [599][1/3]\ttraining loss 6.546 (average: 6.546)\n",
      "Train: [599][2/3]\ttraining loss 6.584 (average: 6.565)\n",
      "Train: [599][3/3]\ttraining loss 4.613 (average: 6.426)\n",
      "Test: [0/2]\tval Loss: 5.7819 (val loss average: 5.7819)\n",
      "Test: [1/2]\tval Loss: 5.7515 (val loss average: 5.7678)\n",
      "Train: [99][1/3]\ttraining loss 6.788 (average: 6.788)\n",
      "Train: [99][2/3]\ttraining loss 6.773 (average: 6.781)\n",
      "Train: [99][3/3]\ttraining loss 4.884 (average: 6.646)\n",
      "Test: [0/2]\tval Loss: 6.0429 (val loss average: 6.0429)\n",
      "Test: [1/2]\tval Loss: 5.8978 (val loss average: 5.9756)\n",
      "Train: [199][1/3]\ttraining loss 6.671 (average: 6.671)\n",
      "Train: [199][2/3]\ttraining loss 6.654 (average: 6.662)\n",
      "Train: [199][3/3]\ttraining loss 4.790 (average: 6.529)\n",
      "Test: [0/2]\tval Loss: 6.0023 (val loss average: 6.0023)\n",
      "Test: [1/2]\tval Loss: 5.9013 (val loss average: 5.9555)\n",
      "Train: [299][1/3]\ttraining loss 6.636 (average: 6.636)\n",
      "Train: [299][2/3]\ttraining loss 6.612 (average: 6.624)\n",
      "Train: [299][3/3]\ttraining loss 4.614 (average: 6.481)\n",
      "Test: [0/2]\tval Loss: 5.9380 (val loss average: 5.9380)\n",
      "Test: [1/2]\tval Loss: 5.7952 (val loss average: 5.8718)\n",
      "Train: [399][1/3]\ttraining loss 6.602 (average: 6.602)\n",
      "Train: [399][2/3]\ttraining loss 6.556 (average: 6.579)\n",
      "Train: [399][3/3]\ttraining loss 4.544 (average: 6.434)\n",
      "Test: [0/2]\tval Loss: 5.8793 (val loss average: 5.8793)\n",
      "Test: [1/2]\tval Loss: 5.7712 (val loss average: 5.8291)\n",
      "Train: [499][1/3]\ttraining loss 6.515 (average: 6.515)\n",
      "Train: [499][2/3]\ttraining loss 6.557 (average: 6.536)\n",
      "Train: [499][3/3]\ttraining loss 4.542 (average: 6.394)\n",
      "Test: [0/2]\tval Loss: 5.9549 (val loss average: 5.9549)\n",
      "Test: [1/2]\tval Loss: 5.7895 (val loss average: 5.8782)\n",
      "Train: [599][1/3]\ttraining loss 6.513 (average: 6.513)\n",
      "Train: [599][2/3]\ttraining loss 6.545 (average: 6.529)\n",
      "Train: [599][3/3]\ttraining loss 4.622 (average: 6.393)\n",
      "Test: [0/2]\tval Loss: 5.9851 (val loss average: 5.9851)\n",
      "Test: [1/2]\tval Loss: 5.7443 (val loss average: 5.8734)\n",
      "Train: [99][1/3]\ttraining loss 6.755 (average: 6.755)\n",
      "Train: [99][2/3]\ttraining loss 6.778 (average: 6.766)\n",
      "Train: [99][3/3]\ttraining loss 4.821 (average: 6.628)\n",
      "Test: [0/2]\tval Loss: 5.9916 (val loss average: 5.9916)\n",
      "Test: [1/2]\tval Loss: 5.8434 (val loss average: 5.9229)\n",
      "Train: [199][1/3]\ttraining loss 6.591 (average: 6.591)\n",
      "Train: [199][2/3]\ttraining loss 6.638 (average: 6.615)\n",
      "Train: [199][3/3]\ttraining loss 4.783 (average: 6.484)\n",
      "Test: [0/2]\tval Loss: 5.8427 (val loss average: 5.8427)\n",
      "Test: [1/2]\tval Loss: 5.7143 (val loss average: 5.7831)\n",
      "Train: [299][1/3]\ttraining loss 6.495 (average: 6.495)\n",
      "Train: [299][2/3]\ttraining loss 6.527 (average: 6.511)\n",
      "Train: [299][3/3]\ttraining loss 4.478 (average: 6.367)\n",
      "Test: [0/2]\tval Loss: 5.9511 (val loss average: 5.9511)\n",
      "Test: [1/2]\tval Loss: 5.8085 (val loss average: 5.8849)\n",
      "Train: [399][1/3]\ttraining loss 6.467 (average: 6.467)\n",
      "Train: [399][2/3]\ttraining loss 6.483 (average: 6.475)\n",
      "Train: [399][3/3]\ttraining loss 4.626 (average: 6.343)\n",
      "Test: [0/2]\tval Loss: 5.8915 (val loss average: 5.8915)\n",
      "Test: [1/2]\tval Loss: 5.7301 (val loss average: 5.8166)\n",
      "Train: [499][1/3]\ttraining loss 6.520 (average: 6.520)\n",
      "Train: [499][2/3]\ttraining loss 6.460 (average: 6.490)\n",
      "Train: [499][3/3]\ttraining loss 4.508 (average: 6.349)\n",
      "Test: [0/2]\tval Loss: 5.9234 (val loss average: 5.9234)\n",
      "Test: [1/2]\tval Loss: 5.7132 (val loss average: 5.8259)\n",
      "Train: [599][1/3]\ttraining loss 6.483 (average: 6.483)\n",
      "Train: [599][2/3]\ttraining loss 6.389 (average: 6.436)\n",
      "Train: [599][3/3]\ttraining loss 4.585 (average: 6.304)\n",
      "Test: [0/2]\tval Loss: 5.9586 (val loss average: 5.9586)\n",
      "Test: [1/2]\tval Loss: 5.7962 (val loss average: 5.8833)\n",
      "Train: [699][1/3]\ttraining loss 6.399 (average: 6.399)\n",
      "Train: [699][2/3]\ttraining loss 6.381 (average: 6.390)\n",
      "Train: [699][3/3]\ttraining loss 4.356 (average: 6.245)\n",
      "Test: [0/2]\tval Loss: 5.9490 (val loss average: 5.9490)\n",
      "Test: [1/2]\tval Loss: 5.8291 (val loss average: 5.8934)\n",
      "Train: [99][1/3]\ttraining loss 6.795 (average: 6.795)\n",
      "Train: [99][2/3]\ttraining loss 6.716 (average: 6.755)\n",
      "Train: [99][3/3]\ttraining loss 4.930 (average: 6.625)\n",
      "Test: [0/2]\tval Loss: 6.0250 (val loss average: 6.0250)\n",
      "Test: [1/2]\tval Loss: 5.9016 (val loss average: 5.9677)\n",
      "Train: [199][1/3]\ttraining loss 6.625 (average: 6.625)\n",
      "Train: [199][2/3]\ttraining loss 6.656 (average: 6.640)\n",
      "Train: [199][3/3]\ttraining loss 4.875 (average: 6.515)\n",
      "Test: [0/2]\tval Loss: 5.9582 (val loss average: 5.9582)\n",
      "Test: [1/2]\tval Loss: 5.8002 (val loss average: 5.8849)\n",
      "Train: [299][1/3]\ttraining loss 6.553 (average: 6.553)\n",
      "Train: [299][2/3]\ttraining loss 6.571 (average: 6.562)\n",
      "Train: [299][3/3]\ttraining loss 4.724 (average: 6.431)\n",
      "Test: [0/2]\tval Loss: 5.9260 (val loss average: 5.9260)\n",
      "Test: [1/2]\tval Loss: 5.6787 (val loss average: 5.8112)\n",
      "Train: [399][1/3]\ttraining loss 6.574 (average: 6.574)\n",
      "Train: [399][2/3]\ttraining loss 6.612 (average: 6.593)\n",
      "Train: [399][3/3]\ttraining loss 4.605 (average: 6.451)\n",
      "Test: [0/2]\tval Loss: 5.8857 (val loss average: 5.8857)\n",
      "Test: [1/2]\tval Loss: 5.8106 (val loss average: 5.8509)\n",
      "Train: [499][1/3]\ttraining loss 6.492 (average: 6.492)\n",
      "Train: [499][2/3]\ttraining loss 6.506 (average: 6.499)\n",
      "Train: [499][3/3]\ttraining loss 4.648 (average: 6.367)\n",
      "Test: [0/2]\tval Loss: 6.0302 (val loss average: 6.0302)\n",
      "Test: [1/2]\tval Loss: 5.8189 (val loss average: 5.9322)\n",
      "Train: [599][1/3]\ttraining loss 6.412 (average: 6.412)\n",
      "Train: [599][2/3]\ttraining loss 6.583 (average: 6.497)\n",
      "Train: [599][3/3]\ttraining loss 4.696 (average: 6.369)\n",
      "Test: [0/2]\tval Loss: 5.8618 (val loss average: 5.8618)\n",
      "Test: [1/2]\tval Loss: 5.8145 (val loss average: 5.8398)\n",
      "Train: [99][1/3]\ttraining loss 6.740 (average: 6.740)\n",
      "Train: [99][2/3]\ttraining loss 6.786 (average: 6.763)\n",
      "Train: [99][3/3]\ttraining loss 4.744 (average: 6.619)\n",
      "Test: [0/2]\tval Loss: 5.9998 (val loss average: 5.9998)\n",
      "Test: [1/2]\tval Loss: 5.8947 (val loss average: 5.9510)\n",
      "Train: [199][1/3]\ttraining loss 6.714 (average: 6.714)\n",
      "Train: [199][2/3]\ttraining loss 6.703 (average: 6.708)\n",
      "Train: [199][3/3]\ttraining loss 4.713 (average: 6.566)\n",
      "Test: [0/2]\tval Loss: 5.9781 (val loss average: 5.9781)\n",
      "Test: [1/2]\tval Loss: 5.8287 (val loss average: 5.9088)\n",
      "Train: [299][1/3]\ttraining loss 6.603 (average: 6.603)\n",
      "Train: [299][2/3]\ttraining loss 6.540 (average: 6.571)\n",
      "Train: [299][3/3]\ttraining loss 4.593 (average: 6.430)\n",
      "Test: [0/2]\tval Loss: 5.9162 (val loss average: 5.9162)\n",
      "Test: [1/2]\tval Loss: 5.8165 (val loss average: 5.8700)\n",
      "Train: [399][1/3]\ttraining loss 6.464 (average: 6.464)\n",
      "Train: [399][2/3]\ttraining loss 6.477 (average: 6.470)\n",
      "Train: [399][3/3]\ttraining loss 4.649 (average: 6.341)\n",
      "Test: [0/2]\tval Loss: 5.8450 (val loss average: 5.8450)\n",
      "Test: [1/2]\tval Loss: 5.6297 (val loss average: 5.7451)\n",
      "Train: [499][1/3]\ttraining loss 6.420 (average: 6.420)\n",
      "Train: [499][2/3]\ttraining loss 6.453 (average: 6.437)\n",
      "Train: [499][3/3]\ttraining loss 4.433 (average: 6.294)\n",
      "Test: [0/2]\tval Loss: 5.8801 (val loss average: 5.8801)\n",
      "Test: [1/2]\tval Loss: 5.8482 (val loss average: 5.8653)\n",
      "Train: [599][1/3]\ttraining loss 6.378 (average: 6.378)\n",
      "Train: [599][2/3]\ttraining loss 6.368 (average: 6.373)\n",
      "Train: [599][3/3]\ttraining loss 4.557 (average: 6.244)\n",
      "Test: [0/2]\tval Loss: 5.9261 (val loss average: 5.9261)\n",
      "Test: [1/2]\tval Loss: 5.7313 (val loss average: 5.8357)\n",
      "Train: [699][1/3]\ttraining loss 6.395 (average: 6.395)\n",
      "Train: [699][2/3]\ttraining loss 6.412 (average: 6.403)\n",
      "Train: [699][3/3]\ttraining loss 4.580 (average: 6.274)\n",
      "Test: [0/2]\tval Loss: 5.8271 (val loss average: 5.8271)\n",
      "Test: [1/2]\tval Loss: 5.7760 (val loss average: 5.8034)\n",
      "Train: [99][1/3]\ttraining loss 6.805 (average: 6.805)\n",
      "Train: [99][2/3]\ttraining loss 6.776 (average: 6.791)\n",
      "Train: [99][3/3]\ttraining loss 4.883 (average: 6.655)\n",
      "Test: [0/2]\tval Loss: 6.0250 (val loss average: 6.0250)\n",
      "Test: [1/2]\tval Loss: 5.8991 (val loss average: 5.9666)\n",
      "Train: [199][1/3]\ttraining loss 6.679 (average: 6.679)\n",
      "Train: [199][2/3]\ttraining loss 6.642 (average: 6.661)\n",
      "Train: [199][3/3]\ttraining loss 4.874 (average: 6.534)\n",
      "Test: [0/2]\tval Loss: 5.9958 (val loss average: 5.9958)\n",
      "Test: [1/2]\tval Loss: 5.8295 (val loss average: 5.9186)\n",
      "Train: [299][1/3]\ttraining loss 6.586 (average: 6.586)\n",
      "Train: [299][2/3]\ttraining loss 6.572 (average: 6.579)\n",
      "Train: [299][3/3]\ttraining loss 4.698 (average: 6.445)\n",
      "Test: [0/2]\tval Loss: 5.8939 (val loss average: 5.8939)\n",
      "Test: [1/2]\tval Loss: 5.7512 (val loss average: 5.8277)\n",
      "Train: [399][1/3]\ttraining loss 6.569 (average: 6.569)\n",
      "Train: [399][2/3]\ttraining loss 6.513 (average: 6.541)\n",
      "Train: [399][3/3]\ttraining loss 4.561 (average: 6.400)\n",
      "Test: [0/2]\tval Loss: 5.8394 (val loss average: 5.8394)\n",
      "Test: [1/2]\tval Loss: 5.7441 (val loss average: 5.7952)\n",
      "Train: [499][1/3]\ttraining loss 6.497 (average: 6.497)\n",
      "Train: [499][2/3]\ttraining loss 6.497 (average: 6.497)\n",
      "Train: [499][3/3]\ttraining loss 4.536 (average: 6.357)\n",
      "Test: [0/2]\tval Loss: 5.8233 (val loss average: 5.8233)\n",
      "Test: [1/2]\tval Loss: 5.6900 (val loss average: 5.7614)\n",
      "Train: [599][1/3]\ttraining loss 6.473 (average: 6.473)\n",
      "Train: [599][2/3]\ttraining loss 6.441 (average: 6.457)\n",
      "Train: [599][3/3]\ttraining loss 4.567 (average: 6.322)\n",
      "Test: [0/2]\tval Loss: 5.8054 (val loss average: 5.8054)\n",
      "Test: [1/2]\tval Loss: 5.6055 (val loss average: 5.7127)\n",
      "Train: [99][1/3]\ttraining loss 6.796 (average: 6.796)\n",
      "Train: [99][2/3]\ttraining loss 6.765 (average: 6.780)\n",
      "Train: [99][3/3]\ttraining loss 4.874 (average: 6.644)\n",
      "Test: [0/2]\tval Loss: 6.0178 (val loss average: 6.0178)\n",
      "Test: [1/2]\tval Loss: 5.8696 (val loss average: 5.9491)\n",
      "Train: [199][1/3]\ttraining loss 6.618 (average: 6.618)\n",
      "Train: [199][2/3]\ttraining loss 6.645 (average: 6.631)\n",
      "Train: [199][3/3]\ttraining loss 4.756 (average: 6.498)\n",
      "Test: [0/2]\tval Loss: 6.0044 (val loss average: 6.0044)\n",
      "Test: [1/2]\tval Loss: 5.8541 (val loss average: 5.9347)\n",
      "Train: [299][1/3]\ttraining loss 6.527 (average: 6.527)\n",
      "Train: [299][2/3]\ttraining loss 6.511 (average: 6.519)\n",
      "Train: [299][3/3]\ttraining loss 4.584 (average: 6.381)\n",
      "Test: [0/2]\tval Loss: 5.8564 (val loss average: 5.8564)\n",
      "Test: [1/2]\tval Loss: 5.6228 (val loss average: 5.7480)\n",
      "Train: [399][1/3]\ttraining loss 6.538 (average: 6.538)\n",
      "Train: [399][2/3]\ttraining loss 6.498 (average: 6.518)\n",
      "Train: [399][3/3]\ttraining loss 4.594 (average: 6.381)\n",
      "Test: [0/2]\tval Loss: 5.8233 (val loss average: 5.8233)\n",
      "Test: [1/2]\tval Loss: 5.8210 (val loss average: 5.8222)\n",
      "Train: [499][1/3]\ttraining loss 6.492 (average: 6.492)\n",
      "Train: [499][2/3]\ttraining loss 6.459 (average: 6.476)\n",
      "Train: [499][3/3]\ttraining loss 4.683 (average: 6.348)\n",
      "Test: [0/2]\tval Loss: 5.8614 (val loss average: 5.8614)\n",
      "Test: [1/2]\tval Loss: 5.5235 (val loss average: 5.7047)\n",
      "Train: [599][1/3]\ttraining loss 6.371 (average: 6.371)\n",
      "Train: [599][2/3]\ttraining loss 6.442 (average: 6.407)\n",
      "Train: [599][3/3]\ttraining loss 4.794 (average: 6.292)\n",
      "Test: [0/2]\tval Loss: 5.8351 (val loss average: 5.8351)\n",
      "Test: [1/2]\tval Loss: 5.7621 (val loss average: 5.8012)\n",
      "Train: [99][1/3]\ttraining loss 6.803 (average: 6.803)\n",
      "Train: [99][2/3]\ttraining loss 6.773 (average: 6.788)\n",
      "Train: [99][3/3]\ttraining loss 4.905 (average: 6.654)\n",
      "Test: [0/2]\tval Loss: 6.0568 (val loss average: 6.0568)\n",
      "Test: [1/2]\tval Loss: 5.8957 (val loss average: 5.9821)\n",
      "Train: [199][1/3]\ttraining loss 6.723 (average: 6.723)\n",
      "Train: [199][2/3]\ttraining loss 6.726 (average: 6.725)\n",
      "Train: [199][3/3]\ttraining loss 4.821 (average: 6.589)\n",
      "Test: [0/2]\tval Loss: 5.9619 (val loss average: 5.9619)\n",
      "Test: [1/2]\tval Loss: 5.7050 (val loss average: 5.8427)\n",
      "Train: [299][1/3]\ttraining loss 6.709 (average: 6.709)\n",
      "Train: [299][2/3]\ttraining loss 6.673 (average: 6.691)\n",
      "Train: [299][3/3]\ttraining loss 4.764 (average: 6.554)\n",
      "Test: [0/2]\tval Loss: 5.9220 (val loss average: 5.9220)\n",
      "Test: [1/2]\tval Loss: 5.7776 (val loss average: 5.8550)\n",
      "Train: [399][1/3]\ttraining loss 6.526 (average: 6.526)\n",
      "Train: [399][2/3]\ttraining loss 6.574 (average: 6.550)\n",
      "Train: [399][3/3]\ttraining loss 4.672 (average: 6.416)\n",
      "Test: [0/2]\tval Loss: 5.9151 (val loss average: 5.9151)\n",
      "Test: [1/2]\tval Loss: 5.7440 (val loss average: 5.8357)\n",
      "Train: [499][1/3]\ttraining loss 6.473 (average: 6.473)\n",
      "Train: [499][2/3]\ttraining loss 6.571 (average: 6.522)\n",
      "Train: [499][3/3]\ttraining loss 4.621 (average: 6.386)\n",
      "Test: [0/2]\tval Loss: 5.8451 (val loss average: 5.8451)\n",
      "Test: [1/2]\tval Loss: 5.7379 (val loss average: 5.7954)\n",
      "Train: [599][1/3]\ttraining loss 6.543 (average: 6.543)\n",
      "Train: [599][2/3]\ttraining loss 6.545 (average: 6.544)\n",
      "Train: [599][3/3]\ttraining loss 4.564 (average: 6.403)\n",
      "Test: [0/2]\tval Loss: 5.8452 (val loss average: 5.8452)\n",
      "Test: [1/2]\tval Loss: 5.6895 (val loss average: 5.7730)\n",
      "Train: [699][1/3]\ttraining loss 6.454 (average: 6.454)\n",
      "Train: [699][2/3]\ttraining loss 6.443 (average: 6.449)\n",
      "Train: [699][3/3]\ttraining loss 4.625 (average: 6.319)\n",
      "Test: [0/2]\tval Loss: 5.6998 (val loss average: 5.6998)\n",
      "Test: [1/2]\tval Loss: 5.6702 (val loss average: 5.6861)\n",
      "Train: [99][1/3]\ttraining loss 6.766 (average: 6.766)\n",
      "Train: [99][2/3]\ttraining loss 6.766 (average: 6.766)\n",
      "Train: [99][3/3]\ttraining loss 4.838 (average: 6.629)\n",
      "Test: [0/2]\tval Loss: 6.0481 (val loss average: 6.0481)\n",
      "Test: [1/2]\tval Loss: 5.8919 (val loss average: 5.9756)\n",
      "Train: [199][1/3]\ttraining loss 6.630 (average: 6.630)\n",
      "Train: [199][2/3]\ttraining loss 6.636 (average: 6.633)\n",
      "Train: [199][3/3]\ttraining loss 4.847 (average: 6.506)\n",
      "Test: [0/2]\tval Loss: 5.9412 (val loss average: 5.9412)\n",
      "Test: [1/2]\tval Loss: 5.8128 (val loss average: 5.8816)\n",
      "Train: [299][1/3]\ttraining loss 6.534 (average: 6.534)\n",
      "Train: [299][2/3]\ttraining loss 6.520 (average: 6.527)\n",
      "Train: [299][3/3]\ttraining loss 4.728 (average: 6.399)\n",
      "Test: [0/2]\tval Loss: 5.8129 (val loss average: 5.8129)\n",
      "Test: [1/2]\tval Loss: 5.6978 (val loss average: 5.7595)\n",
      "Train: [399][1/3]\ttraining loss 6.515 (average: 6.515)\n",
      "Train: [399][2/3]\ttraining loss 6.569 (average: 6.542)\n",
      "Train: [399][3/3]\ttraining loss 4.507 (average: 6.397)\n",
      "Test: [0/2]\tval Loss: 5.8182 (val loss average: 5.8182)\n",
      "Test: [1/2]\tval Loss: 5.7308 (val loss average: 5.7777)\n",
      "Train: [499][1/3]\ttraining loss 6.475 (average: 6.475)\n",
      "Train: [499][2/3]\ttraining loss 6.445 (average: 6.460)\n",
      "Train: [499][3/3]\ttraining loss 4.452 (average: 6.317)\n",
      "Test: [0/2]\tval Loss: 5.8390 (val loss average: 5.8390)\n",
      "Test: [1/2]\tval Loss: 5.8019 (val loss average: 5.8218)\n",
      "Train: [599][1/3]\ttraining loss 6.493 (average: 6.493)\n",
      "Train: [599][2/3]\ttraining loss 6.357 (average: 6.425)\n",
      "Train: [599][3/3]\ttraining loss 4.549 (average: 6.292)\n",
      "Test: [0/2]\tval Loss: 5.9281 (val loss average: 5.9281)\n",
      "Test: [1/2]\tval Loss: 5.6509 (val loss average: 5.7995)\n",
      "Train: [99][1/3]\ttraining loss 6.743 (average: 6.743)\n",
      "Train: [99][2/3]\ttraining loss 6.753 (average: 6.748)\n",
      "Train: [99][3/3]\ttraining loss 4.836 (average: 6.612)\n",
      "Test: [0/2]\tval Loss: 5.9490 (val loss average: 5.9490)\n",
      "Test: [1/2]\tval Loss: 5.9032 (val loss average: 5.9277)\n",
      "Train: [199][1/3]\ttraining loss 6.654 (average: 6.654)\n",
      "Train: [199][2/3]\ttraining loss 6.647 (average: 6.651)\n",
      "Train: [199][3/3]\ttraining loss 4.736 (average: 6.514)\n",
      "Test: [0/2]\tval Loss: 5.9655 (val loss average: 5.9655)\n",
      "Test: [1/2]\tval Loss: 5.7591 (val loss average: 5.8698)\n",
      "Train: [299][1/3]\ttraining loss 6.573 (average: 6.573)\n",
      "Train: [299][2/3]\ttraining loss 6.607 (average: 6.590)\n",
      "Train: [299][3/3]\ttraining loss 4.564 (average: 6.446)\n",
      "Test: [0/2]\tval Loss: 5.8981 (val loss average: 5.8981)\n",
      "Test: [1/2]\tval Loss: 5.7652 (val loss average: 5.8364)\n",
      "Train: [399][1/3]\ttraining loss 6.534 (average: 6.534)\n",
      "Train: [399][2/3]\ttraining loss 6.497 (average: 6.516)\n",
      "Train: [399][3/3]\ttraining loss 4.568 (average: 6.377)\n",
      "Test: [0/2]\tval Loss: 5.9127 (val loss average: 5.9127)\n",
      "Test: [1/2]\tval Loss: 5.8429 (val loss average: 5.8803)\n",
      "Train: [499][1/3]\ttraining loss 6.483 (average: 6.483)\n",
      "Train: [499][2/3]\ttraining loss 6.555 (average: 6.519)\n",
      "Train: [499][3/3]\ttraining loss 4.511 (average: 6.376)\n",
      "Test: [0/2]\tval Loss: 5.8962 (val loss average: 5.8962)\n",
      "Test: [1/2]\tval Loss: 5.7617 (val loss average: 5.8338)\n",
      "Train: [599][1/3]\ttraining loss 6.450 (average: 6.450)\n",
      "Train: [599][2/3]\ttraining loss 6.506 (average: 6.478)\n",
      "Train: [599][3/3]\ttraining loss 4.524 (average: 6.339)\n",
      "Test: [0/2]\tval Loss: 5.8605 (val loss average: 5.8605)\n",
      "Test: [1/2]\tval Loss: 5.7708 (val loss average: 5.8189)\n",
      "Train: [99][1/3]\ttraining loss 6.759 (average: 6.759)\n",
      "Train: [99][2/3]\ttraining loss 6.780 (average: 6.769)\n",
      "Train: [99][3/3]\ttraining loss 4.824 (average: 6.631)\n",
      "Test: [0/2]\tval Loss: 6.0860 (val loss average: 6.0860)\n",
      "Test: [1/2]\tval Loss: 5.9400 (val loss average: 6.0183)\n",
      "Train: [199][1/3]\ttraining loss 6.729 (average: 6.729)\n",
      "Train: [199][2/3]\ttraining loss 6.700 (average: 6.715)\n",
      "Train: [199][3/3]\ttraining loss 4.892 (average: 6.585)\n",
      "Test: [0/2]\tval Loss: 6.0562 (val loss average: 6.0562)\n",
      "Test: [1/2]\tval Loss: 5.9137 (val loss average: 5.9901)\n",
      "Train: [299][1/3]\ttraining loss 6.598 (average: 6.598)\n",
      "Train: [299][2/3]\ttraining loss 6.622 (average: 6.610)\n",
      "Train: [299][3/3]\ttraining loss 4.689 (average: 6.473)\n",
      "Test: [0/2]\tval Loss: 5.9923 (val loss average: 5.9923)\n",
      "Test: [1/2]\tval Loss: 5.8061 (val loss average: 5.9059)\n",
      "Train: [399][1/3]\ttraining loss 6.535 (average: 6.535)\n",
      "Train: [399][2/3]\ttraining loss 6.553 (average: 6.544)\n",
      "Train: [399][3/3]\ttraining loss 4.642 (average: 6.409)\n",
      "Test: [0/2]\tval Loss: 5.9216 (val loss average: 5.9216)\n",
      "Test: [1/2]\tval Loss: 5.7027 (val loss average: 5.8200)\n",
      "Train: [499][1/3]\ttraining loss 6.501 (average: 6.501)\n",
      "Train: [499][2/3]\ttraining loss 6.493 (average: 6.497)\n",
      "Train: [499][3/3]\ttraining loss 4.795 (average: 6.376)\n",
      "Test: [0/2]\tval Loss: 5.8206 (val loss average: 5.8206)\n",
      "Test: [1/2]\tval Loss: 5.6434 (val loss average: 5.7384)\n",
      "Train: [599][1/3]\ttraining loss 6.468 (average: 6.468)\n",
      "Train: [599][2/3]\ttraining loss 6.523 (average: 6.496)\n",
      "Train: [599][3/3]\ttraining loss 4.594 (average: 6.360)\n",
      "Test: [0/2]\tval Loss: 5.8623 (val loss average: 5.8623)\n",
      "Test: [1/2]\tval Loss: 5.7722 (val loss average: 5.8205)\n",
      "Train: [99][1/3]\ttraining loss 6.797 (average: 6.797)\n",
      "Train: [99][2/3]\ttraining loss 6.752 (average: 6.775)\n",
      "Train: [99][3/3]\ttraining loss 4.874 (average: 6.639)\n",
      "Test: [0/2]\tval Loss: 6.0732 (val loss average: 6.0732)\n",
      "Test: [1/2]\tval Loss: 5.9072 (val loss average: 5.9962)\n",
      "Train: [199][1/3]\ttraining loss 6.675 (average: 6.675)\n",
      "Train: [199][2/3]\ttraining loss 6.679 (average: 6.677)\n",
      "Train: [199][3/3]\ttraining loss 4.872 (average: 6.549)\n",
      "Test: [0/2]\tval Loss: 6.0103 (val loss average: 6.0103)\n",
      "Test: [1/2]\tval Loss: 5.8538 (val loss average: 5.9377)\n",
      "Train: [299][1/3]\ttraining loss 6.639 (average: 6.639)\n",
      "Train: [299][2/3]\ttraining loss 6.642 (average: 6.641)\n",
      "Train: [299][3/3]\ttraining loss 4.729 (average: 6.505)\n",
      "Test: [0/2]\tval Loss: 5.9076 (val loss average: 5.9076)\n",
      "Test: [1/2]\tval Loss: 5.7722 (val loss average: 5.8448)\n",
      "Train: [399][1/3]\ttraining loss 6.553 (average: 6.553)\n",
      "Train: [399][2/3]\ttraining loss 6.512 (average: 6.533)\n",
      "Train: [399][3/3]\ttraining loss 4.606 (average: 6.396)\n",
      "Test: [0/2]\tval Loss: 5.9432 (val loss average: 5.9432)\n",
      "Test: [1/2]\tval Loss: 5.8491 (val loss average: 5.8995)\n",
      "Train: [499][1/3]\ttraining loss 6.519 (average: 6.519)\n",
      "Train: [499][2/3]\ttraining loss 6.567 (average: 6.543)\n",
      "Train: [499][3/3]\ttraining loss 4.578 (average: 6.403)\n",
      "Test: [0/2]\tval Loss: 5.9418 (val loss average: 5.9418)\n",
      "Test: [1/2]\tval Loss: 5.7061 (val loss average: 5.8325)\n",
      "Train: [599][1/3]\ttraining loss 6.539 (average: 6.539)\n",
      "Train: [599][2/3]\ttraining loss 6.514 (average: 6.527)\n",
      "Train: [599][3/3]\ttraining loss 4.551 (average: 6.386)\n",
      "Test: [0/2]\tval Loss: 5.8760 (val loss average: 5.8760)\n",
      "Test: [1/2]\tval Loss: 5.7628 (val loss average: 5.8235)\n",
      "Train: [99][1/3]\ttraining loss 6.732 (average: 6.732)\n",
      "Train: [99][2/3]\ttraining loss 6.762 (average: 6.747)\n",
      "Train: [99][3/3]\ttraining loss 4.866 (average: 6.613)\n",
      "Test: [0/2]\tval Loss: 5.9769 (val loss average: 5.9769)\n",
      "Test: [1/2]\tval Loss: 5.8173 (val loss average: 5.9029)\n",
      "Train: [199][1/3]\ttraining loss 6.585 (average: 6.585)\n",
      "Train: [199][2/3]\ttraining loss 6.655 (average: 6.620)\n",
      "Train: [199][3/3]\ttraining loss 4.670 (average: 6.481)\n",
      "Test: [0/2]\tval Loss: 5.8198 (val loss average: 5.8198)\n",
      "Test: [1/2]\tval Loss: 5.7191 (val loss average: 5.7731)\n",
      "Train: [299][1/3]\ttraining loss 6.547 (average: 6.547)\n",
      "Train: [299][2/3]\ttraining loss 6.587 (average: 6.567)\n",
      "Train: [299][3/3]\ttraining loss 4.710 (average: 6.435)\n",
      "Test: [0/2]\tval Loss: 5.8369 (val loss average: 5.8369)\n",
      "Test: [1/2]\tval Loss: 5.7564 (val loss average: 5.7996)\n",
      "Train: [399][1/3]\ttraining loss 6.495 (average: 6.495)\n",
      "Train: [399][2/3]\ttraining loss 6.458 (average: 6.476)\n",
      "Train: [399][3/3]\ttraining loss 4.572 (average: 6.341)\n",
      "Test: [0/2]\tval Loss: 5.7913 (val loss average: 5.7913)\n",
      "Test: [1/2]\tval Loss: 5.7196 (val loss average: 5.7580)\n",
      "Train: [499][1/3]\ttraining loss 6.482 (average: 6.482)\n",
      "Train: [499][2/3]\ttraining loss 6.457 (average: 6.470)\n",
      "Train: [499][3/3]\ttraining loss 4.746 (average: 6.347)\n",
      "Test: [0/2]\tval Loss: 5.9355 (val loss average: 5.9355)\n",
      "Test: [1/2]\tval Loss: 5.7537 (val loss average: 5.8511)\n",
      "Train: [599][1/3]\ttraining loss 6.434 (average: 6.434)\n",
      "Train: [599][2/3]\ttraining loss 6.412 (average: 6.423)\n",
      "Train: [599][3/3]\ttraining loss 4.529 (average: 6.288)\n",
      "Test: [0/2]\tval Loss: 5.8527 (val loss average: 5.8527)\n",
      "Test: [1/2]\tval Loss: 5.6788 (val loss average: 5.7720)\n",
      "Train: [99][1/3]\ttraining loss 6.734 (average: 6.734)\n",
      "Train: [99][2/3]\ttraining loss 6.799 (average: 6.766)\n",
      "Train: [99][3/3]\ttraining loss 4.840 (average: 6.629)\n",
      "Test: [0/2]\tval Loss: 6.0052 (val loss average: 6.0052)\n",
      "Test: [1/2]\tval Loss: 5.8542 (val loss average: 5.9352)\n",
      "Train: [199][1/3]\ttraining loss 6.611 (average: 6.611)\n",
      "Train: [199][2/3]\ttraining loss 6.669 (average: 6.640)\n",
      "Train: [199][3/3]\ttraining loss 4.745 (average: 6.505)\n",
      "Test: [0/2]\tval Loss: 5.8584 (val loss average: 5.8584)\n",
      "Test: [1/2]\tval Loss: 5.7427 (val loss average: 5.8047)\n",
      "Train: [299][1/3]\ttraining loss 6.581 (average: 6.581)\n",
      "Train: [299][2/3]\ttraining loss 6.601 (average: 6.591)\n",
      "Train: [299][3/3]\ttraining loss 4.666 (average: 6.454)\n",
      "Test: [0/2]\tval Loss: 5.9177 (val loss average: 5.9177)\n",
      "Test: [1/2]\tval Loss: 5.7900 (val loss average: 5.8584)\n",
      "Train: [399][1/3]\ttraining loss 6.591 (average: 6.591)\n",
      "Train: [399][2/3]\ttraining loss 6.645 (average: 6.618)\n",
      "Train: [399][3/3]\ttraining loss 4.684 (average: 6.480)\n",
      "Test: [0/2]\tval Loss: 5.9203 (val loss average: 5.9203)\n",
      "Test: [1/2]\tval Loss: 5.7416 (val loss average: 5.8374)\n",
      "Train: [499][1/3]\ttraining loss 6.530 (average: 6.530)\n",
      "Train: [499][2/3]\ttraining loss 6.510 (average: 6.520)\n",
      "Train: [499][3/3]\ttraining loss 4.822 (average: 6.399)\n",
      "Test: [0/2]\tval Loss: 5.9018 (val loss average: 5.9018)\n",
      "Test: [1/2]\tval Loss: 5.8042 (val loss average: 5.8565)\n",
      "Train: [599][1/3]\ttraining loss 6.544 (average: 6.544)\n",
      "Train: [599][2/3]\ttraining loss 6.524 (average: 6.534)\n",
      "Train: [599][3/3]\ttraining loss 4.677 (average: 6.402)\n",
      "Test: [0/2]\tval Loss: 5.8370 (val loss average: 5.8370)\n",
      "Test: [1/2]\tval Loss: 5.7481 (val loss average: 5.7958)\n",
      "Train: [99][1/3]\ttraining loss 6.774 (average: 6.774)\n",
      "Train: [99][2/3]\ttraining loss 6.789 (average: 6.782)\n",
      "Train: [99][3/3]\ttraining loss 4.861 (average: 6.645)\n",
      "Test: [0/2]\tval Loss: 6.0488 (val loss average: 6.0488)\n",
      "Test: [1/2]\tval Loss: 5.8752 (val loss average: 5.9683)\n",
      "Train: [199][1/3]\ttraining loss 6.651 (average: 6.651)\n",
      "Train: [199][2/3]\ttraining loss 6.644 (average: 6.647)\n",
      "Train: [199][3/3]\ttraining loss 4.667 (average: 6.506)\n",
      "Test: [0/2]\tval Loss: 5.9378 (val loss average: 5.9378)\n",
      "Test: [1/2]\tval Loss: 5.8802 (val loss average: 5.9111)\n",
      "Train: [299][1/3]\ttraining loss 6.528 (average: 6.528)\n",
      "Train: [299][2/3]\ttraining loss 6.604 (average: 6.566)\n",
      "Train: [299][3/3]\ttraining loss 4.419 (average: 6.413)\n",
      "Test: [0/2]\tval Loss: 5.9737 (val loss average: 5.9737)\n",
      "Test: [1/2]\tval Loss: 5.8653 (val loss average: 5.9234)\n",
      "Train: [399][1/3]\ttraining loss 6.566 (average: 6.566)\n",
      "Train: [399][2/3]\ttraining loss 6.488 (average: 6.527)\n",
      "Train: [399][3/3]\ttraining loss 4.682 (average: 6.395)\n",
      "Test: [0/2]\tval Loss: 5.9292 (val loss average: 5.9292)\n",
      "Test: [1/2]\tval Loss: 5.7509 (val loss average: 5.8465)\n",
      "Train: [499][1/3]\ttraining loss 6.497 (average: 6.497)\n",
      "Train: [499][2/3]\ttraining loss 6.432 (average: 6.465)\n",
      "Train: [499][3/3]\ttraining loss 4.538 (average: 6.328)\n",
      "Test: [0/2]\tval Loss: 5.9640 (val loss average: 5.9640)\n",
      "Test: [1/2]\tval Loss: 5.9331 (val loss average: 5.9497)\n",
      "Train: [599][1/3]\ttraining loss 6.392 (average: 6.392)\n",
      "Train: [599][2/3]\ttraining loss 6.420 (average: 6.406)\n",
      "Train: [599][3/3]\ttraining loss 4.369 (average: 6.261)\n",
      "Test: [0/2]\tval Loss: 5.9070 (val loss average: 5.9070)\n",
      "Test: [1/2]\tval Loss: 5.8169 (val loss average: 5.8652)\n",
      "Train: [99][1/3]\ttraining loss 6.802 (average: 6.802)\n",
      "Train: [99][2/3]\ttraining loss 6.793 (average: 6.798)\n",
      "Train: [99][3/3]\ttraining loss 4.918 (average: 6.664)\n",
      "Test: [0/2]\tval Loss: 6.0467 (val loss average: 6.0467)\n",
      "Test: [1/2]\tval Loss: 5.9182 (val loss average: 5.9871)\n",
      "Train: [199][1/3]\ttraining loss 6.747 (average: 6.747)\n",
      "Train: [199][2/3]\ttraining loss 6.759 (average: 6.753)\n",
      "Train: [199][3/3]\ttraining loss 4.714 (average: 6.607)\n",
      "Test: [0/2]\tval Loss: 6.0447 (val loss average: 6.0447)\n",
      "Test: [1/2]\tval Loss: 5.9061 (val loss average: 5.9804)\n",
      "Train: [299][1/3]\ttraining loss 6.660 (average: 6.660)\n",
      "Train: [299][2/3]\ttraining loss 6.625 (average: 6.642)\n",
      "Train: [299][3/3]\ttraining loss 4.793 (average: 6.511)\n",
      "Test: [0/2]\tval Loss: 5.9382 (val loss average: 5.9382)\n",
      "Test: [1/2]\tval Loss: 5.7807 (val loss average: 5.8651)\n",
      "Train: [399][1/3]\ttraining loss 6.574 (average: 6.574)\n",
      "Train: [399][2/3]\ttraining loss 6.558 (average: 6.566)\n",
      "Train: [399][3/3]\ttraining loss 4.677 (average: 6.431)\n",
      "Test: [0/2]\tval Loss: 5.9766 (val loss average: 5.9766)\n",
      "Test: [1/2]\tval Loss: 5.8478 (val loss average: 5.9169)\n",
      "Train: [499][1/3]\ttraining loss 6.529 (average: 6.529)\n",
      "Train: [499][2/3]\ttraining loss 6.548 (average: 6.538)\n",
      "Train: [499][3/3]\ttraining loss 4.624 (average: 6.402)\n",
      "Test: [0/2]\tval Loss: 5.9648 (val loss average: 5.9648)\n",
      "Test: [1/2]\tval Loss: 5.7035 (val loss average: 5.8436)\n",
      "Train: [599][1/3]\ttraining loss 6.515 (average: 6.515)\n",
      "Train: [599][2/3]\ttraining loss 6.470 (average: 6.493)\n",
      "Train: [599][3/3]\ttraining loss 4.637 (average: 6.361)\n",
      "Test: [0/2]\tval Loss: 5.9444 (val loss average: 5.9444)\n",
      "Test: [1/2]\tval Loss: 5.7694 (val loss average: 5.8632)\n",
      "Train: [699][1/3]\ttraining loss 6.493 (average: 6.493)\n",
      "Train: [699][2/3]\ttraining loss 6.434 (average: 6.464)\n",
      "Train: [699][3/3]\ttraining loss 4.602 (average: 6.331)\n",
      "Test: [0/2]\tval Loss: 5.9679 (val loss average: 5.9679)\n",
      "Test: [1/2]\tval Loss: 5.7543 (val loss average: 5.8688)\n",
      "Train: [799][1/3]\ttraining loss 6.439 (average: 6.439)\n",
      "Train: [799][2/3]\ttraining loss 6.502 (average: 6.470)\n",
      "Train: [799][3/3]\ttraining loss 4.485 (average: 6.329)\n",
      "Test: [0/2]\tval Loss: 5.9026 (val loss average: 5.9026)\n",
      "Test: [1/2]\tval Loss: 5.6897 (val loss average: 5.8038)\n",
      "Train: [899][1/3]\ttraining loss 6.387 (average: 6.387)\n",
      "Train: [899][2/3]\ttraining loss 6.377 (average: 6.382)\n",
      "Train: [899][3/3]\ttraining loss 4.435 (average: 6.243)\n",
      "Test: [0/2]\tval Loss: 5.8023 (val loss average: 5.8023)\n",
      "Test: [1/2]\tval Loss: 5.7510 (val loss average: 5.7785)\n",
      "Train: [99][1/3]\ttraining loss 6.778 (average: 6.778)\n",
      "Train: [99][2/3]\ttraining loss 6.755 (average: 6.767)\n",
      "Train: [99][3/3]\ttraining loss 4.907 (average: 6.634)\n",
      "Test: [0/2]\tval Loss: 6.0087 (val loss average: 6.0087)\n",
      "Test: [1/2]\tval Loss: 5.8524 (val loss average: 5.9362)\n",
      "Train: [199][1/3]\ttraining loss 6.654 (average: 6.654)\n",
      "Train: [199][2/3]\ttraining loss 6.662 (average: 6.658)\n",
      "Train: [199][3/3]\ttraining loss 4.842 (average: 6.529)\n",
      "Test: [0/2]\tval Loss: 5.8495 (val loss average: 5.8495)\n",
      "Test: [1/2]\tval Loss: 5.7304 (val loss average: 5.7942)\n",
      "Train: [299][1/3]\ttraining loss 6.522 (average: 6.522)\n",
      "Train: [299][2/3]\ttraining loss 6.627 (average: 6.575)\n",
      "Train: [299][3/3]\ttraining loss 4.750 (average: 6.445)\n",
      "Test: [0/2]\tval Loss: 5.8572 (val loss average: 5.8572)\n",
      "Test: [1/2]\tval Loss: 5.6129 (val loss average: 5.7438)\n",
      "Train: [399][1/3]\ttraining loss 6.490 (average: 6.490)\n",
      "Train: [399][2/3]\ttraining loss 6.488 (average: 6.489)\n",
      "Train: [399][3/3]\ttraining loss 4.677 (average: 6.360)\n",
      "Test: [0/2]\tval Loss: 5.6925 (val loss average: 5.6925)\n",
      "Test: [1/2]\tval Loss: 5.5541 (val loss average: 5.6283)\n",
      "Train: [499][1/3]\ttraining loss 6.469 (average: 6.469)\n",
      "Train: [499][2/3]\ttraining loss 6.507 (average: 6.488)\n",
      "Train: [499][3/3]\ttraining loss 4.636 (average: 6.356)\n",
      "Test: [0/2]\tval Loss: 5.7914 (val loss average: 5.7914)\n",
      "Test: [1/2]\tval Loss: 5.6451 (val loss average: 5.7235)\n",
      "Train: [599][1/3]\ttraining loss 6.448 (average: 6.448)\n",
      "Train: [599][2/3]\ttraining loss 6.530 (average: 6.489)\n",
      "Train: [599][3/3]\ttraining loss 4.547 (average: 6.351)\n",
      "Test: [0/2]\tval Loss: 5.7732 (val loss average: 5.7732)\n",
      "Test: [1/2]\tval Loss: 5.6036 (val loss average: 5.6945)\n",
      "Train: [699][1/3]\ttraining loss 6.392 (average: 6.392)\n",
      "Train: [699][2/3]\ttraining loss 6.395 (average: 6.394)\n",
      "Train: [699][3/3]\ttraining loss 4.460 (average: 6.256)\n",
      "Test: [0/2]\tval Loss: 5.7234 (val loss average: 5.7234)\n",
      "Test: [1/2]\tval Loss: 5.6329 (val loss average: 5.6814)\n",
      "Train: [99][1/3]\ttraining loss 6.727 (average: 6.727)\n",
      "Train: [99][2/3]\ttraining loss 6.746 (average: 6.737)\n",
      "Train: [99][3/3]\ttraining loss 4.860 (average: 6.603)\n",
      "Test: [0/2]\tval Loss: 6.0160 (val loss average: 6.0160)\n",
      "Test: [1/2]\tval Loss: 5.8648 (val loss average: 5.9459)\n",
      "Train: [199][1/3]\ttraining loss 6.600 (average: 6.600)\n",
      "Train: [199][2/3]\ttraining loss 6.589 (average: 6.595)\n",
      "Train: [199][3/3]\ttraining loss 4.698 (average: 6.460)\n",
      "Test: [0/2]\tval Loss: 5.8704 (val loss average: 5.8704)\n",
      "Test: [1/2]\tval Loss: 5.8143 (val loss average: 5.8444)\n",
      "Train: [299][1/3]\ttraining loss 6.546 (average: 6.546)\n",
      "Train: [299][2/3]\ttraining loss 6.538 (average: 6.542)\n",
      "Train: [299][3/3]\ttraining loss 4.600 (average: 6.404)\n",
      "Test: [0/2]\tval Loss: 5.9605 (val loss average: 5.9605)\n",
      "Test: [1/2]\tval Loss: 5.8489 (val loss average: 5.9088)\n",
      "Train: [399][1/3]\ttraining loss 6.502 (average: 6.502)\n",
      "Train: [399][2/3]\ttraining loss 6.485 (average: 6.493)\n",
      "Train: [399][3/3]\ttraining loss 4.605 (average: 6.359)\n",
      "Test: [0/2]\tval Loss: 6.0032 (val loss average: 6.0032)\n",
      "Test: [1/2]\tval Loss: 5.7935 (val loss average: 5.9059)\n",
      "Train: [499][1/3]\ttraining loss 6.514 (average: 6.514)\n",
      "Train: [499][2/3]\ttraining loss 6.497 (average: 6.505)\n",
      "Train: [499][3/3]\ttraining loss 4.665 (average: 6.374)\n",
      "Test: [0/2]\tval Loss: 5.8665 (val loss average: 5.8665)\n",
      "Test: [1/2]\tval Loss: 5.8820 (val loss average: 5.8737)\n",
      "Train: [599][1/3]\ttraining loss 6.433 (average: 6.433)\n",
      "Train: [599][2/3]\ttraining loss 6.441 (average: 6.437)\n",
      "Train: [599][3/3]\ttraining loss 4.596 (average: 6.306)\n",
      "Test: [0/2]\tval Loss: 5.7707 (val loss average: 5.7707)\n",
      "Test: [1/2]\tval Loss: 5.7678 (val loss average: 5.7694)\n",
      "Train: [99][1/3]\ttraining loss 6.771 (average: 6.771)\n",
      "Train: [99][2/3]\ttraining loss 6.785 (average: 6.778)\n",
      "Train: [99][3/3]\ttraining loss 4.901 (average: 6.644)\n",
      "Test: [0/2]\tval Loss: 6.0297 (val loss average: 6.0297)\n",
      "Test: [1/2]\tval Loss: 5.8390 (val loss average: 5.9412)\n",
      "Train: [199][1/3]\ttraining loss 6.669 (average: 6.669)\n",
      "Train: [199][2/3]\ttraining loss 6.675 (average: 6.672)\n",
      "Train: [199][3/3]\ttraining loss 4.694 (average: 6.531)\n",
      "Test: [0/2]\tval Loss: 5.9894 (val loss average: 5.9894)\n",
      "Test: [1/2]\tval Loss: 5.7412 (val loss average: 5.8743)\n",
      "Train: [299][1/3]\ttraining loss 6.570 (average: 6.570)\n",
      "Train: [299][2/3]\ttraining loss 6.586 (average: 6.578)\n",
      "Train: [299][3/3]\ttraining loss 4.698 (average: 6.444)\n",
      "Test: [0/2]\tval Loss: 5.8876 (val loss average: 5.8876)\n",
      "Test: [1/2]\tval Loss: 5.7667 (val loss average: 5.8315)\n",
      "Train: [399][1/3]\ttraining loss 6.496 (average: 6.496)\n",
      "Train: [399][2/3]\ttraining loss 6.582 (average: 6.539)\n",
      "Train: [399][3/3]\ttraining loss 4.732 (average: 6.410)\n",
      "Test: [0/2]\tval Loss: 5.9175 (val loss average: 5.9175)\n",
      "Test: [1/2]\tval Loss: 5.7278 (val loss average: 5.8295)\n",
      "Train: [499][1/3]\ttraining loss 6.534 (average: 6.534)\n",
      "Train: [499][2/3]\ttraining loss 6.503 (average: 6.519)\n",
      "Train: [499][3/3]\ttraining loss 4.601 (average: 6.382)\n",
      "Test: [0/2]\tval Loss: 5.8868 (val loss average: 5.8868)\n",
      "Test: [1/2]\tval Loss: 5.8345 (val loss average: 5.8625)\n",
      "Train: [599][1/3]\ttraining loss 6.480 (average: 6.480)\n",
      "Train: [599][2/3]\ttraining loss 6.491 (average: 6.486)\n",
      "Train: [599][3/3]\ttraining loss 4.842 (average: 6.369)\n",
      "Test: [0/2]\tval Loss: 5.8034 (val loss average: 5.8034)\n",
      "Test: [1/2]\tval Loss: 5.6246 (val loss average: 5.7205)\n",
      "Train: [99][1/3]\ttraining loss 6.764 (average: 6.764)\n",
      "Train: [99][2/3]\ttraining loss 6.766 (average: 6.765)\n",
      "Train: [99][3/3]\ttraining loss 4.848 (average: 6.628)\n",
      "Test: [0/2]\tval Loss: 6.0172 (val loss average: 6.0172)\n",
      "Test: [1/2]\tval Loss: 5.8910 (val loss average: 5.9586)\n",
      "Train: [199][1/3]\ttraining loss 6.630 (average: 6.630)\n",
      "Train: [199][2/3]\ttraining loss 6.655 (average: 6.643)\n",
      "Train: [199][3/3]\ttraining loss 4.692 (average: 6.504)\n",
      "Test: [0/2]\tval Loss: 5.9110 (val loss average: 5.9110)\n",
      "Test: [1/2]\tval Loss: 5.7858 (val loss average: 5.8529)\n",
      "Train: [299][1/3]\ttraining loss 6.617 (average: 6.617)\n",
      "Train: [299][2/3]\ttraining loss 6.623 (average: 6.620)\n",
      "Train: [299][3/3]\ttraining loss 4.745 (average: 6.486)\n",
      "Test: [0/2]\tval Loss: 5.8272 (val loss average: 5.8272)\n",
      "Test: [1/2]\tval Loss: 5.6580 (val loss average: 5.7487)\n",
      "Train: [399][1/3]\ttraining loss 6.536 (average: 6.536)\n",
      "Train: [399][2/3]\ttraining loss 6.524 (average: 6.530)\n",
      "Train: [399][3/3]\ttraining loss 4.640 (average: 6.395)\n",
      "Test: [0/2]\tval Loss: 5.8728 (val loss average: 5.8728)\n",
      "Test: [1/2]\tval Loss: 5.8279 (val loss average: 5.8520)\n",
      "Train: [499][1/3]\ttraining loss 6.530 (average: 6.530)\n",
      "Train: [499][2/3]\ttraining loss 6.520 (average: 6.525)\n",
      "Train: [499][3/3]\ttraining loss 4.607 (average: 6.388)\n",
      "Test: [0/2]\tval Loss: 5.7483 (val loss average: 5.7483)\n",
      "Test: [1/2]\tval Loss: 5.6419 (val loss average: 5.6989)\n",
      "Train: [599][1/3]\ttraining loss 6.497 (average: 6.497)\n",
      "Train: [599][2/3]\ttraining loss 6.482 (average: 6.490)\n",
      "Train: [599][3/3]\ttraining loss 4.586 (average: 6.354)\n",
      "Test: [0/2]\tval Loss: 5.7565 (val loss average: 5.7565)\n",
      "Test: [1/2]\tval Loss: 5.6636 (val loss average: 5.7134)\n",
      "Train: [99][1/3]\ttraining loss 6.771 (average: 6.771)\n",
      "Train: [99][2/3]\ttraining loss 6.757 (average: 6.764)\n",
      "Train: [99][3/3]\ttraining loss 4.849 (average: 6.628)\n",
      "Test: [0/2]\tval Loss: 6.0504 (val loss average: 6.0504)\n",
      "Test: [1/2]\tval Loss: 5.8322 (val loss average: 5.9491)\n",
      "Train: [199][1/3]\ttraining loss 6.613 (average: 6.613)\n",
      "Train: [199][2/3]\ttraining loss 6.646 (average: 6.629)\n",
      "Train: [199][3/3]\ttraining loss 4.760 (average: 6.496)\n",
      "Test: [0/2]\tval Loss: 5.9431 (val loss average: 5.9431)\n",
      "Test: [1/2]\tval Loss: 5.7912 (val loss average: 5.8726)\n",
      "Train: [299][1/3]\ttraining loss 6.570 (average: 6.570)\n",
      "Train: [299][2/3]\ttraining loss 6.582 (average: 6.576)\n",
      "Train: [299][3/3]\ttraining loss 4.531 (average: 6.430)\n",
      "Test: [0/2]\tval Loss: 5.9360 (val loss average: 5.9360)\n",
      "Test: [1/2]\tval Loss: 5.7976 (val loss average: 5.8718)\n",
      "Train: [399][1/3]\ttraining loss 6.478 (average: 6.478)\n",
      "Train: [399][2/3]\ttraining loss 6.525 (average: 6.501)\n",
      "Train: [399][3/3]\ttraining loss 4.573 (average: 6.364)\n",
      "Test: [0/2]\tval Loss: 5.8871 (val loss average: 5.8871)\n",
      "Test: [1/2]\tval Loss: 5.7118 (val loss average: 5.8058)\n",
      "Train: [499][1/3]\ttraining loss 6.388 (average: 6.388)\n",
      "Train: [499][2/3]\ttraining loss 6.431 (average: 6.410)\n",
      "Train: [499][3/3]\ttraining loss 4.507 (average: 6.274)\n",
      "Test: [0/2]\tval Loss: 5.7407 (val loss average: 5.7407)\n",
      "Test: [1/2]\tval Loss: 5.7645 (val loss average: 5.7518)\n",
      "Train: [599][1/3]\ttraining loss 6.472 (average: 6.472)\n",
      "Train: [599][2/3]\ttraining loss 6.494 (average: 6.483)\n",
      "Train: [599][3/3]\ttraining loss 4.409 (average: 6.335)\n",
      "Test: [0/2]\tval Loss: 5.8825 (val loss average: 5.8825)\n",
      "Test: [1/2]\tval Loss: 5.6254 (val loss average: 5.7632)\n",
      "Train: [699][1/3]\ttraining loss 6.417 (average: 6.417)\n",
      "Train: [699][2/3]\ttraining loss 6.473 (average: 6.445)\n",
      "Train: [699][3/3]\ttraining loss 4.401 (average: 6.299)\n",
      "Test: [0/2]\tval Loss: 5.8009 (val loss average: 5.8009)\n",
      "Test: [1/2]\tval Loss: 5.7838 (val loss average: 5.7930)\n",
      "Train: [799][1/3]\ttraining loss 6.286 (average: 6.286)\n",
      "Train: [799][2/3]\ttraining loss 6.384 (average: 6.335)\n",
      "Train: [799][3/3]\ttraining loss 4.364 (average: 6.195)\n",
      "Test: [0/2]\tval Loss: 5.8515 (val loss average: 5.8515)\n",
      "Test: [1/2]\tval Loss: 5.6779 (val loss average: 5.7709)\n",
      "Train: [99][1/3]\ttraining loss 6.796 (average: 6.796)\n",
      "Train: [99][2/3]\ttraining loss 6.789 (average: 6.792)\n",
      "Train: [99][3/3]\ttraining loss 4.808 (average: 6.651)\n",
      "Test: [0/2]\tval Loss: 6.0225 (val loss average: 6.0225)\n",
      "Test: [1/2]\tval Loss: 5.8657 (val loss average: 5.9497)\n",
      "Train: [199][1/3]\ttraining loss 6.693 (average: 6.693)\n",
      "Train: [199][2/3]\ttraining loss 6.680 (average: 6.687)\n",
      "Train: [199][3/3]\ttraining loss 4.845 (average: 6.556)\n",
      "Test: [0/2]\tval Loss: 5.9341 (val loss average: 5.9341)\n",
      "Test: [1/2]\tval Loss: 5.8147 (val loss average: 5.8787)\n",
      "Train: [299][1/3]\ttraining loss 6.613 (average: 6.613)\n",
      "Train: [299][2/3]\ttraining loss 6.563 (average: 6.588)\n",
      "Train: [299][3/3]\ttraining loss 4.850 (average: 6.464)\n",
      "Test: [0/2]\tval Loss: 5.7967 (val loss average: 5.7967)\n",
      "Test: [1/2]\tval Loss: 5.7059 (val loss average: 5.7546)\n",
      "Train: [399][1/3]\ttraining loss 6.583 (average: 6.583)\n",
      "Train: [399][2/3]\ttraining loss 6.544 (average: 6.564)\n",
      "Train: [399][3/3]\ttraining loss 4.686 (average: 6.430)\n",
      "Test: [0/2]\tval Loss: 5.9139 (val loss average: 5.9139)\n",
      "Test: [1/2]\tval Loss: 5.8088 (val loss average: 5.8651)\n",
      "Train: [499][1/3]\ttraining loss 6.521 (average: 6.521)\n",
      "Train: [499][2/3]\ttraining loss 6.480 (average: 6.501)\n",
      "Train: [499][3/3]\ttraining loss 4.634 (average: 6.368)\n",
      "Test: [0/2]\tval Loss: 5.8050 (val loss average: 5.8050)\n",
      "Test: [1/2]\tval Loss: 5.5772 (val loss average: 5.6993)\n",
      "Train: [599][1/3]\ttraining loss 6.549 (average: 6.549)\n",
      "Train: [599][2/3]\ttraining loss 6.479 (average: 6.514)\n",
      "Train: [599][3/3]\ttraining loss 4.431 (average: 6.366)\n",
      "Test: [0/2]\tval Loss: 5.7544 (val loss average: 5.7544)\n",
      "Test: [1/2]\tval Loss: 5.6067 (val loss average: 5.6859)\n",
      "Train: [99][1/3]\ttraining loss 6.788 (average: 6.788)\n",
      "Train: [99][2/3]\ttraining loss 6.765 (average: 6.777)\n",
      "Train: [99][3/3]\ttraining loss 4.910 (average: 6.644)\n",
      "Test: [0/2]\tval Loss: 6.0254 (val loss average: 6.0254)\n",
      "Test: [1/2]\tval Loss: 5.8449 (val loss average: 5.9417)\n",
      "Train: [199][1/3]\ttraining loss 6.649 (average: 6.649)\n",
      "Train: [199][2/3]\ttraining loss 6.624 (average: 6.636)\n",
      "Train: [199][3/3]\ttraining loss 4.749 (average: 6.502)\n",
      "Test: [0/2]\tval Loss: 5.9485 (val loss average: 5.9485)\n",
      "Test: [1/2]\tval Loss: 5.7434 (val loss average: 5.8533)\n",
      "Train: [299][1/3]\ttraining loss 6.581 (average: 6.581)\n",
      "Train: [299][2/3]\ttraining loss 6.582 (average: 6.581)\n",
      "Train: [299][3/3]\ttraining loss 4.895 (average: 6.461)\n",
      "Test: [0/2]\tval Loss: 5.9296 (val loss average: 5.9296)\n",
      "Test: [1/2]\tval Loss: 5.7669 (val loss average: 5.8542)\n",
      "Train: [399][1/3]\ttraining loss 6.550 (average: 6.550)\n",
      "Train: [399][2/3]\ttraining loss 6.543 (average: 6.546)\n",
      "Train: [399][3/3]\ttraining loss 4.561 (average: 6.405)\n",
      "Test: [0/2]\tval Loss: 5.8323 (val loss average: 5.8323)\n",
      "Test: [1/2]\tval Loss: 5.6954 (val loss average: 5.7688)\n",
      "Train: [499][1/3]\ttraining loss 6.493 (average: 6.493)\n",
      "Train: [499][2/3]\ttraining loss 6.516 (average: 6.504)\n",
      "Train: [499][3/3]\ttraining loss 4.567 (average: 6.366)\n",
      "Test: [0/2]\tval Loss: 5.8454 (val loss average: 5.8454)\n",
      "Test: [1/2]\tval Loss: 5.6828 (val loss average: 5.7699)\n",
      "Train: [599][1/3]\ttraining loss 6.469 (average: 6.469)\n",
      "Train: [599][2/3]\ttraining loss 6.465 (average: 6.467)\n",
      "Train: [599][3/3]\ttraining loss 4.657 (average: 6.338)\n",
      "Test: [0/2]\tval Loss: 5.8464 (val loss average: 5.8464)\n",
      "Test: [1/2]\tval Loss: 5.6954 (val loss average: 5.7764)\n",
      "Train: [99][1/3]\ttraining loss 6.777 (average: 6.777)\n",
      "Train: [99][2/3]\ttraining loss 6.775 (average: 6.776)\n",
      "Train: [99][3/3]\ttraining loss 4.841 (average: 6.639)\n",
      "Test: [0/2]\tval Loss: 6.0211 (val loss average: 6.0211)\n",
      "Test: [1/2]\tval Loss: 5.8162 (val loss average: 5.9261)\n",
      "Train: [199][1/3]\ttraining loss 6.623 (average: 6.623)\n",
      "Train: [199][2/3]\ttraining loss 6.640 (average: 6.631)\n",
      "Train: [199][3/3]\ttraining loss 4.726 (average: 6.496)\n",
      "Test: [0/2]\tval Loss: 5.9479 (val loss average: 5.9479)\n",
      "Test: [1/2]\tval Loss: 5.7716 (val loss average: 5.8661)\n",
      "Train: [299][1/3]\ttraining loss 6.594 (average: 6.594)\n",
      "Train: [299][2/3]\ttraining loss 6.540 (average: 6.567)\n",
      "Train: [299][3/3]\ttraining loss 4.604 (average: 6.427)\n",
      "Test: [0/2]\tval Loss: 5.8940 (val loss average: 5.8940)\n",
      "Test: [1/2]\tval Loss: 5.7690 (val loss average: 5.8360)\n",
      "Train: [399][1/3]\ttraining loss 6.566 (average: 6.566)\n",
      "Train: [399][2/3]\ttraining loss 6.565 (average: 6.565)\n",
      "Train: [399][3/3]\ttraining loss 4.736 (average: 6.435)\n",
      "Test: [0/2]\tval Loss: 5.9338 (val loss average: 5.9338)\n",
      "Test: [1/2]\tval Loss: 5.6800 (val loss average: 5.8161)\n",
      "Train: [499][1/3]\ttraining loss 6.481 (average: 6.481)\n",
      "Train: [499][2/3]\ttraining loss 6.502 (average: 6.491)\n",
      "Train: [499][3/3]\ttraining loss 4.622 (average: 6.358)\n",
      "Test: [0/2]\tval Loss: 5.9802 (val loss average: 5.9802)\n",
      "Test: [1/2]\tval Loss: 5.9467 (val loss average: 5.9647)\n",
      "Train: [599][1/3]\ttraining loss 6.520 (average: 6.520)\n",
      "Train: [599][2/3]\ttraining loss 6.573 (average: 6.546)\n",
      "Train: [599][3/3]\ttraining loss 4.554 (average: 6.405)\n",
      "Test: [0/2]\tval Loss: 6.0204 (val loss average: 6.0204)\n",
      "Test: [1/2]\tval Loss: 5.8293 (val loss average: 5.9317)\n",
      "Train: [99][1/3]\ttraining loss 6.759 (average: 6.759)\n",
      "Train: [99][2/3]\ttraining loss 6.768 (average: 6.763)\n",
      "Train: [99][3/3]\ttraining loss 4.811 (average: 6.624)\n",
      "Test: [0/2]\tval Loss: 5.9694 (val loss average: 5.9694)\n",
      "Test: [1/2]\tval Loss: 5.8339 (val loss average: 5.9065)\n",
      "Train: [199][1/3]\ttraining loss 6.649 (average: 6.649)\n",
      "Train: [199][2/3]\ttraining loss 6.599 (average: 6.624)\n",
      "Train: [199][3/3]\ttraining loss 4.660 (average: 6.484)\n",
      "Test: [0/2]\tval Loss: 5.9466 (val loss average: 5.9466)\n",
      "Test: [1/2]\tval Loss: 5.7480 (val loss average: 5.8544)\n",
      "Train: [299][1/3]\ttraining loss 6.528 (average: 6.528)\n",
      "Train: [299][2/3]\ttraining loss 6.512 (average: 6.520)\n",
      "Train: [299][3/3]\ttraining loss 4.597 (average: 6.383)\n",
      "Test: [0/2]\tval Loss: 5.8536 (val loss average: 5.8536)\n",
      "Test: [1/2]\tval Loss: 5.6733 (val loss average: 5.7699)\n",
      "Train: [399][1/3]\ttraining loss 6.480 (average: 6.480)\n",
      "Train: [399][2/3]\ttraining loss 6.479 (average: 6.479)\n",
      "Train: [399][3/3]\ttraining loss 4.545 (average: 6.342)\n",
      "Test: [0/2]\tval Loss: 5.8663 (val loss average: 5.8663)\n",
      "Test: [1/2]\tval Loss: 5.6853 (val loss average: 5.7824)\n",
      "Train: [499][1/3]\ttraining loss 6.507 (average: 6.507)\n",
      "Train: [499][2/3]\ttraining loss 6.410 (average: 6.458)\n",
      "Train: [499][3/3]\ttraining loss 4.645 (average: 6.329)\n",
      "Test: [0/2]\tval Loss: 5.9463 (val loss average: 5.9463)\n",
      "Test: [1/2]\tval Loss: 5.8514 (val loss average: 5.9023)\n",
      "Train: [599][1/3]\ttraining loss 6.448 (average: 6.448)\n",
      "Train: [599][2/3]\ttraining loss 6.414 (average: 6.431)\n",
      "Train: [599][3/3]\ttraining loss 4.427 (average: 6.288)\n",
      "Test: [0/2]\tval Loss: 5.8120 (val loss average: 5.8120)\n",
      "Test: [1/2]\tval Loss: 5.5529 (val loss average: 5.6918)\n",
      "Train: [99][1/3]\ttraining loss 6.773 (average: 6.773)\n",
      "Train: [99][2/3]\ttraining loss 6.788 (average: 6.781)\n",
      "Train: [99][3/3]\ttraining loss 4.817 (average: 6.641)\n",
      "Test: [0/2]\tval Loss: 6.0262 (val loss average: 6.0262)\n",
      "Test: [1/2]\tval Loss: 5.9025 (val loss average: 5.9688)\n",
      "Train: [199][1/3]\ttraining loss 6.615 (average: 6.615)\n",
      "Train: [199][2/3]\ttraining loss 6.597 (average: 6.606)\n",
      "Train: [199][3/3]\ttraining loss 4.714 (average: 6.471)\n",
      "Test: [0/2]\tval Loss: 5.9191 (val loss average: 5.9191)\n",
      "Test: [1/2]\tval Loss: 5.7188 (val loss average: 5.8262)\n",
      "Train: [299][1/3]\ttraining loss 6.557 (average: 6.557)\n",
      "Train: [299][2/3]\ttraining loss 6.597 (average: 6.577)\n",
      "Train: [299][3/3]\ttraining loss 4.661 (average: 6.441)\n",
      "Test: [0/2]\tval Loss: 5.8842 (val loss average: 5.8842)\n",
      "Test: [1/2]\tval Loss: 5.7047 (val loss average: 5.8009)\n",
      "Train: [399][1/3]\ttraining loss 6.532 (average: 6.532)\n",
      "Train: [399][2/3]\ttraining loss 6.534 (average: 6.533)\n",
      "Train: [399][3/3]\ttraining loss 4.657 (average: 6.400)\n",
      "Test: [0/2]\tval Loss: 5.9122 (val loss average: 5.9122)\n",
      "Test: [1/2]\tval Loss: 5.6823 (val loss average: 5.8055)\n",
      "Train: [499][1/3]\ttraining loss 6.478 (average: 6.478)\n",
      "Train: [499][2/3]\ttraining loss 6.572 (average: 6.525)\n",
      "Train: [499][3/3]\ttraining loss 4.582 (average: 6.386)\n",
      "Test: [0/2]\tval Loss: 5.7161 (val loss average: 5.7161)\n",
      "Test: [1/2]\tval Loss: 5.6991 (val loss average: 5.7082)\n",
      "Train: [599][1/3]\ttraining loss 6.481 (average: 6.481)\n",
      "Train: [599][2/3]\ttraining loss 6.527 (average: 6.504)\n",
      "Train: [599][3/3]\ttraining loss 4.638 (average: 6.371)\n",
      "Test: [0/2]\tval Loss: 5.9692 (val loss average: 5.9692)\n",
      "Test: [1/2]\tval Loss: 5.7228 (val loss average: 5.8549)\n",
      "Train: [99][1/3]\ttraining loss 6.800 (average: 6.800)\n",
      "Train: [99][2/3]\ttraining loss 6.763 (average: 6.782)\n",
      "Train: [99][3/3]\ttraining loss 4.826 (average: 6.642)\n",
      "Test: [0/2]\tval Loss: 5.9864 (val loss average: 5.9864)\n",
      "Test: [1/2]\tval Loss: 5.8380 (val loss average: 5.9176)\n",
      "Train: [199][1/3]\ttraining loss 6.683 (average: 6.683)\n",
      "Train: [199][2/3]\ttraining loss 6.713 (average: 6.698)\n",
      "Train: [199][3/3]\ttraining loss 4.711 (average: 6.557)\n",
      "Test: [0/2]\tval Loss: 5.9720 (val loss average: 5.9720)\n",
      "Test: [1/2]\tval Loss: 5.7972 (val loss average: 5.8909)\n",
      "Train: [299][1/3]\ttraining loss 6.654 (average: 6.654)\n",
      "Train: [299][2/3]\ttraining loss 6.576 (average: 6.615)\n",
      "Train: [299][3/3]\ttraining loss 4.582 (average: 6.470)\n",
      "Test: [0/2]\tval Loss: 5.7616 (val loss average: 5.7616)\n",
      "Test: [1/2]\tval Loss: 5.8272 (val loss average: 5.7920)\n",
      "Train: [399][1/3]\ttraining loss 6.484 (average: 6.484)\n",
      "Train: [399][2/3]\ttraining loss 6.583 (average: 6.533)\n",
      "Train: [399][3/3]\ttraining loss 4.709 (average: 6.404)\n",
      "Test: [0/2]\tval Loss: 5.8601 (val loss average: 5.8601)\n",
      "Test: [1/2]\tval Loss: 5.6500 (val loss average: 5.7626)\n",
      "Train: [499][1/3]\ttraining loss 6.541 (average: 6.541)\n",
      "Train: [499][2/3]\ttraining loss 6.527 (average: 6.534)\n",
      "Train: [499][3/3]\ttraining loss 4.600 (average: 6.396)\n",
      "Test: [0/2]\tval Loss: 5.8165 (val loss average: 5.8165)\n",
      "Test: [1/2]\tval Loss: 5.7771 (val loss average: 5.7982)\n",
      "Train: [599][1/3]\ttraining loss 6.449 (average: 6.449)\n",
      "Train: [599][2/3]\ttraining loss 6.508 (average: 6.479)\n",
      "Train: [599][3/3]\ttraining loss 4.649 (average: 6.348)\n",
      "Test: [0/2]\tval Loss: 5.7676 (val loss average: 5.7676)\n",
      "Test: [1/2]\tval Loss: 5.7335 (val loss average: 5.7518)\n",
      "Train: [99][1/3]\ttraining loss 6.762 (average: 6.762)\n",
      "Train: [99][2/3]\ttraining loss 6.730 (average: 6.746)\n",
      "Train: [99][3/3]\ttraining loss 4.821 (average: 6.609)\n",
      "Test: [0/2]\tval Loss: 5.9571 (val loss average: 5.9571)\n",
      "Test: [1/2]\tval Loss: 5.7990 (val loss average: 5.8837)\n",
      "Train: [199][1/3]\ttraining loss 6.600 (average: 6.600)\n",
      "Train: [199][2/3]\ttraining loss 6.625 (average: 6.612)\n",
      "Train: [199][3/3]\ttraining loss 4.686 (average: 6.475)\n",
      "Test: [0/2]\tval Loss: 5.8837 (val loss average: 5.8837)\n",
      "Test: [1/2]\tval Loss: 5.7463 (val loss average: 5.8200)\n",
      "Train: [299][1/3]\ttraining loss 6.573 (average: 6.573)\n",
      "Train: [299][2/3]\ttraining loss 6.567 (average: 6.570)\n",
      "Train: [299][3/3]\ttraining loss 4.743 (average: 6.440)\n",
      "Test: [0/2]\tval Loss: 5.9069 (val loss average: 5.9069)\n",
      "Test: [1/2]\tval Loss: 5.7810 (val loss average: 5.8485)\n",
      "Train: [399][1/3]\ttraining loss 6.502 (average: 6.502)\n",
      "Train: [399][2/3]\ttraining loss 6.501 (average: 6.501)\n",
      "Train: [399][3/3]\ttraining loss 4.694 (average: 6.373)\n",
      "Test: [0/2]\tval Loss: 5.8722 (val loss average: 5.8722)\n",
      "Test: [1/2]\tval Loss: 5.6862 (val loss average: 5.7859)\n",
      "Train: [499][1/3]\ttraining loss 6.470 (average: 6.470)\n",
      "Train: [499][2/3]\ttraining loss 6.480 (average: 6.475)\n",
      "Train: [499][3/3]\ttraining loss 4.603 (average: 6.342)\n",
      "Test: [0/2]\tval Loss: 5.8869 (val loss average: 5.8869)\n",
      "Test: [1/2]\tval Loss: 5.6436 (val loss average: 5.7740)\n",
      "Train: [599][1/3]\ttraining loss 6.482 (average: 6.482)\n",
      "Train: [599][2/3]\ttraining loss 6.463 (average: 6.472)\n",
      "Train: [599][3/3]\ttraining loss 4.566 (average: 6.337)\n",
      "Test: [0/2]\tval Loss: 5.8426 (val loss average: 5.8426)\n",
      "Test: [1/2]\tval Loss: 5.8410 (val loss average: 5.8419)\n",
      "Train: [699][1/3]\ttraining loss 6.459 (average: 6.459)\n",
      "Train: [699][2/3]\ttraining loss 6.396 (average: 6.427)\n",
      "Train: [699][3/3]\ttraining loss 4.658 (average: 6.301)\n",
      "Test: [0/2]\tval Loss: 5.8656 (val loss average: 5.8656)\n",
      "Test: [1/2]\tval Loss: 5.7248 (val loss average: 5.8003)\n",
      "Train: [799][1/3]\ttraining loss 6.381 (average: 6.381)\n",
      "Train: [799][2/3]\ttraining loss 6.481 (average: 6.431)\n",
      "Train: [799][3/3]\ttraining loss 4.435 (average: 6.289)\n",
      "Test: [0/2]\tval Loss: 5.7794 (val loss average: 5.7794)\n",
      "Test: [1/2]\tval Loss: 5.8191 (val loss average: 5.7978)\n",
      "Train: [99][1/3]\ttraining loss 6.785 (average: 6.785)\n",
      "Train: [99][2/3]\ttraining loss 6.768 (average: 6.777)\n",
      "Train: [99][3/3]\ttraining loss 4.895 (average: 6.643)\n",
      "Test: [0/2]\tval Loss: 6.0325 (val loss average: 6.0325)\n",
      "Test: [1/2]\tval Loss: 5.9182 (val loss average: 5.9794)\n",
      "Train: [199][1/3]\ttraining loss 6.678 (average: 6.678)\n",
      "Train: [199][2/3]\ttraining loss 6.662 (average: 6.670)\n",
      "Train: [199][3/3]\ttraining loss 4.829 (average: 6.539)\n",
      "Test: [0/2]\tval Loss: 6.0051 (val loss average: 6.0051)\n",
      "Test: [1/2]\tval Loss: 5.8470 (val loss average: 5.9317)\n",
      "Train: [299][1/3]\ttraining loss 6.601 (average: 6.601)\n",
      "Train: [299][2/3]\ttraining loss 6.665 (average: 6.633)\n",
      "Train: [299][3/3]\ttraining loss 4.621 (average: 6.490)\n",
      "Test: [0/2]\tval Loss: 5.9202 (val loss average: 5.9202)\n",
      "Test: [1/2]\tval Loss: 5.8159 (val loss average: 5.8718)\n",
      "Train: [399][1/3]\ttraining loss 6.580 (average: 6.580)\n",
      "Train: [399][2/3]\ttraining loss 6.512 (average: 6.546)\n",
      "Train: [399][3/3]\ttraining loss 4.720 (average: 6.416)\n",
      "Test: [0/2]\tval Loss: 5.8698 (val loss average: 5.8698)\n",
      "Test: [1/2]\tval Loss: 5.7598 (val loss average: 5.8188)\n",
      "Train: [499][1/3]\ttraining loss 6.561 (average: 6.561)\n",
      "Train: [499][2/3]\ttraining loss 6.544 (average: 6.553)\n",
      "Train: [499][3/3]\ttraining loss 4.529 (average: 6.409)\n",
      "Test: [0/2]\tval Loss: 5.8461 (val loss average: 5.8461)\n",
      "Test: [1/2]\tval Loss: 5.7440 (val loss average: 5.7987)\n",
      "Train: [599][1/3]\ttraining loss 6.439 (average: 6.439)\n",
      "Train: [599][2/3]\ttraining loss 6.512 (average: 6.475)\n",
      "Train: [599][3/3]\ttraining loss 4.524 (average: 6.336)\n",
      "Test: [0/2]\tval Loss: 5.9460 (val loss average: 5.9460)\n",
      "Test: [1/2]\tval Loss: 5.7115 (val loss average: 5.8372)\n",
      "Train: [699][1/3]\ttraining loss 6.387 (average: 6.387)\n",
      "Train: [699][2/3]\ttraining loss 6.481 (average: 6.434)\n",
      "Train: [699][3/3]\ttraining loss 4.659 (average: 6.307)\n",
      "Test: [0/2]\tval Loss: 5.9274 (val loss average: 5.9274)\n",
      "Test: [1/2]\tval Loss: 5.6966 (val loss average: 5.8203)\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "for i in range(100):\n",
    "\n",
    "    X_test_, y_test_, train_data, total_val_data, X_notrain, y_nottrain = split()\n",
    "\n",
    "    train_1()\n",
    "\n",
    "    #### load constrastive model \n",
    "\n",
    "    saved_file = os.listdir(\"./revise/effu220120_weighted_20_models/\")\n",
    "    loaded_model = torch.load(opt.model_path+f\"/{saved_file[0]}\")\n",
    "\n",
    "    model = small_encoder(input_len, [128, 256, 128, 32], dimension)\n",
    "    model.load_state_dict(loaded_model[\"model\"])\n",
    "    model = model.cuda()\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    ### classifier training\n",
    "    add_on()\n",
    "\n",
    "    clas_mod = os.listdir('./model_classifier221024/')[0]\n",
    "    classifier_model = torch.load(f'./model_classifier221024/{clas_mod}')\n",
    "    classifier_model = classifier_model.eval()\n",
    "    soft = nn.Softmax(dim=1)\n",
    "\n",
    "    val_acc1, val_acc2, roc_weight_val, roc_mirco_val, test_acc1, test_acc2, roc_weight_test, roc_micro_test = eval_model()\n",
    "    dataframe = dataframe.append({\"val_acc1\":val_acc1,\n",
    "                  \"val_acc2\":val_acc2, \n",
    "                  \"roc_weight_val\": roc_weight_val, \n",
    "                  \"roc_mirco_val\":roc_mirco_val, \n",
    "                  \"test_acc1\": test_acc1, \n",
    "                  \"test_acc2\":test_acc2, \n",
    "                  \"roc_weight_test\":roc_weight_test, \n",
    "                  \"roc_micro_test\":roc_micro_test}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"./final_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe().to_csv(\"./finalsummary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_micro_test</th>\n",
       "      <th>roc_mirco_val</th>\n",
       "      <th>roc_weight_test</th>\n",
       "      <th>roc_weight_val</th>\n",
       "      <th>test_acc1</th>\n",
       "      <th>test_acc2</th>\n",
       "      <th>val_acc1</th>\n",
       "      <th>val_acc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>75.10</td>\n",
       "      <td>88.47</td>\n",
       "      <td>75.13</td>\n",
       "      <td>88.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>70.37</td>\n",
       "      <td>84.68</td>\n",
       "      <td>70.67</td>\n",
       "      <td>85.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>74.41</td>\n",
       "      <td>87.88</td>\n",
       "      <td>74.04</td>\n",
       "      <td>87.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>75.08</td>\n",
       "      <td>88.38</td>\n",
       "      <td>75.48</td>\n",
       "      <td>88.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>76.09</td>\n",
       "      <td>89.23</td>\n",
       "      <td>76.44</td>\n",
       "      <td>89.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>79.12</td>\n",
       "      <td>91.25</td>\n",
       "      <td>79.57</td>\n",
       "      <td>91.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       roc_micro_test  roc_mirco_val  roc_weight_test  roc_weight_val  \\\n",
       "count          100.00         100.00           100.00          100.00   \n",
       "mean             0.93           0.93             0.89            0.89   \n",
       "std              0.01           0.01             0.01            0.01   \n",
       "min              0.91           0.92             0.85            0.86   \n",
       "25%              0.93           0.93             0.88            0.88   \n",
       "50%              0.93           0.93             0.89            0.89   \n",
       "75%              0.94           0.94             0.89            0.90   \n",
       "max              0.95           0.95             0.91            0.92   \n",
       "\n",
       "       test_acc1  test_acc2  val_acc1  val_acc2  \n",
       "count     100.00     100.00    100.00    100.00  \n",
       "mean       75.10      88.47     75.13     88.47  \n",
       "std         1.49       1.16      1.87      1.38  \n",
       "min        70.37      84.68     70.67     85.10  \n",
       "25%        74.41      87.88     74.04     87.44  \n",
       "50%        75.08      88.38     75.48     88.46  \n",
       "75%        76.09      89.23     76.44     89.42  \n",
       "max        79.12      91.25     79.57     91.11  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_micro_test</th>\n",
       "      <th>roc_mirco_val</th>\n",
       "      <th>roc_weight_test</th>\n",
       "      <th>roc_weight_val</th>\n",
       "      <th>test_acc1</th>\n",
       "      <th>test_acc2</th>\n",
       "      <th>val_acc1</th>\n",
       "      <th>val_acc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>79.12</td>\n",
       "      <td>90.74</td>\n",
       "      <td>74.04</td>\n",
       "      <td>88.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>76.26</td>\n",
       "      <td>90.24</td>\n",
       "      <td>75.96</td>\n",
       "      <td>91.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>75.08</td>\n",
       "      <td>91.25</td>\n",
       "      <td>76.68</td>\n",
       "      <td>87.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>75.76</td>\n",
       "      <td>88.22</td>\n",
       "      <td>75.96</td>\n",
       "      <td>89.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>77.78</td>\n",
       "      <td>89.56</td>\n",
       "      <td>74.04</td>\n",
       "      <td>90.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>76.60</td>\n",
       "      <td>89.39</td>\n",
       "      <td>75.72</td>\n",
       "      <td>89.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>76.26</td>\n",
       "      <td>90.57</td>\n",
       "      <td>73.56</td>\n",
       "      <td>85.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>75.25</td>\n",
       "      <td>89.39</td>\n",
       "      <td>75.24</td>\n",
       "      <td>87.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>76.43</td>\n",
       "      <td>88.55</td>\n",
       "      <td>76.44</td>\n",
       "      <td>87.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>77.61</td>\n",
       "      <td>90.57</td>\n",
       "      <td>75.48</td>\n",
       "      <td>88.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    roc_micro_test  roc_mirco_val  roc_weight_test  roc_weight_val  test_acc1  \\\n",
       "77            0.95           0.93             0.91            0.89      79.12   \n",
       "1             0.95           0.93             0.91            0.88      76.26   \n",
       "41            0.94           0.93             0.90            0.90      75.08   \n",
       "81            0.94           0.93             0.91            0.89      75.76   \n",
       "25            0.94           0.94             0.90            0.90      77.78   \n",
       "80            0.94           0.93             0.90            0.88      76.60   \n",
       "6             0.94           0.92             0.89            0.86      76.26   \n",
       "55            0.94           0.93             0.90            0.89      75.25   \n",
       "97            0.94           0.93             0.90            0.89      76.43   \n",
       "34            0.94           0.94             0.90            0.89      77.61   \n",
       "\n",
       "    test_acc2  val_acc1  val_acc2  \n",
       "77      90.74     74.04     88.22  \n",
       "1       90.24     75.96     91.11  \n",
       "41      91.25     76.68     87.50  \n",
       "81      88.22     75.96     89.18  \n",
       "25      89.56     74.04     90.14  \n",
       "80      89.39     75.72     89.18  \n",
       "6       90.57     73.56     85.58  \n",
       "55      89.39     75.24     87.02  \n",
       "97      88.55     76.44     87.98  \n",
       "34      90.57     75.48     88.94  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.sort_values(by=\"roc_micro_test\", ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "park",
   "language": "python",
   "name": "park"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
